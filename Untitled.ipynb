{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "43330f14-139e-41db-ad8d-8c9f0a316c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/Cellar/jupyterlab/4.0.7/libexec/lib/python3.11/site-packages (1.26.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/local/Cellar/jupyterlab/4.0.7/libexec/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: scikit-learn in /usr/local/Cellar/jupyterlab/4.0.7/libexec/lib/python3.11/site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/Cellar/jupyterlab/4.0.7/libexec/lib/python3.11/site-packages (from scikit-learn) (1.26.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/Cellar/jupyterlab/4.0.7/libexec/lib/python3.11/site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/Cellar/jupyterlab/4.0.7/libexec/lib/python3.11/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/Cellar/jupyterlab/4.0.7/libexec/lib/python3.11/site-packages (from scikit-learn) (3.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/local/Cellar/jupyterlab/4.0.7/libexec/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /usr/local/Cellar/jupyterlab/4.0.7/libexec/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/Cellar/jupyterlab/4.0.7/libexec/lib/python3.11/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/Cellar/jupyterlab/4.0.7/libexec/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/Cellar/jupyterlab/4.0.7/libexec/lib/python3.11/site-packages (from matplotlib) (4.44.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/Cellar/jupyterlab/4.0.7/libexec/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/Cellar/jupyterlab/4.0.7/libexec/lib/python3.11/site-packages (from matplotlib) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/opt/python-packaging/lib/python3.11/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/Cellar/jupyterlab/4.0.7/libexec/lib/python3.11/site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/Cellar/jupyterlab/4.0.7/libexec/lib/python3.11/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/Cellar/jupyterlab/4.0.7/libexec/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/opt/six/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/local/Cellar/jupyterlab/4.0.7/libexec/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: opencv-python in /usr/local/Cellar/jupyterlab/4.0.7/libexec/lib/python3.11/site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /usr/local/Cellar/jupyterlab/4.0.7/libexec/lib/python3.11/site-packages (from opencv-python) (1.26.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/local/Cellar/jupyterlab/4.0.7/libexec/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: scipy in /usr/local/Cellar/jupyterlab/4.0.7/libexec/lib/python3.11/site-packages (1.11.3)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/Cellar/jupyterlab/4.0.7/libexec/lib/python3.11/site-packages (from scipy) (1.26.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/local/Cellar/jupyterlab/4.0.7/libexec/bin/python -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install -U scikit-learn\n",
    "!{sys.executable} -m pip install -U matplotlib\n",
    "!{sys.executable} -m pip install -U opencv-python\n",
    "!{sys.executable} -m pip install scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "eabd7694-6c51-4d4c-afcc-100a4b212ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from activations import ReLU, Softmax, Sigmoid, TanH\n",
    "from dataset import heart_classification\n",
    "from evaluation import BCE\n",
    "from initializers import He, Xavier\n",
    "from model import NeuralNetwork\n",
    "from train import Train\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d17f8bb-8037-4302-b6e1-9bd869efdfbc",
   "metadata": {},
   "source": [
    "### Set initial parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c3370c-d63f-4766-af16-bbf458b3cb0f",
   "metadata": {},
   "source": [
    "Dataset: heart disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "83ad5336-36cf-408f-990a-2eace9e1c169",
   "metadata": {},
   "outputs": [],
   "source": [
    "    inputs, outputs = heart_classification()\n",
    "    inputs_train, inputs_test, outputs_train, outputs_test = train_test_split(inputs, outputs, test_size=0.16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d42acfa-228a-4df8-a504-9da43f4e33a7",
   "metadata": {},
   "source": [
    "Loss function - BCE - for binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb9a390-d36f-4102-ab11-4d0449ae9d39",
   "metadata": {},
   "source": [
    "Batch size = Input data size -> Use gradient descent for first iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "92b9718e-5827-4d23-b1d2-b07836d9e890",
   "metadata": {},
   "outputs": [],
   "source": [
    "    learning_rate = 0.00001\n",
    "    batch_size = inputs_train.shape[0]\n",
    "    epochs = 50000\n",
    "    loss_function = BCE()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4ef124-bac2-4409-b7ba-1f0065fe6b64",
   "metadata": {},
   "source": [
    "Reshape output vector into numpy matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "18208cda-b4b2-48a6-aa27-7058be6949c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    if len(outputs_train.shape) == 1:\n",
    "        outputs_train = np.reshape(outputs_train, (outputs_train.shape[0], 1))\n",
    "    input_dim = inputs_train.shape[1]\n",
    "    hidden_dim = inputs_train.shape[0]\n",
    "    output_dim = outputs_train.shape[1]\n",
    "    num_of_hidden_layers = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a17628b-5216-4e56-a759-e032308ff45f",
   "metadata": {},
   "source": [
    "ReLU - for hidden layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02edf407-411c-44a8-9c9a-ac650f09d032",
   "metadata": {},
   "source": [
    "Sigmoid - for output layers to calculate probabilities for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "61490f56-8258-4449-81e8-14457e1809fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "    activation = ReLU()\n",
    "    activation_output = Sigmoid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca99e57-3f73-480f-af51-d0b057637f85",
   "metadata": {},
   "source": [
    "He - for Relu activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f8509c-2d88-4ee3-b68d-757b27b4e5d8",
   "metadata": {},
   "source": [
    "Xavier - for Sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cc74ceaa-794a-44e1-95bd-f85b3329ed79",
   "metadata": {},
   "outputs": [],
   "source": [
    "    initialization = He\n",
    "    output_initialization = Xavier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a33a7b-efe7-4697-a3e8-16a425146697",
   "metadata": {},
   "source": [
    "Initialize network with specified parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5796b47c-fe8f-4907-908f-2c64e4b3d3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "    network = NeuralNetwork(input_dim,\n",
    "                            hidden_dim,\n",
    "                            output_dim,\n",
    "                            num_of_hidden_layers,\n",
    "                            activation,\n",
    "                            activation_output,\n",
    "                            initialization,\n",
    "                            output_initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5e55f570-6768-4b88-8975-9c602dd98330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Accuracy: 0.6382113821138211 Loss: 5.690334597694974\n",
      "500. Accuracy: 0.6626016260162602 Loss: 2.240485367860273\n",
      "1000. Accuracy: 0.6707317073170732 Loss: 1.9143648668074844\n",
      "1500. Accuracy: 0.6707317073170732 Loss: 1.6724534063148462\n",
      "2000. Accuracy: 0.6707317073170732 Loss: 1.4785086196615758\n",
      "2500. Accuracy: 0.6829268292682927 Loss: 1.3292591866995278\n",
      "3000. Accuracy: 0.6910569105691057 Loss: 1.192323072848696\n",
      "3500. Accuracy: 0.6910569105691057 Loss: 1.084460879896159\n",
      "4000. Accuracy: 0.7032520325203252 Loss: 0.9847105010284054\n",
      "4500. Accuracy: 0.7073170731707317 Loss: 0.8773359462269575\n",
      "5000. Accuracy: 0.7154471544715447 Loss: 0.8233425352108774\n",
      "5500. Accuracy: 0.7154471544715447 Loss: 0.7658620536121022\n",
      "6000. Accuracy: 0.7235772357723578 Loss: 0.7176942970554707\n",
      "6500. Accuracy: 0.7235772357723578 Loss: 0.6758265605058357\n",
      "7000. Accuracy: 0.7276422764227642 Loss: 0.6387606997170595\n",
      "7500. Accuracy: 0.7276422764227642 Loss: 0.6072776186090981\n",
      "8000. Accuracy: 0.7357723577235772 Loss: 0.5805377733332917\n",
      "8500. Accuracy: 0.7357723577235772 Loss: 0.5592135635681692\n",
      "9000. Accuracy: 0.7398373983739838 Loss: 0.5382819988335367\n",
      "9500. Accuracy: 0.7439024390243902 Loss: 0.522008114903603\n",
      "10000. Accuracy: 0.7479674796747967 Loss: 0.5072398433398487\n",
      "10500. Accuracy: 0.7479674796747967 Loss: 0.49401208718308853\n",
      "11000. Accuracy: 0.7520325203252033 Loss: 0.483563805729846\n",
      "11500. Accuracy: 0.7560975609756098 Loss: 0.4747444624117122\n",
      "12000. Accuracy: 0.7601626016260162 Loss: 0.46597294761785457\n",
      "12500. Accuracy: 0.7642276422764228 Loss: 0.45681668659883706\n",
      "13000. Accuracy: 0.7723577235772358 Loss: 0.45073242011817766\n",
      "13500. Accuracy: 0.7723577235772358 Loss: 0.4444226031930781\n",
      "14000. Accuracy: 0.7764227642276422 Loss: 0.439147291755752\n",
      "14500. Accuracy: 0.7723577235772358 Loss: 0.4341149795095232\n",
      "15000. Accuracy: 0.7682926829268293 Loss: 0.4301365229373298\n",
      "15500. Accuracy: 0.7682926829268293 Loss: 0.42568194608163173\n",
      "16000. Accuracy: 0.7804878048780488 Loss: 0.42133388068675837\n",
      "16500. Accuracy: 0.7804878048780488 Loss: 0.42083494379220354\n",
      "17000. Accuracy: 0.7845528455284553 Loss: 0.4163417635608349\n",
      "17500. Accuracy: 0.7886178861788617 Loss: 0.4132785593500559\n",
      "18000. Accuracy: 0.7886178861788617 Loss: 0.4108001410755403\n",
      "18500. Accuracy: 0.7886178861788617 Loss: 0.4086404969032955\n",
      "19000. Accuracy: 0.7886178861788617 Loss: 0.40608281655583445\n",
      "19500. Accuracy: 0.7886178861788617 Loss: 0.4036903676741423\n",
      "20000. Accuracy: 0.7886178861788617 Loss: 0.40131509978347446\n",
      "20500. Accuracy: 0.7926829268292683 Loss: 0.3985000802512662\n",
      "21000. Accuracy: 0.7926829268292683 Loss: 0.39551527960032723\n",
      "21500. Accuracy: 0.7926829268292683 Loss: 0.3936571759268485\n",
      "22000. Accuracy: 0.7926829268292683 Loss: 0.3928583686063482\n",
      "22500. Accuracy: 0.7926829268292683 Loss: 0.39096695936375375\n",
      "23000. Accuracy: 0.8008130081300813 Loss: 0.389458343629018\n",
      "23500. Accuracy: 0.8008130081300813 Loss: 0.3878342280491007\n",
      "24000. Accuracy: 0.8008130081300813 Loss: 0.3862877543608289\n",
      "24500. Accuracy: 0.8048780487804879 Loss: 0.384859565623509\n",
      "25000. Accuracy: 0.8048780487804879 Loss: 0.3832963902328408\n",
      "25500. Accuracy: 0.8089430894308943 Loss: 0.38127169794691385\n",
      "26000. Accuracy: 0.8130081300813008 Loss: 0.3786201804765587\n",
      "26500. Accuracy: 0.8130081300813008 Loss: 0.3780902364246669\n",
      "27000. Accuracy: 0.8089430894308943 Loss: 0.3766892625723474\n",
      "27500. Accuracy: 0.8130081300813008 Loss: 0.375022444823419\n",
      "28000. Accuracy: 0.8130081300813008 Loss: 0.37343051727372656\n",
      "28500. Accuracy: 0.8170731707317073 Loss: 0.37307114111849227\n",
      "29000. Accuracy: 0.8170731707317073 Loss: 0.37303121398685524\n",
      "29500. Accuracy: 0.8211382113821138 Loss: 0.37219061531491715\n",
      "30000. Accuracy: 0.8292682926829268 Loss: 0.37169535309190516\n",
      "30500. Accuracy: 0.8292682926829268 Loss: 0.36977095268482135\n",
      "31000. Accuracy: 0.8292682926829268 Loss: 0.3700193878219023\n",
      "31500. Accuracy: 0.8252032520325203 Loss: 0.3686900977569495\n",
      "32000. Accuracy: 0.8292682926829268 Loss: 0.3687034386653895\n",
      "32500. Accuracy: 0.8333333333333334 Loss: 0.36738267100666977\n",
      "33000. Accuracy: 0.8252032520325203 Loss: 0.36649171791218527\n",
      "33500. Accuracy: 0.8292682926829268 Loss: 0.36591796143326155\n",
      "34000. Accuracy: 0.8252032520325203 Loss: 0.3645462993950579\n",
      "34500. Accuracy: 0.8292682926829268 Loss: 0.36386688358255653\n",
      "35000. Accuracy: 0.8292682926829268 Loss: 0.36210487308927203\n",
      "35500. Accuracy: 0.8333333333333334 Loss: 0.36071792773070227\n",
      "36000. Accuracy: 0.8373983739837398 Loss: 0.3598190180429187\n",
      "36500. Accuracy: 0.8373983739837398 Loss: 0.3587791046905258\n",
      "37000. Accuracy: 0.8373983739837398 Loss: 0.3574933874748876\n",
      "37500. Accuracy: 0.8373983739837398 Loss: 0.35666001662231783\n",
      "38000. Accuracy: 0.8333333333333334 Loss: 0.35499378861901604\n",
      "38500. Accuracy: 0.8333333333333334 Loss: 0.3531491815967539\n",
      "39000. Accuracy: 0.8333333333333334 Loss: 0.3526623859602288\n",
      "39500. Accuracy: 0.8333333333333334 Loss: 0.3511420102701175\n",
      "40000. Accuracy: 0.8292682926829268 Loss: 0.3504204928691539\n",
      "40500. Accuracy: 0.8292682926829268 Loss: 0.3496450347707656\n",
      "41000. Accuracy: 0.8292682926829268 Loss: 0.3495226279481609\n",
      "41500. Accuracy: 0.8292682926829268 Loss: 0.3491925004014648\n",
      "42000. Accuracy: 0.8333333333333334 Loss: 0.3499738815763719\n",
      "42500. Accuracy: 0.8333333333333334 Loss: 0.34935242044293896\n",
      "43000. Accuracy: 0.8373983739837398 Loss: 0.34836213933774896\n",
      "43500. Accuracy: 0.8333333333333334 Loss: 0.34581286465831623\n",
      "44000. Accuracy: 0.8333333333333334 Loss: 0.34675823544688594\n",
      "44500. Accuracy: 0.8333333333333334 Loss: 0.3463400380336936\n",
      "45000. Accuracy: 0.8333333333333334 Loss: 0.3456844112804089\n",
      "45500. Accuracy: 0.8373983739837398 Loss: 0.3464553419054457\n",
      "46000. Accuracy: 0.8333333333333334 Loss: 0.34545344085749674\n",
      "46500. Accuracy: 0.8333333333333334 Loss: 0.3442248685711552\n",
      "47000. Accuracy: 0.8333333333333334 Loss: 0.34307883770268144\n",
      "47500. Accuracy: 0.8373983739837398 Loss: 0.34175227670122893\n",
      "48000. Accuracy: 0.8373983739837398 Loss: 0.34261472283796146\n",
      "48500. Accuracy: 0.8373983739837398 Loss: 0.34025822103680686\n",
      "49000. Accuracy: 0.8373983739837398 Loss: 0.34108453962391333\n",
      "49500. Accuracy: 0.8373983739837398 Loss: 0.33986602321743187\n"
     ]
    }
   ],
   "source": [
    "    train = Train(network, learning_rate, batch_size, epochs, loss_function)\n",
    "    cost, accuracies = train.train(inputs_train, outputs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5ef17bea-8220-4f15-b643-9403c200b47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([a for a in range(len(cost))],cost)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a36b7a-3cfa-4e6b-aeb3-885297539860",
   "metadata": {},
   "source": [
    "## 1. Measuring the impact of neural network dimensionality on model performance (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e1d6f8-0fef-4223-9f60-b5205f19e7c4",
   "metadata": {},
   "source": [
    "### a) change number of hidden layers to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f251b880-9a91-4d25-a910-c2aa3d72ac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_hidden_layers = 2\n",
    "network1a = NeuralNetwork(input_dim,\n",
    "                        hidden_dim,\n",
    "                        output_dim,\n",
    "                        num_of_hidden_layers,\n",
    "                        activation,\n",
    "                        activation_output,\n",
    "                        initialization,\n",
    "                        output_initialization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8307dc72-c38d-43e7-9a91-292730068824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Accuracy: 0.6382113821138211 Loss: 5.793770430373392\n",
      "500. Accuracy: 0.6869918699186992 Loss: 0.8414479245691645\n",
      "1000. Accuracy: 0.7032520325203252 Loss: 0.7125503124975939\n",
      "1500. Accuracy: 0.7235772357723578 Loss: 0.6397614862152232\n",
      "2000. Accuracy: 0.7276422764227642 Loss: 0.5881119506571346\n",
      "2500. Accuracy: 0.7276422764227642 Loss: 0.5576394795175881\n",
      "3000. Accuracy: 0.7276422764227642 Loss: 0.5536732893773403\n",
      "3500. Accuracy: 0.7235772357723578 Loss: 0.583645896998256\n",
      "4000. Accuracy: 0.7276422764227642 Loss: 0.5910000255480949\n",
      "4500. Accuracy: 0.7235772357723578 Loss: 0.6138842100791669\n",
      "5000. Accuracy: 0.7195121951219512 Loss: 0.6519341872161265\n",
      "5500. Accuracy: 0.7032520325203252 Loss: 0.6950865462507294\n",
      "6000. Accuracy: 0.7113821138211383 Loss: 0.7161282165929986\n",
      "6500. Accuracy: 0.6991869918699187 Loss: 0.7694132385323469\n",
      "7000. Accuracy: 0.7032520325203252 Loss: 0.6994676010809475\n",
      "7500. Accuracy: 0.7073170731707317 Loss: 0.7105760620064372\n",
      "8000. Accuracy: 0.7073170731707317 Loss: 0.7255004023803147\n",
      "8500. Accuracy: 0.7195121951219512 Loss: 0.6461586966959244\n",
      "9000. Accuracy: 0.6991869918699187 Loss: 0.6789652110810059\n",
      "9500. Accuracy: 0.7032520325203252 Loss: 0.6410771799262621\n",
      "10000. Accuracy: 0.7073170731707317 Loss: 0.617381450983349\n",
      "10500. Accuracy: 0.7073170731707317 Loss: 0.6380380321156472\n",
      "11000. Accuracy: 0.7154471544715447 Loss: 0.6310764185682994\n",
      "11500. Accuracy: 0.7154471544715447 Loss: 0.6373699013102953\n",
      "12000. Accuracy: 0.7235772357723578 Loss: 0.6224892708005414\n",
      "12500. Accuracy: 0.7235772357723578 Loss: 0.6057270080071893\n",
      "13000. Accuracy: 0.7276422764227642 Loss: 0.5794699467433582\n",
      "13500. Accuracy: 0.7276422764227642 Loss: 0.5724012977136991\n",
      "14000. Accuracy: 0.7357723577235772 Loss: 0.517079149862634\n",
      "14500. Accuracy: 0.7317073170731707 Loss: 0.5216728656703816\n",
      "15000. Accuracy: 0.7317073170731707 Loss: 0.531035342505761\n",
      "15500. Accuracy: 0.7317073170731707 Loss: 0.5395545169584789\n",
      "16000. Accuracy: 0.7317073170731707 Loss: 0.5318345321620409\n",
      "16500. Accuracy: 0.7357723577235772 Loss: 0.5121278191885208\n",
      "17000. Accuracy: 0.7317073170731707 Loss: 0.53224512215702\n",
      "17500. Accuracy: 0.7398373983739838 Loss: 0.5152913748542419\n",
      "18000. Accuracy: 0.7357723577235772 Loss: 0.5079749110369219\n",
      "18500. Accuracy: 0.7398373983739838 Loss: 0.511414486266992\n",
      "19000. Accuracy: 0.7398373983739838 Loss: 0.5038409360857431\n",
      "19500. Accuracy: 0.7520325203252033 Loss: 0.4812474099121852\n",
      "20000. Accuracy: 0.7398373983739838 Loss: 0.4862490689474591\n",
      "20500. Accuracy: 0.7439024390243902 Loss: 0.48033485782219987\n",
      "21000. Accuracy: 0.7398373983739838 Loss: 0.4890353606674738\n",
      "21500. Accuracy: 0.7398373983739838 Loss: 0.4955522018895203\n",
      "22000. Accuracy: 0.7479674796747967 Loss: 0.4826744851772785\n",
      "22500. Accuracy: 0.7398373983739838 Loss: 0.5068018038520196\n",
      "23000. Accuracy: 0.7439024390243902 Loss: 0.45569956556534624\n",
      "23500. Accuracy: 0.7520325203252033 Loss: 0.47924601869419664\n",
      "24000. Accuracy: 0.7560975609756098 Loss: 0.4626306625421002\n",
      "24500. Accuracy: 0.7398373983739838 Loss: 0.5084019493186466\n",
      "25000. Accuracy: 0.7601626016260162 Loss: 0.47123406666502904\n",
      "25500. Accuracy: 0.7560975609756098 Loss: 0.4563159789916112\n",
      "26000. Accuracy: 0.7520325203252033 Loss: 0.4881041883512743\n",
      "26500. Accuracy: 0.7479674796747967 Loss: 0.49260612481612204\n",
      "27000. Accuracy: 0.7560975609756098 Loss: 0.4828901062258867\n",
      "27500. Accuracy: 0.7560975609756098 Loss: 0.46989749975616274\n",
      "28000. Accuracy: 0.7642276422764228 Loss: 0.44932689653685864\n",
      "28500. Accuracy: 0.7642276422764228 Loss: 0.48062877320923697\n",
      "29000. Accuracy: 0.7479674796747967 Loss: 0.4886145353286567\n",
      "29500. Accuracy: 0.7601626016260162 Loss: 0.4818125938383729\n",
      "30000. Accuracy: 0.7601626016260162 Loss: 0.5064975583616778\n",
      "30500. Accuracy: 0.7642276422764228 Loss: 0.48184683946171375\n",
      "31000. Accuracy: 0.7560975609756098 Loss: 0.4917817044134264\n",
      "31500. Accuracy: 0.7601626016260162 Loss: 0.47347173567779266\n",
      "32000. Accuracy: 0.7560975609756098 Loss: 0.4733353722548756\n",
      "32500. Accuracy: 0.7642276422764228 Loss: 0.4709936265851679\n",
      "33000. Accuracy: 0.7520325203252033 Loss: 0.48910174471118506\n",
      "33500. Accuracy: 0.7764227642276422 Loss: 0.4499254917120406\n",
      "34000. Accuracy: 0.7601626016260162 Loss: 0.46504588485274656\n",
      "34500. Accuracy: 0.7601626016260162 Loss: 0.4891642385497224\n",
      "35000. Accuracy: 0.7520325203252033 Loss: 0.5253683142685163\n",
      "35500. Accuracy: 0.7682926829268293 Loss: 0.4559437591449453\n",
      "36000. Accuracy: 0.7601626016260162 Loss: 0.5012899486177146\n",
      "36500. Accuracy: 0.7479674796747967 Loss: 0.5314698141745853\n",
      "37000. Accuracy: 0.7845528455284553 Loss: 0.44253365123434907\n",
      "37500. Accuracy: 0.7845528455284553 Loss: 0.45973807043524434\n",
      "38000. Accuracy: 0.7520325203252033 Loss: 0.5229916757624595\n",
      "38500. Accuracy: 0.7682926829268293 Loss: 0.4655757078276574\n",
      "39000. Accuracy: 0.7601626016260162 Loss: 0.4801035615257232\n",
      "39500. Accuracy: 0.7601626016260162 Loss: 0.5185382902849559\n",
      "40000. Accuracy: 0.7479674796747967 Loss: 0.5203710365525295\n",
      "40500. Accuracy: 0.7723577235772358 Loss: 0.4560985780219501\n",
      "41000. Accuracy: 0.7723577235772358 Loss: 0.4558225611140321\n",
      "41500. Accuracy: 0.7682926829268293 Loss: 0.465853358112093\n",
      "42000. Accuracy: 0.7682926829268293 Loss: 0.504869875963729\n",
      "42500. Accuracy: 0.7601626016260162 Loss: 0.47552714625505976\n",
      "43000. Accuracy: 0.7520325203252033 Loss: 0.5103758590870848\n",
      "43500. Accuracy: 0.7642276422764228 Loss: 0.45464197966531517\n",
      "44000. Accuracy: 0.7723577235772358 Loss: 0.49477418397510464\n",
      "44500. Accuracy: 0.7804878048780488 Loss: 0.46809829638996314\n",
      "45000. Accuracy: 0.7560975609756098 Loss: 0.5100904548149521\n",
      "45500. Accuracy: 0.7682926829268293 Loss: 0.45377467210237454\n",
      "46000. Accuracy: 0.7601626016260162 Loss: 0.4850397161981182\n",
      "46500. Accuracy: 0.7601626016260162 Loss: 0.4497216583497345\n",
      "47000. Accuracy: 0.7642276422764228 Loss: 0.4693273587727794\n",
      "47500. Accuracy: 0.7520325203252033 Loss: 0.491165223710228\n",
      "48000. Accuracy: 0.7560975609756098 Loss: 0.4968907512942512\n",
      "48500. Accuracy: 0.7764227642276422 Loss: 0.4821599220362303\n",
      "49000. Accuracy: 0.7317073170731707 Loss: 0.5818980497676937\n",
      "49500. Accuracy: 0.7642276422764228 Loss: 0.48492606302360797\n"
     ]
    }
   ],
   "source": [
    "train = Train(network1a, learning_rate, batch_size, epochs, loss_function)\n",
    "cost, accuracies = train.train(inputs_train, outputs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "61e865ab-092a-4c19-afdd-a2b4d860d38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([a for a in range(len(cost))],cost)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85392c4d-290d-4706-a27a-5071f4942e14",
   "metadata": {},
   "source": [
    "### b) split data into batches using batch size = 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "72124817-d972-4203-9753-b4da3c7c6a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 41\n",
    "num_of_hidden_layers = 1\n",
    "network1b = NeuralNetwork(input_dim,\n",
    "                        hidden_dim,\n",
    "                        output_dim,\n",
    "                        num_of_hidden_layers,\n",
    "                        activation,\n",
    "                        activation_output,\n",
    "                        initialization,\n",
    "                        output_initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2976b058-aebf-43bb-adf2-802728204148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Accuracy: 0.5853658536585366 Loss: 4.197640638867117\n",
      "0. Accuracy: 0.6585365853658537 Loss: 1.1267248235466916\n",
      "0. Accuracy: 0.4146341463414634 Loss: 1.4750011439843314\n",
      "0. Accuracy: 0.6829268292682927 Loss: 1.2829731163129563\n",
      "0. Accuracy: 0.5365853658536586 Loss: 1.1571274017907507\n",
      "0. Accuracy: 0.5121951219512195 Loss: 0.9471374790045203\n",
      "500. Accuracy: 0.7804878048780488 Loss: 0.4654870078496932\n",
      "500. Accuracy: 0.5853658536585366 Loss: 0.7001568185780439\n",
      "500. Accuracy: 0.8048780487804879 Loss: 0.3706620711177948\n",
      "500. Accuracy: 0.7317073170731707 Loss: 0.5123997795250759\n",
      "500. Accuracy: 0.6585365853658537 Loss: 0.6046343824201998\n",
      "500. Accuracy: 0.7073170731707317 Loss: 0.546372575226287\n",
      "1000. Accuracy: 0.6341463414634146 Loss: 0.5974318799835981\n",
      "1000. Accuracy: 0.5365853658536586 Loss: 0.7702654629451415\n",
      "1000. Accuracy: 0.8048780487804879 Loss: 0.38217974639444746\n",
      "1000. Accuracy: 0.7317073170731707 Loss: 0.4732164859292\n",
      "1000. Accuracy: 0.7317073170731707 Loss: 0.5837464296977126\n",
      "1000. Accuracy: 0.6585365853658537 Loss: 0.5737531568958181\n",
      "1500. Accuracy: 0.8780487804878049 Loss: 0.36827841045202026\n",
      "1500. Accuracy: 0.6829268292682927 Loss: 0.6854899129956126\n",
      "1500. Accuracy: 0.3902439024390244 Loss: 0.8081180264354967\n",
      "1500. Accuracy: 0.7073170731707317 Loss: 1.0242161575100432\n",
      "1500. Accuracy: 0.7317073170731707 Loss: 0.5539234847627587\n",
      "1500. Accuracy: 0.7804878048780488 Loss: 0.5082134937958597\n",
      "2000. Accuracy: 0.7317073170731707 Loss: 0.45009716972031694\n",
      "2000. Accuracy: 0.6585365853658537 Loss: 0.6208751195409633\n",
      "2000. Accuracy: 0.8536585365853658 Loss: 0.2985563463430148\n",
      "2000. Accuracy: 0.7560975609756098 Loss: 0.43914377270718025\n",
      "2000. Accuracy: 0.7804878048780488 Loss: 0.5383912411020335\n",
      "2000. Accuracy: 0.7560975609756098 Loss: 0.4998381808853474\n",
      "2500. Accuracy: 0.9024390243902439 Loss: 0.34157798745415135\n",
      "2500. Accuracy: 0.6829268292682927 Loss: 0.599466633069177\n",
      "2500. Accuracy: 0.6585365853658537 Loss: 0.5892984088741375\n",
      "2500. Accuracy: 0.7073170731707317 Loss: 0.7757102789486283\n",
      "2500. Accuracy: 0.7073170731707317 Loss: 0.5297976280868335\n",
      "2500. Accuracy: 0.8048780487804879 Loss: 0.4705030962328423\n",
      "3000. Accuracy: 0.9024390243902439 Loss: 0.33047545033090514\n",
      "3000. Accuracy: 0.7073170731707317 Loss: 0.5870121425099665\n",
      "3000. Accuracy: 0.6585365853658537 Loss: 0.5665758330515313\n",
      "3000. Accuracy: 0.7317073170731707 Loss: 0.731159881125763\n",
      "3000. Accuracy: 0.7073170731707317 Loss: 0.5177220441477639\n",
      "3000. Accuracy: 0.8048780487804879 Loss: 0.45969236650505996\n",
      "3500. Accuracy: 0.8780487804878049 Loss: 0.31710946315319455\n",
      "3500. Accuracy: 0.7073170731707317 Loss: 0.5457390252029738\n",
      "3500. Accuracy: 0.8292682926829268 Loss: 0.4525849528919508\n",
      "3500. Accuracy: 0.7317073170731707 Loss: 0.6087320646009192\n",
      "3500. Accuracy: 0.6829268292682927 Loss: 0.512480991097338\n",
      "3500. Accuracy: 0.8048780487804879 Loss: 0.4529085602120125\n",
      "4000. Accuracy: 0.9024390243902439 Loss: 0.30931879670815154\n",
      "4000. Accuracy: 0.7560975609756098 Loss: 0.5274758348203108\n",
      "4000. Accuracy: 0.8536585365853658 Loss: 0.4046913499413061\n",
      "4000. Accuracy: 0.7560975609756098 Loss: 0.5504338772501312\n",
      "4000. Accuracy: 0.7317073170731707 Loss: 0.5013083270161877\n",
      "4000. Accuracy: 0.8048780487804879 Loss: 0.44358533734820527\n",
      "4500. Accuracy: 0.9024390243902439 Loss: 0.3054445804286015\n",
      "4500. Accuracy: 0.7317073170731707 Loss: 0.5105509286680407\n",
      "4500. Accuracy: 0.926829268292683 Loss: 0.35710064307865214\n",
      "4500. Accuracy: 0.7560975609756098 Loss: 0.4939751415976921\n",
      "4500. Accuracy: 0.7804878048780488 Loss: 0.489920705637905\n",
      "4500. Accuracy: 0.7804878048780488 Loss: 0.43629621112605643\n",
      "5000. Accuracy: 0.9024390243902439 Loss: 0.30094869773236094\n",
      "5000. Accuracy: 0.7560975609756098 Loss: 0.5017715511265021\n",
      "5000. Accuracy: 0.9512195121951219 Loss: 0.3373325836016457\n",
      "5000. Accuracy: 0.7560975609756098 Loss: 0.46923878485282267\n",
      "5000. Accuracy: 0.8048780487804879 Loss: 0.47921466489487596\n",
      "5000. Accuracy: 0.7804878048780488 Loss: 0.43242410456941816\n",
      "5500. Accuracy: 0.9024390243902439 Loss: 0.30016077957596643\n",
      "5500. Accuracy: 0.7560975609756098 Loss: 0.4925971269938462\n",
      "5500. Accuracy: 0.975609756097561 Loss: 0.3147332592090918\n",
      "5500. Accuracy: 0.7560975609756098 Loss: 0.44468009298266803\n",
      "5500. Accuracy: 0.8292682926829268 Loss: 0.4713998105514837\n",
      "5500. Accuracy: 0.7804878048780488 Loss: 0.43033902724544426\n",
      "6000. Accuracy: 0.9024390243902439 Loss: 0.293019506689937\n",
      "6000. Accuracy: 0.7560975609756098 Loss: 0.4869433056586883\n",
      "6000. Accuracy: 0.975609756097561 Loss: 0.31846020504232436\n",
      "6000. Accuracy: 0.7560975609756098 Loss: 0.44151200140380314\n",
      "6000. Accuracy: 0.8536585365853658 Loss: 0.46612007759571605\n",
      "6000. Accuracy: 0.7804878048780488 Loss: 0.42764417874110006\n",
      "6500. Accuracy: 0.9024390243902439 Loss: 0.29109513098056883\n",
      "6500. Accuracy: 0.7560975609756098 Loss: 0.47964925978475426\n",
      "6500. Accuracy: 0.975609756097561 Loss: 0.3068104566793772\n",
      "6500. Accuracy: 0.7560975609756098 Loss: 0.426009918745075\n",
      "6500. Accuracy: 0.8536585365853658 Loss: 0.4614018969772403\n",
      "6500. Accuracy: 0.7804878048780488 Loss: 0.42657276965320406\n",
      "7000. Accuracy: 0.8780487804878049 Loss: 0.2883513559637663\n",
      "7000. Accuracy: 0.7560975609756098 Loss: 0.47348768413448056\n",
      "7000. Accuracy: 0.9512195121951219 Loss: 0.3016278568226766\n",
      "7000. Accuracy: 0.7560975609756098 Loss: 0.41702777312567757\n",
      "7000. Accuracy: 0.8536585365853658 Loss: 0.45671871226458044\n",
      "7000. Accuracy: 0.7804878048780488 Loss: 0.4270924478666042\n",
      "7500. Accuracy: 0.8780487804878049 Loss: 0.2847871584232767\n",
      "7500. Accuracy: 0.7804878048780488 Loss: 0.4689023206667732\n",
      "7500. Accuracy: 0.9512195121951219 Loss: 0.2966737662039564\n",
      "7500. Accuracy: 0.7560975609756098 Loss: 0.40755970285600845\n",
      "7500. Accuracy: 0.8780487804878049 Loss: 0.4520731349506319\n",
      "7500. Accuracy: 0.7560975609756098 Loss: 0.42698782043910466\n",
      "8000. Accuracy: 0.8780487804878049 Loss: 0.2833013479535874\n",
      "8000. Accuracy: 0.7804878048780488 Loss: 0.46358115556526885\n",
      "8000. Accuracy: 0.9512195121951219 Loss: 0.29012008444190696\n",
      "8000. Accuracy: 0.7560975609756098 Loss: 0.39713601984546143\n",
      "8000. Accuracy: 0.8780487804878049 Loss: 0.4481600436292892\n",
      "8000. Accuracy: 0.7560975609756098 Loss: 0.42806843534407957\n",
      "8500. Accuracy: 0.9024390243902439 Loss: 0.2798726564326014\n",
      "8500. Accuracy: 0.7560975609756098 Loss: 0.4597429733820852\n",
      "8500. Accuracy: 0.9512195121951219 Loss: 0.2893431292949531\n",
      "8500. Accuracy: 0.7560975609756098 Loss: 0.39156832127176305\n",
      "8500. Accuracy: 0.8780487804878049 Loss: 0.44500048840695505\n",
      "8500. Accuracy: 0.7317073170731707 Loss: 0.4286753086534952\n",
      "9000. Accuracy: 0.9024390243902439 Loss: 0.2760024041219203\n",
      "9000. Accuracy: 0.7560975609756098 Loss: 0.45664900627285804\n",
      "9000. Accuracy: 0.9512195121951219 Loss: 0.2875085661233885\n",
      "9000. Accuracy: 0.7804878048780488 Loss: 0.38442145157549995\n",
      "9000. Accuracy: 0.8780487804878049 Loss: 0.4419681935736102\n",
      "9000. Accuracy: 0.7317073170731707 Loss: 0.4295254254027458\n",
      "9500. Accuracy: 0.9024390243902439 Loss: 0.27418783792502954\n",
      "9500. Accuracy: 0.7560975609756098 Loss: 0.4528801859835247\n",
      "9500. Accuracy: 0.9512195121951219 Loss: 0.28358843964730296\n",
      "9500. Accuracy: 0.7804878048780488 Loss: 0.3769813637275611\n",
      "9500. Accuracy: 0.8780487804878049 Loss: 0.4370095883349145\n",
      "9500. Accuracy: 0.7317073170731707 Loss: 0.43149208325924027\n",
      "10000. Accuracy: 0.9024390243902439 Loss: 0.2709205160228588\n",
      "10000. Accuracy: 0.7560975609756098 Loss: 0.4498277357666116\n",
      "10000. Accuracy: 0.9512195121951219 Loss: 0.28150028006705785\n",
      "10000. Accuracy: 0.7804878048780488 Loss: 0.37054333679479146\n",
      "10000. Accuracy: 0.8780487804878049 Loss: 0.43435638535642407\n",
      "10000. Accuracy: 0.7560975609756098 Loss: 0.4328660501298769\n",
      "10500. Accuracy: 0.9024390243902439 Loss: 0.2678277448650421\n",
      "10500. Accuracy: 0.7804878048780488 Loss: 0.4476633031153224\n",
      "10500. Accuracy: 0.9512195121951219 Loss: 0.2807495217167495\n",
      "10500. Accuracy: 0.7804878048780488 Loss: 0.3646038627852744\n",
      "10500. Accuracy: 0.8536585365853658 Loss: 0.4320126510862008\n",
      "10500. Accuracy: 0.7317073170731707 Loss: 0.4342307454386656\n",
      "11000. Accuracy: 0.9024390243902439 Loss: 0.2658158373950629\n",
      "11000. Accuracy: 0.7804878048780488 Loss: 0.4450597057069474\n",
      "11000. Accuracy: 0.9512195121951219 Loss: 0.27785624242631135\n",
      "11000. Accuracy: 0.7804878048780488 Loss: 0.3585686402754553\n",
      "11000. Accuracy: 0.8536585365853658 Loss: 0.42959655125032475\n",
      "11000. Accuracy: 0.7317073170731707 Loss: 0.4354549793028204\n",
      "11500. Accuracy: 0.9024390243902439 Loss: 0.2628195380654916\n",
      "11500. Accuracy: 0.7804878048780488 Loss: 0.44320993418031307\n",
      "11500. Accuracy: 0.9512195121951219 Loss: 0.2745348177466723\n",
      "11500. Accuracy: 0.7560975609756098 Loss: 0.351203563528189\n",
      "11500. Accuracy: 0.8292682926829268 Loss: 0.4276392379495328\n",
      "11500. Accuracy: 0.7317073170731707 Loss: 0.4362060315608665\n",
      "12000. Accuracy: 0.9024390243902439 Loss: 0.2591013742990904\n",
      "12000. Accuracy: 0.7804878048780488 Loss: 0.44255256026609646\n",
      "12000. Accuracy: 0.926829268292683 Loss: 0.27352068525877926\n",
      "12000. Accuracy: 0.7560975609756098 Loss: 0.3449159055759474\n",
      "12000. Accuracy: 0.8292682926829268 Loss: 0.4245654098133467\n",
      "12000. Accuracy: 0.7317073170731707 Loss: 0.4356588335138375\n",
      "12500. Accuracy: 0.9024390243902439 Loss: 0.2569927855304651\n",
      "12500. Accuracy: 0.7804878048780488 Loss: 0.4406636105422978\n",
      "12500. Accuracy: 0.926829268292683 Loss: 0.26952134789482446\n",
      "12500. Accuracy: 0.7560975609756098 Loss: 0.33711429108491797\n",
      "12500. Accuracy: 0.8292682926829268 Loss: 0.42296217775137374\n",
      "12500. Accuracy: 0.7317073170731707 Loss: 0.4383718483914708\n",
      "13000. Accuracy: 0.9024390243902439 Loss: 0.2541940998598102\n",
      "13000. Accuracy: 0.7804878048780488 Loss: 0.4399297461116862\n",
      "13000. Accuracy: 0.926829268292683 Loss: 0.26847025071666475\n",
      "13000. Accuracy: 0.7560975609756098 Loss: 0.33170358813869205\n",
      "13000. Accuracy: 0.8292682926829268 Loss: 0.42074939936671396\n",
      "13000. Accuracy: 0.7317073170731707 Loss: 0.4389413959345372\n",
      "13500. Accuracy: 0.9024390243902439 Loss: 0.25080389112236523\n",
      "13500. Accuracy: 0.7804878048780488 Loss: 0.4393245411998883\n",
      "13500. Accuracy: 0.926829268292683 Loss: 0.2666650913407849\n",
      "13500. Accuracy: 0.7560975609756098 Loss: 0.32615188071985013\n",
      "13500. Accuracy: 0.8292682926829268 Loss: 0.4192609865714159\n",
      "13500. Accuracy: 0.7317073170731707 Loss: 0.440189136494243\n",
      "14000. Accuracy: 0.9024390243902439 Loss: 0.24926272914368391\n",
      "14000. Accuracy: 0.7804878048780488 Loss: 0.43787442953927846\n",
      "14000. Accuracy: 0.926829268292683 Loss: 0.2624057519735152\n",
      "14000. Accuracy: 0.7560975609756098 Loss: 0.31970129704699596\n",
      "14000. Accuracy: 0.8292682926829268 Loss: 0.41815478084990443\n",
      "14000. Accuracy: 0.7317073170731707 Loss: 0.44163776761235923\n",
      "14500. Accuracy: 0.9024390243902439 Loss: 0.24616036467052715\n",
      "14500. Accuracy: 0.7804878048780488 Loss: 0.4373352257153524\n",
      "14500. Accuracy: 0.9512195121951219 Loss: 0.26083074700091136\n",
      "14500. Accuracy: 0.7804878048780488 Loss: 0.3139143487425854\n",
      "14500. Accuracy: 0.8292682926829268 Loss: 0.41777974158219794\n",
      "14500. Accuracy: 0.7317073170731707 Loss: 0.441643945649554\n",
      "15000. Accuracy: 0.9024390243902439 Loss: 0.2423622671750566\n",
      "15000. Accuracy: 0.7560975609756098 Loss: 0.43700839446457007\n",
      "15000. Accuracy: 0.9512195121951219 Loss: 0.2596458914542449\n",
      "15000. Accuracy: 0.7804878048780488 Loss: 0.3087867936312262\n",
      "15000. Accuracy: 0.8292682926829268 Loss: 0.4167111428498828\n",
      "15000. Accuracy: 0.7317073170731707 Loss: 0.43873220913035726\n",
      "15500. Accuracy: 0.9024390243902439 Loss: 0.23934413435526236\n",
      "15500. Accuracy: 0.7560975609756098 Loss: 0.43899908272873106\n",
      "15500. Accuracy: 0.9512195121951219 Loss: 0.25765072185949095\n",
      "15500. Accuracy: 0.7804878048780488 Loss: 0.30487326863401826\n",
      "15500. Accuracy: 0.8292682926829268 Loss: 0.41560609387228886\n",
      "15500. Accuracy: 0.7804878048780488 Loss: 0.4353811131431159\n",
      "16000. Accuracy: 0.9024390243902439 Loss: 0.2356048253803698\n",
      "16000. Accuracy: 0.7560975609756098 Loss: 0.4428041050926701\n",
      "16000. Accuracy: 0.9512195121951219 Loss: 0.2566591821384833\n",
      "16000. Accuracy: 0.8048780487804879 Loss: 0.30071552832552717\n",
      "16000. Accuracy: 0.8536585365853658 Loss: 0.41281965852288477\n",
      "16000. Accuracy: 0.7804878048780488 Loss: 0.4334938288802485\n",
      "16500. Accuracy: 0.9024390243902439 Loss: 0.23370830215520522\n",
      "16500. Accuracy: 0.7560975609756098 Loss: 0.44403160432092875\n",
      "16500. Accuracy: 0.9512195121951219 Loss: 0.25221984889123344\n",
      "16500. Accuracy: 0.8048780487804879 Loss: 0.29588019050457903\n",
      "16500. Accuracy: 0.8536585365853658 Loss: 0.4109435710359128\n",
      "16500. Accuracy: 0.8048780487804879 Loss: 0.4349087092165948\n",
      "17000. Accuracy: 0.9024390243902439 Loss: 0.23195760130148257\n",
      "17000. Accuracy: 0.7560975609756098 Loss: 0.44482081574624865\n",
      "17000. Accuracy: 0.9512195121951219 Loss: 0.2488460374480217\n",
      "17000. Accuracy: 0.8292682926829268 Loss: 0.2906468696873917\n",
      "17000. Accuracy: 0.8292682926829268 Loss: 0.4102945294103869\n",
      "17000. Accuracy: 0.8048780487804879 Loss: 0.43564202949041286\n",
      "17500. Accuracy: 0.9024390243902439 Loss: 0.23258883720363682\n",
      "17500. Accuracy: 0.7804878048780488 Loss: 0.44454391647843455\n",
      "17500. Accuracy: 0.9512195121951219 Loss: 0.2458206551623443\n",
      "17500. Accuracy: 0.8292682926829268 Loss: 0.2878779536754419\n",
      "17500. Accuracy: 0.8292682926829268 Loss: 0.4079628250173771\n",
      "17500. Accuracy: 0.8048780487804879 Loss: 0.43379111882435006\n",
      "18000. Accuracy: 0.9024390243902439 Loss: 0.23426595262834266\n",
      "18000. Accuracy: 0.7804878048780488 Loss: 0.44474199420289384\n",
      "18000. Accuracy: 0.9512195121951219 Loss: 0.24376146565281093\n",
      "18000. Accuracy: 0.8292682926829268 Loss: 0.2882009098175975\n",
      "18000. Accuracy: 0.8292682926829268 Loss: 0.4031225181910186\n",
      "18000. Accuracy: 0.7804878048780488 Loss: 0.4347735936661412\n",
      "18500. Accuracy: 0.9024390243902439 Loss: 0.23730430882190676\n",
      "18500. Accuracy: 0.7560975609756098 Loss: 0.4420940576550576\n",
      "18500. Accuracy: 0.9512195121951219 Loss: 0.238662921471307\n",
      "18500. Accuracy: 0.8292682926829268 Loss: 0.28819149466427146\n",
      "18500. Accuracy: 0.8292682926829268 Loss: 0.39505614723262067\n",
      "18500. Accuracy: 0.8048780487804879 Loss: 0.4360280185170086\n",
      "19000. Accuracy: 0.8780487804878049 Loss: 0.23717070543215535\n",
      "19000. Accuracy: 0.7560975609756098 Loss: 0.44114681686259594\n",
      "19000. Accuracy: 0.9512195121951219 Loss: 0.2345483722628018\n",
      "19000. Accuracy: 0.8292682926829268 Loss: 0.28765287871592676\n",
      "19000. Accuracy: 0.8292682926829268 Loss: 0.3906794742433317\n",
      "19000. Accuracy: 0.8048780487804879 Loss: 0.4386774729056812\n",
      "19500. Accuracy: 0.9024390243902439 Loss: 0.23746663037850893\n",
      "19500. Accuracy: 0.7560975609756098 Loss: 0.4420758586665051\n",
      "19500. Accuracy: 0.9512195121951219 Loss: 0.2303825719530016\n",
      "19500. Accuracy: 0.8292682926829268 Loss: 0.28355206909041164\n",
      "19500. Accuracy: 0.8292682926829268 Loss: 0.3868309982554264\n",
      "19500. Accuracy: 0.8048780487804879 Loss: 0.4387506757329301\n",
      "20000. Accuracy: 0.9024390243902439 Loss: 0.23836448288665332\n",
      "20000. Accuracy: 0.7560975609756098 Loss: 0.4388673179788381\n",
      "20000. Accuracy: 0.9512195121951219 Loss: 0.22895013347823562\n",
      "20000. Accuracy: 0.8292682926829268 Loss: 0.2794032921819271\n",
      "20000. Accuracy: 0.8292682926829268 Loss: 0.38575854729262155\n",
      "20000. Accuracy: 0.8048780487804879 Loss: 0.4426759407684636\n",
      "20500. Accuracy: 0.8780487804878049 Loss: 0.23892616306182948\n",
      "20500. Accuracy: 0.7560975609756098 Loss: 0.4339361246240548\n",
      "20500. Accuracy: 0.9512195121951219 Loss: 0.22860301403231803\n",
      "20500. Accuracy: 0.8292682926829268 Loss: 0.2783561293627611\n",
      "20500. Accuracy: 0.8292682926829268 Loss: 0.38494359146480633\n",
      "20500. Accuracy: 0.8048780487804879 Loss: 0.44384491647766827\n",
      "21000. Accuracy: 0.9024390243902439 Loss: 0.23764116608529098\n",
      "21000. Accuracy: 0.7804878048780488 Loss: 0.43029318359806357\n",
      "21000. Accuracy: 0.9512195121951219 Loss: 0.2268090982053558\n",
      "21000. Accuracy: 0.8292682926829268 Loss: 0.2764898133381085\n",
      "21000. Accuracy: 0.8292682926829268 Loss: 0.38621977308397215\n",
      "21000. Accuracy: 0.8048780487804879 Loss: 0.450234169018662\n",
      "21500. Accuracy: 0.9024390243902439 Loss: 0.23833528954902342\n",
      "21500. Accuracy: 0.7804878048780488 Loss: 0.42575921415897133\n",
      "21500. Accuracy: 0.9512195121951219 Loss: 0.22326285679764052\n",
      "21500. Accuracy: 0.8780487804878049 Loss: 0.2736849435768063\n",
      "21500. Accuracy: 0.8292682926829268 Loss: 0.38789456514635456\n",
      "21500. Accuracy: 0.8048780487804879 Loss: 0.45481210844258557\n",
      "22000. Accuracy: 0.9024390243902439 Loss: 0.23986695286311552\n",
      "22000. Accuracy: 0.7804878048780488 Loss: 0.4200713497774532\n",
      "22000. Accuracy: 0.9512195121951219 Loss: 0.21843497752315252\n",
      "22000. Accuracy: 0.9024390243902439 Loss: 0.27029280038641157\n",
      "22000. Accuracy: 0.8292682926829268 Loss: 0.3889809329421841\n",
      "22000. Accuracy: 0.8048780487804879 Loss: 0.4613755542070899\n",
      "22500. Accuracy: 0.9024390243902439 Loss: 0.23785703010838613\n",
      "22500. Accuracy: 0.7804878048780488 Loss: 0.41381870424539635\n",
      "22500. Accuracy: 0.975609756097561 Loss: 0.21707509220012103\n",
      "22500. Accuracy: 0.926829268292683 Loss: 0.2692006021337385\n",
      "22500. Accuracy: 0.8292682926829268 Loss: 0.3896410900644868\n",
      "22500. Accuracy: 0.7560975609756098 Loss: 0.4633459684307478\n",
      "23000. Accuracy: 0.9024390243902439 Loss: 0.22837101503776866\n",
      "23000. Accuracy: 0.8048780487804879 Loss: 0.41194292866611104\n",
      "23000. Accuracy: 0.975609756097561 Loss: 0.2189982168642462\n",
      "23000. Accuracy: 0.8780487804878049 Loss: 0.27170113335281626\n",
      "23000. Accuracy: 0.8292682926829268 Loss: 0.3914674554134417\n",
      "23000. Accuracy: 0.7560975609756098 Loss: 0.45818578330604515\n",
      "23500. Accuracy: 0.9024390243902439 Loss: 0.22656222405581708\n",
      "23500. Accuracy: 0.8048780487804879 Loss: 0.40806655867729413\n",
      "23500. Accuracy: 0.975609756097561 Loss: 0.21385144903846484\n",
      "23500. Accuracy: 0.8780487804878049 Loss: 0.27191048739264656\n",
      "23500. Accuracy: 0.8292682926829268 Loss: 0.388213006448834\n",
      "23500. Accuracy: 0.8048780487804879 Loss: 0.4504939165559998\n",
      "24000. Accuracy: 0.9024390243902439 Loss: 0.22555634821131035\n",
      "24000. Accuracy: 0.8048780487804879 Loss: 0.408045660018976\n",
      "24000. Accuracy: 0.975609756097561 Loss: 0.2099817669063693\n",
      "24000. Accuracy: 0.8780487804878049 Loss: 0.27011086139041685\n",
      "24000. Accuracy: 0.8292682926829268 Loss: 0.3847562129737837\n",
      "24000. Accuracy: 0.8048780487804879 Loss: 0.4413936741642746\n",
      "24500. Accuracy: 0.9024390243902439 Loss: 0.2245180737638225\n",
      "24500. Accuracy: 0.8048780487804879 Loss: 0.4103902693307012\n",
      "24500. Accuracy: 0.975609756097561 Loss: 0.2083763745441875\n",
      "24500. Accuracy: 0.8780487804878049 Loss: 0.2688905332909952\n",
      "24500. Accuracy: 0.8292682926829268 Loss: 0.38137481280690577\n",
      "24500. Accuracy: 0.7804878048780488 Loss: 0.43838010297101826\n",
      "25000. Accuracy: 0.9024390243902439 Loss: 0.22493123401918982\n",
      "25000. Accuracy: 0.8048780487804879 Loss: 0.40950171423216775\n",
      "25000. Accuracy: 0.975609756097561 Loss: 0.20360148859341867\n",
      "25000. Accuracy: 0.8780487804878049 Loss: 0.26902890590033385\n",
      "25000. Accuracy: 0.8292682926829268 Loss: 0.37691512846933534\n",
      "25000. Accuracy: 0.7804878048780488 Loss: 0.43403693896314777\n",
      "25500. Accuracy: 0.9024390243902439 Loss: 0.22462113150191745\n",
      "25500. Accuracy: 0.8048780487804879 Loss: 0.4103207671305844\n",
      "25500. Accuracy: 0.975609756097561 Loss: 0.20309878612815332\n",
      "25500. Accuracy: 0.8780487804878049 Loss: 0.2712091771546256\n",
      "25500. Accuracy: 0.8292682926829268 Loss: 0.3725455241783746\n",
      "25500. Accuracy: 0.8048780487804879 Loss: 0.4324552122968381\n",
      "26000. Accuracy: 0.9024390243902439 Loss: 0.22305081130550553\n",
      "26000. Accuracy: 0.8048780487804879 Loss: 0.4135728410969836\n",
      "26000. Accuracy: 0.975609756097561 Loss: 0.20579736087260359\n",
      "26000. Accuracy: 0.8780487804878049 Loss: 0.2709412975903324\n",
      "26000. Accuracy: 0.8536585365853658 Loss: 0.36853847713808013\n",
      "26000. Accuracy: 0.8048780487804879 Loss: 0.4327512132187128\n",
      "26500. Accuracy: 0.9024390243902439 Loss: 0.22240609221758936\n",
      "26500. Accuracy: 0.8048780487804879 Loss: 0.4155364590011607\n",
      "26500. Accuracy: 0.975609756097561 Loss: 0.2049501054630124\n",
      "26500. Accuracy: 0.8780487804878049 Loss: 0.26814759215311046\n",
      "26500. Accuracy: 0.8780487804878049 Loss: 0.36313629413702114\n",
      "26500. Accuracy: 0.8048780487804879 Loss: 0.43101155211640263\n",
      "27000. Accuracy: 0.9024390243902439 Loss: 0.22185156620946114\n",
      "27000. Accuracy: 0.8048780487804879 Loss: 0.4180718267000533\n",
      "27000. Accuracy: 0.975609756097561 Loss: 0.20214131590543147\n",
      "27000. Accuracy: 0.8780487804878049 Loss: 0.264263139658131\n",
      "27000. Accuracy: 0.8780487804878049 Loss: 0.36056558557336704\n",
      "27000. Accuracy: 0.8048780487804879 Loss: 0.429475279710094\n",
      "27500. Accuracy: 0.9024390243902439 Loss: 0.22144082107925833\n",
      "27500. Accuracy: 0.8048780487804879 Loss: 0.4192148986346964\n",
      "27500. Accuracy: 0.975609756097561 Loss: 0.203195719223927\n",
      "27500. Accuracy: 0.9024390243902439 Loss: 0.2607947839841865\n",
      "27500. Accuracy: 0.8780487804878049 Loss: 0.3573921357603027\n",
      "27500. Accuracy: 0.8048780487804879 Loss: 0.42825095440437416\n",
      "28000. Accuracy: 0.9024390243902439 Loss: 0.22003451500413515\n",
      "28000. Accuracy: 0.8048780487804879 Loss: 0.41769089712689134\n",
      "28000. Accuracy: 0.9512195121951219 Loss: 0.20125731731128488\n",
      "28000. Accuracy: 0.8780487804878049 Loss: 0.2573226452022975\n",
      "28000. Accuracy: 0.8780487804878049 Loss: 0.35558188436382665\n",
      "28000. Accuracy: 0.8292682926829268 Loss: 0.42869636366032826\n",
      "28500. Accuracy: 0.9024390243902439 Loss: 0.2188000634984578\n",
      "28500. Accuracy: 0.7804878048780488 Loss: 0.4156112698778099\n",
      "28500. Accuracy: 0.9512195121951219 Loss: 0.19778740318888471\n",
      "28500. Accuracy: 0.8780487804878049 Loss: 0.2537629704448162\n",
      "28500. Accuracy: 0.8780487804878049 Loss: 0.3550593015681197\n",
      "28500. Accuracy: 0.8292682926829268 Loss: 0.43558113564746515\n",
      "29000. Accuracy: 0.9024390243902439 Loss: 0.21890410823595535\n",
      "29000. Accuracy: 0.8048780487804879 Loss: 0.41410741837553894\n",
      "29000. Accuracy: 0.9512195121951219 Loss: 0.19325159233477354\n",
      "29000. Accuracy: 0.8780487804878049 Loss: 0.2498041271928135\n",
      "29000. Accuracy: 0.8780487804878049 Loss: 0.3536694976823577\n",
      "29000. Accuracy: 0.8292682926829268 Loss: 0.43781931274150754\n",
      "29500. Accuracy: 0.9024390243902439 Loss: 0.21904790106427016\n",
      "29500. Accuracy: 0.8048780487804879 Loss: 0.41394528897625327\n",
      "29500. Accuracy: 0.9512195121951219 Loss: 0.1912574328987963\n",
      "29500. Accuracy: 0.8780487804878049 Loss: 0.24767358853926635\n",
      "29500. Accuracy: 0.8780487804878049 Loss: 0.3535104003569381\n",
      "29500. Accuracy: 0.8292682926829268 Loss: 0.43617536783981364\n",
      "30000. Accuracy: 0.9024390243902439 Loss: 0.21872229217815306\n",
      "30000. Accuracy: 0.8048780487804879 Loss: 0.41382623224517634\n",
      "30000. Accuracy: 0.9512195121951219 Loss: 0.18821350634414782\n",
      "30000. Accuracy: 0.8780487804878049 Loss: 0.24659437067738216\n",
      "30000. Accuracy: 0.8780487804878049 Loss: 0.35558119896242807\n",
      "30000. Accuracy: 0.8292682926829268 Loss: 0.4347485230645333\n",
      "30500. Accuracy: 0.9024390243902439 Loss: 0.2184777182203198\n",
      "30500. Accuracy: 0.8048780487804879 Loss: 0.41259108892668933\n",
      "30500. Accuracy: 0.9512195121951219 Loss: 0.1860513980192017\n",
      "30500. Accuracy: 0.8780487804878049 Loss: 0.24562445773628405\n",
      "30500. Accuracy: 0.8780487804878049 Loss: 0.3563306519022571\n",
      "30500. Accuracy: 0.8292682926829268 Loss: 0.4364324905193531\n",
      "31000. Accuracy: 0.9024390243902439 Loss: 0.21863418610398608\n",
      "31000. Accuracy: 0.8048780487804879 Loss: 0.4118595646070804\n",
      "31000. Accuracy: 0.975609756097561 Loss: 0.1826613596665368\n",
      "31000. Accuracy: 0.9024390243902439 Loss: 0.24540608745616177\n",
      "31000. Accuracy: 0.8292682926829268 Loss: 0.36003869094599095\n",
      "31000. Accuracy: 0.8292682926829268 Loss: 0.4383499255024131\n",
      "31500. Accuracy: 0.9024390243902439 Loss: 0.2163073718763783\n",
      "31500. Accuracy: 0.8292682926829268 Loss: 0.41043869589429266\n",
      "31500. Accuracy: 0.975609756097561 Loss: 0.1809344050227739\n",
      "31500. Accuracy: 0.9024390243902439 Loss: 0.244103747607198\n",
      "31500. Accuracy: 0.8292682926829268 Loss: 0.36083389691945766\n",
      "31500. Accuracy: 0.8292682926829268 Loss: 0.4379596254041299\n",
      "32000. Accuracy: 0.9024390243902439 Loss: 0.21485218931696037\n",
      "32000. Accuracy: 0.8292682926829268 Loss: 0.40843485197373025\n",
      "32000. Accuracy: 0.975609756097561 Loss: 0.17903351723177355\n",
      "32000. Accuracy: 0.9024390243902439 Loss: 0.24222818072946828\n",
      "32000. Accuracy: 0.8292682926829268 Loss: 0.3611316711097182\n",
      "32000. Accuracy: 0.8292682926829268 Loss: 0.43819729980017424\n",
      "32500. Accuracy: 0.9024390243902439 Loss: 0.21291877084247463\n",
      "32500. Accuracy: 0.8292682926829268 Loss: 0.4079491747304478\n",
      "32500. Accuracy: 0.975609756097561 Loss: 0.17910151098184743\n",
      "32500. Accuracy: 0.9024390243902439 Loss: 0.23952395575548857\n",
      "32500. Accuracy: 0.8292682926829268 Loss: 0.3598960570734818\n",
      "32500. Accuracy: 0.8292682926829268 Loss: 0.43756747632721416\n",
      "33000. Accuracy: 0.9024390243902439 Loss: 0.21218574023595485\n",
      "33000. Accuracy: 0.8292682926829268 Loss: 0.40615634348353236\n",
      "33000. Accuracy: 0.975609756097561 Loss: 0.17836354621759487\n",
      "33000. Accuracy: 0.9024390243902439 Loss: 0.23772396484578528\n",
      "33000. Accuracy: 0.8292682926829268 Loss: 0.35914632153072334\n",
      "33000. Accuracy: 0.8292682926829268 Loss: 0.4398462649767795\n",
      "33500. Accuracy: 0.9024390243902439 Loss: 0.21059664743098866\n",
      "33500. Accuracy: 0.8292682926829268 Loss: 0.40608077515977986\n",
      "33500. Accuracy: 0.975609756097561 Loss: 0.1805268145411362\n",
      "33500. Accuracy: 0.9024390243902439 Loss: 0.2381965844150437\n",
      "33500. Accuracy: 0.8292682926829268 Loss: 0.35615469134044225\n",
      "33500. Accuracy: 0.8292682926829268 Loss: 0.43840683161411675\n",
      "34000. Accuracy: 0.9024390243902439 Loss: 0.2103603623633854\n",
      "34000. Accuracy: 0.8292682926829268 Loss: 0.40444194681900064\n",
      "34000. Accuracy: 0.975609756097561 Loss: 0.1825360379722421\n",
      "34000. Accuracy: 0.9024390243902439 Loss: 0.23822812195646154\n",
      "34000. Accuracy: 0.8536585365853658 Loss: 0.35340138061292853\n",
      "34000. Accuracy: 0.8292682926829268 Loss: 0.43562008612422726\n",
      "34500. Accuracy: 0.9024390243902439 Loss: 0.20888518242583876\n",
      "34500. Accuracy: 0.8292682926829268 Loss: 0.40492750910552555\n",
      "34500. Accuracy: 0.975609756097561 Loss: 0.18400435300172963\n",
      "34500. Accuracy: 0.9024390243902439 Loss: 0.23833200350326178\n",
      "34500. Accuracy: 0.8536585365853658 Loss: 0.3498838042730295\n",
      "34500. Accuracy: 0.8292682926829268 Loss: 0.43240381493044516\n",
      "35000. Accuracy: 0.9024390243902439 Loss: 0.20841537103689867\n",
      "35000. Accuracy: 0.8292682926829268 Loss: 0.4042845640638847\n",
      "35000. Accuracy: 0.975609756097561 Loss: 0.18357343017349717\n",
      "35000. Accuracy: 0.9024390243902439 Loss: 0.2384320346831021\n",
      "35000. Accuracy: 0.8536585365853658 Loss: 0.3466690657068578\n",
      "35000. Accuracy: 0.8292682926829268 Loss: 0.4322956429386419\n",
      "35500. Accuracy: 0.9024390243902439 Loss: 0.20759994997152756\n",
      "35500. Accuracy: 0.8292682926829268 Loss: 0.4038842715800495\n",
      "35500. Accuracy: 0.975609756097561 Loss: 0.18258522150569784\n",
      "35500. Accuracy: 0.8780487804878049 Loss: 0.23873276816935105\n",
      "35500. Accuracy: 0.8536585365853658 Loss: 0.34311758855271346\n",
      "35500. Accuracy: 0.8292682926829268 Loss: 0.4308581209121451\n",
      "36000. Accuracy: 0.9024390243902439 Loss: 0.20719751111730295\n",
      "36000. Accuracy: 0.8292682926829268 Loss: 0.402501131938704\n",
      "36000. Accuracy: 0.9512195121951219 Loss: 0.18234981699821717\n",
      "36000. Accuracy: 0.8780487804878049 Loss: 0.24016610197293015\n",
      "36000. Accuracy: 0.8536585365853658 Loss: 0.34010124297141875\n",
      "36000. Accuracy: 0.8292682926829268 Loss: 0.43194968947311835\n",
      "36500. Accuracy: 0.9024390243902439 Loss: 0.20665035970443624\n",
      "36500. Accuracy: 0.8292682926829268 Loss: 0.40326817082628647\n",
      "36500. Accuracy: 0.9512195121951219 Loss: 0.18352227760774056\n",
      "36500. Accuracy: 0.8780487804878049 Loss: 0.2392793828120911\n",
      "36500. Accuracy: 0.8536585365853658 Loss: 0.3376617323020325\n",
      "36500. Accuracy: 0.8292682926829268 Loss: 0.43100414080273297\n",
      "37000. Accuracy: 0.9024390243902439 Loss: 0.20620255693988415\n",
      "37000. Accuracy: 0.8048780487804879 Loss: 0.40493148166748766\n",
      "37000. Accuracy: 0.9512195121951219 Loss: 0.18382775006270907\n",
      "37000. Accuracy: 0.8780487804878049 Loss: 0.23946293109049602\n",
      "37000. Accuracy: 0.8536585365853658 Loss: 0.33620617102593076\n",
      "37000. Accuracy: 0.8292682926829268 Loss: 0.4286652586059726\n",
      "37500. Accuracy: 0.9024390243902439 Loss: 0.20742098429076533\n",
      "37500. Accuracy: 0.8048780487804879 Loss: 0.4060747053016118\n",
      "37500. Accuracy: 0.9512195121951219 Loss: 0.1834752343210034\n",
      "37500. Accuracy: 0.8536585365853658 Loss: 0.2387009730646903\n",
      "37500. Accuracy: 0.8536585365853658 Loss: 0.3357225420775544\n",
      "37500. Accuracy: 0.8292682926829268 Loss: 0.42556598962774916\n",
      "38000. Accuracy: 0.9024390243902439 Loss: 0.20834120265951925\n",
      "38000. Accuracy: 0.8048780487804879 Loss: 0.4056229233313178\n",
      "38000. Accuracy: 0.9512195121951219 Loss: 0.18287564507410137\n",
      "38000. Accuracy: 0.8536585365853658 Loss: 0.2381320134739419\n",
      "38000. Accuracy: 0.8536585365853658 Loss: 0.3351202711855526\n",
      "38000. Accuracy: 0.8292682926829268 Loss: 0.42242008717841223\n",
      "38500. Accuracy: 0.9024390243902439 Loss: 0.20837872122298853\n",
      "38500. Accuracy: 0.8048780487804879 Loss: 0.40255292861481473\n",
      "38500. Accuracy: 0.9512195121951219 Loss: 0.177854872809299\n",
      "38500. Accuracy: 0.8780487804878049 Loss: 0.23639621967034088\n",
      "38500. Accuracy: 0.8536585365853658 Loss: 0.33582762395091587\n",
      "38500. Accuracy: 0.8292682926829268 Loss: 0.42141707121307603\n",
      "39000. Accuracy: 0.9024390243902439 Loss: 0.20675981531326873\n",
      "39000. Accuracy: 0.8048780487804879 Loss: 0.4022799083169785\n",
      "39000. Accuracy: 0.9512195121951219 Loss: 0.17659757811492344\n",
      "39000. Accuracy: 0.8780487804878049 Loss: 0.23454220791844102\n",
      "39000. Accuracy: 0.8780487804878049 Loss: 0.3350888782857196\n",
      "39000. Accuracy: 0.8292682926829268 Loss: 0.4210219085332507\n",
      "39500. Accuracy: 0.9024390243902439 Loss: 0.20626396240294045\n",
      "39500. Accuracy: 0.8048780487804879 Loss: 0.40088228357378725\n",
      "39500. Accuracy: 0.9512195121951219 Loss: 0.17428626273159636\n",
      "39500. Accuracy: 0.8780487804878049 Loss: 0.23437929926746393\n",
      "39500. Accuracy: 0.8780487804878049 Loss: 0.33323871260533855\n",
      "39500. Accuracy: 0.8292682926829268 Loss: 0.41951076209878574\n",
      "40000. Accuracy: 0.9024390243902439 Loss: 0.20417251119749624\n",
      "40000. Accuracy: 0.8048780487804879 Loss: 0.39808909127112707\n",
      "40000. Accuracy: 0.9512195121951219 Loss: 0.17220431306805026\n",
      "40000. Accuracy: 0.8780487804878049 Loss: 0.23474454113016996\n",
      "40000. Accuracy: 0.8780487804878049 Loss: 0.3318459683429083\n",
      "40000. Accuracy: 0.8292682926829268 Loss: 0.4188900606154621\n",
      "40500. Accuracy: 0.9024390243902439 Loss: 0.201206800754091\n",
      "40500. Accuracy: 0.8048780487804879 Loss: 0.3971379113644906\n",
      "40500. Accuracy: 0.9512195121951219 Loss: 0.1746698964183217\n",
      "40500. Accuracy: 0.8780487804878049 Loss: 0.2344595789620144\n",
      "40500. Accuracy: 0.8780487804878049 Loss: 0.33061986046598696\n",
      "40500. Accuracy: 0.8292682926829268 Loss: 0.4159004045734364\n",
      "41000. Accuracy: 0.9024390243902439 Loss: 0.19929081595873321\n",
      "41000. Accuracy: 0.8048780487804879 Loss: 0.39778660523643217\n",
      "41000. Accuracy: 0.9512195121951219 Loss: 0.1752125451640728\n",
      "41000. Accuracy: 0.8780487804878049 Loss: 0.2329682201197042\n",
      "41000. Accuracy: 0.8780487804878049 Loss: 0.3309320554071121\n",
      "41000. Accuracy: 0.8292682926829268 Loss: 0.41542346582772155\n",
      "41500. Accuracy: 0.926829268292683 Loss: 0.19727374473980297\n",
      "41500. Accuracy: 0.8048780487804879 Loss: 0.40027426298762087\n",
      "41500. Accuracy: 0.975609756097561 Loss: 0.17699707374009233\n",
      "41500. Accuracy: 0.8780487804878049 Loss: 0.23102787399070532\n",
      "41500. Accuracy: 0.8780487804878049 Loss: 0.33079761735091606\n",
      "41500. Accuracy: 0.8292682926829268 Loss: 0.41448690632012025\n",
      "42000. Accuracy: 0.926829268292683 Loss: 0.19692104239819339\n",
      "42000. Accuracy: 0.7804878048780488 Loss: 0.3993339539053182\n",
      "42000. Accuracy: 0.975609756097561 Loss: 0.1763529232194263\n",
      "42000. Accuracy: 0.8780487804878049 Loss: 0.22948604770990366\n",
      "42000. Accuracy: 0.8536585365853658 Loss: 0.33067817614539136\n",
      "42000. Accuracy: 0.8292682926829268 Loss: 0.41728932542894764\n",
      "42500. Accuracy: 0.9024390243902439 Loss: 0.19709519058085656\n",
      "42500. Accuracy: 0.8048780487804879 Loss: 0.39737538602130645\n",
      "42500. Accuracy: 0.975609756097561 Loss: 0.17380998732876174\n",
      "42500. Accuracy: 0.8780487804878049 Loss: 0.22814551003159744\n",
      "42500. Accuracy: 0.8536585365853658 Loss: 0.33255619203145836\n",
      "42500. Accuracy: 0.8292682926829268 Loss: 0.4188990420422758\n",
      "43000. Accuracy: 0.9024390243902439 Loss: 0.1971615074295553\n",
      "43000. Accuracy: 0.7804878048780488 Loss: 0.39718498980418526\n",
      "43000. Accuracy: 0.975609756097561 Loss: 0.17087433246501466\n",
      "43000. Accuracy: 0.8780487804878049 Loss: 0.22754608429947137\n",
      "43000. Accuracy: 0.8536585365853658 Loss: 0.33368060948362976\n",
      "43000. Accuracy: 0.8292682926829268 Loss: 0.418230165804339\n",
      "43500. Accuracy: 0.9024390243902439 Loss: 0.19677547282822716\n",
      "43500. Accuracy: 0.8048780487804879 Loss: 0.39591909695420163\n",
      "43500. Accuracy: 0.975609756097561 Loss: 0.16818990555581634\n",
      "43500. Accuracy: 0.9024390243902439 Loss: 0.2267184914106791\n",
      "43500. Accuracy: 0.8536585365853658 Loss: 0.3342699985936715\n",
      "43500. Accuracy: 0.8536585365853658 Loss: 0.41844031989556413\n",
      "44000. Accuracy: 0.9024390243902439 Loss: 0.1967769171941641\n",
      "44000. Accuracy: 0.8048780487804879 Loss: 0.3939567914963818\n",
      "44000. Accuracy: 0.975609756097561 Loss: 0.16599481967291063\n",
      "44000. Accuracy: 0.9024390243902439 Loss: 0.22509651300804756\n",
      "44000. Accuracy: 0.8536585365853658 Loss: 0.3341295210177353\n",
      "44000. Accuracy: 0.8536585365853658 Loss: 0.4179859672086103\n",
      "44500. Accuracy: 0.9024390243902439 Loss: 0.19586459579929344\n",
      "44500. Accuracy: 0.8048780487804879 Loss: 0.3942719792049099\n",
      "44500. Accuracy: 0.975609756097561 Loss: 0.16564571170825346\n",
      "44500. Accuracy: 0.9024390243902439 Loss: 0.2232243284194753\n",
      "44500. Accuracy: 0.8536585365853658 Loss: 0.3322681509308023\n",
      "44500. Accuracy: 0.8536585365853658 Loss: 0.4151783541982154\n",
      "45000. Accuracy: 0.9024390243902439 Loss: 0.19548957532163813\n",
      "45000. Accuracy: 0.8048780487804879 Loss: 0.3936103063958053\n",
      "45000. Accuracy: 0.975609756097561 Loss: 0.1645434333676446\n",
      "45000. Accuracy: 0.9024390243902439 Loss: 0.22139581617405954\n",
      "45000. Accuracy: 0.8536585365853658 Loss: 0.3314526528609743\n",
      "45000. Accuracy: 0.8536585365853658 Loss: 0.41315419859527736\n",
      "45500. Accuracy: 0.9024390243902439 Loss: 0.19605771447966408\n",
      "45500. Accuracy: 0.8048780487804879 Loss: 0.3913964512822669\n",
      "45500. Accuracy: 0.975609756097561 Loss: 0.16250237418065258\n",
      "45500. Accuracy: 0.9024390243902439 Loss: 0.2196408193038912\n",
      "45500. Accuracy: 0.8536585365853658 Loss: 0.3307582029367341\n",
      "45500. Accuracy: 0.8536585365853658 Loss: 0.41148683846100303\n",
      "46000. Accuracy: 0.9024390243902439 Loss: 0.1961325617644559\n",
      "46000. Accuracy: 0.8048780487804879 Loss: 0.3905240222346349\n",
      "46000. Accuracy: 0.975609756097561 Loss: 0.16164139853462084\n",
      "46000. Accuracy: 0.9024390243902439 Loss: 0.21765227176459476\n",
      "46000. Accuracy: 0.8536585365853658 Loss: 0.3299932667738432\n",
      "46000. Accuracy: 0.8536585365853658 Loss: 0.4100695229451086\n",
      "46500. Accuracy: 0.9024390243902439 Loss: 0.19597092961267912\n",
      "46500. Accuracy: 0.8048780487804879 Loss: 0.38978384969942\n",
      "46500. Accuracy: 0.975609756097561 Loss: 0.16161007523408644\n",
      "46500. Accuracy: 0.9024390243902439 Loss: 0.21625122851657383\n",
      "46500. Accuracy: 0.8536585365853658 Loss: 0.32847303347118745\n",
      "46500. Accuracy: 0.8536585365853658 Loss: 0.40852420765517\n",
      "47000. Accuracy: 0.9024390243902439 Loss: 0.1959627099186245\n",
      "47000. Accuracy: 0.8048780487804879 Loss: 0.3889798647958412\n",
      "47000. Accuracy: 0.975609756097561 Loss: 0.1605932627405728\n",
      "47000. Accuracy: 0.9024390243902439 Loss: 0.21472232217660422\n",
      "47000. Accuracy: 0.8536585365853658 Loss: 0.32760864099808\n",
      "47000. Accuracy: 0.8536585365853658 Loss: 0.40777971571361016\n",
      "47500. Accuracy: 0.9024390243902439 Loss: 0.19494802432287028\n",
      "47500. Accuracy: 0.8292682926829268 Loss: 0.38965346196212003\n",
      "47500. Accuracy: 0.975609756097561 Loss: 0.15987998274564172\n",
      "47500. Accuracy: 0.9024390243902439 Loss: 0.21416186594510292\n",
      "47500. Accuracy: 0.8536585365853658 Loss: 0.3258442314678444\n",
      "47500. Accuracy: 0.8536585365853658 Loss: 0.4050847674236917\n",
      "48000. Accuracy: 0.9024390243902439 Loss: 0.1941077382083982\n",
      "48000. Accuracy: 0.8292682926829268 Loss: 0.3901227722875594\n",
      "48000. Accuracy: 0.975609756097561 Loss: 0.1591772472908387\n",
      "48000. Accuracy: 0.9024390243902439 Loss: 0.21455982084455094\n",
      "48000. Accuracy: 0.8780487804878049 Loss: 0.32364590170054824\n",
      "48000. Accuracy: 0.8536585365853658 Loss: 0.40354012487026947\n",
      "48500. Accuracy: 0.926829268292683 Loss: 0.19301375722026395\n",
      "48500. Accuracy: 0.8292682926829268 Loss: 0.38980236090769144\n",
      "48500. Accuracy: 0.975609756097561 Loss: 0.15821691754021583\n",
      "48500. Accuracy: 0.9024390243902439 Loss: 0.21458402143457597\n",
      "48500. Accuracy: 0.8780487804878049 Loss: 0.3215858927332795\n",
      "48500. Accuracy: 0.8536585365853658 Loss: 0.40334134232893515\n",
      "49000. Accuracy: 0.926829268292683 Loss: 0.19154331983680326\n",
      "49000. Accuracy: 0.8292682926829268 Loss: 0.38965831971554576\n",
      "49000. Accuracy: 0.975609756097561 Loss: 0.1565787427423739\n",
      "49000. Accuracy: 0.9024390243902439 Loss: 0.21544404507730697\n",
      "49000. Accuracy: 0.8780487804878049 Loss: 0.3187384970742157\n",
      "49000. Accuracy: 0.8292682926829268 Loss: 0.3997439457641074\n",
      "49500. Accuracy: 0.926829268292683 Loss: 0.18861340399635157\n",
      "49500. Accuracy: 0.8048780487804879 Loss: 0.3911464547691555\n",
      "49500. Accuracy: 0.975609756097561 Loss: 0.15299344583383995\n",
      "49500. Accuracy: 0.9024390243902439 Loss: 0.2172999986228652\n",
      "49500. Accuracy: 0.9024390243902439 Loss: 0.3147974295791523\n",
      "49500. Accuracy: 0.8292682926829268 Loss: 0.3982097208062922\n"
     ]
    }
   ],
   "source": [
    "train = Train(network1b, learning_rate, batch_size, epochs, loss_function)\n",
    "cost, accuracies = train.train(inputs_train, outputs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "efae9859-4a6c-47d6-b9b1-9c78b66ff2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([a for a in range(len(cost))],cost)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d790bca-a4a1-439b-a44e-4b90c80b2eba",
   "metadata": {},
   "source": [
    "### c) change hidden_dim (batch size stays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "26fd06bd-47e3-45b7-a348-bd0504a26419",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 500\n",
    "network1c = NeuralNetwork(input_dim,\n",
    "                        hidden_dim,\n",
    "                        output_dim,\n",
    "                        num_of_hidden_layers,\n",
    "                        activation,\n",
    "                        activation_output,\n",
    "                        initialization,\n",
    "                        output_initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8a82cba9-8fd3-41e1-82d5-2aadb115a8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Accuracy: 0.5853658536585366 Loss: 6.432620161778941\n",
      "0. Accuracy: 0.5609756097560976 Loss: 6.954254758836192\n",
      "0. Accuracy: 0.7073170731707317 Loss: 4.354137841399346\n",
      "0. Accuracy: 0.6829268292682927 Loss: 4.769066337841388\n",
      "0. Accuracy: 0.6097560975609756 Loss: 6.289989337060559\n",
      "0. Accuracy: 0.6829268292682927 Loss: 5.110876652783145\n",
      "500. Accuracy: 0.5853658536585366 Loss: 3.8462464029198387\n",
      "500. Accuracy: 0.6829268292682927 Loss: 0.8875066069890911\n",
      "500. Accuracy: 0.8048780487804879 Loss: 0.3732868370870077\n",
      "500. Accuracy: 0.7560975609756098 Loss: 0.6895580367814014\n",
      "500. Accuracy: 0.6585365853658537 Loss: 0.8570940689590355\n",
      "500. Accuracy: 0.7073170731707317 Loss: 0.8092589240970197\n",
      "1000. Accuracy: 0.5853658536585366 Loss: 0.9681947709825555\n",
      "1000. Accuracy: 0.5609756097560976 Loss: 2.938927398994562\n",
      "1000. Accuracy: 0.34146341463414637 Loss: 2.230346920332984\n",
      "1000. Accuracy: 0.7073170731707317 Loss: 3.11549883727841\n",
      "1000. Accuracy: 0.6829268292682927 Loss: 1.1084704614192287\n",
      "1000. Accuracy: 0.43902439024390244 Loss: 2.077998527325296\n",
      "1500. Accuracy: 0.7804878048780488 Loss: 0.577975185100924\n",
      "1500. Accuracy: 0.5365853658536586 Loss: 0.7405959192338665\n",
      "1500. Accuracy: 0.7804878048780488 Loss: 0.6865253076707983\n",
      "1500. Accuracy: 0.7804878048780488 Loss: 0.4330075964032512\n",
      "1500. Accuracy: 0.6829268292682927 Loss: 0.6779030923237679\n",
      "1500. Accuracy: 0.5365853658536586 Loss: 1.1746365500755818\n",
      "2000. Accuracy: 0.7804878048780488 Loss: 0.44988400123206523\n",
      "2000. Accuracy: 0.6585365853658537 Loss: 1.6011278275736365\n",
      "2000. Accuracy: 0.3170731707317073 Loss: 2.1953596077475135\n",
      "2000. Accuracy: 0.7073170731707317 Loss: 2.684959167473905\n",
      "2000. Accuracy: 0.6829268292682927 Loss: 0.9086140974117588\n",
      "2000. Accuracy: 0.43902439024390244 Loss: 1.7993198035961273\n",
      "2500. Accuracy: 0.9512195121951219 Loss: 0.22256925776061864\n",
      "2500. Accuracy: 0.7073170731707317 Loss: 0.5499879529137777\n",
      "2500. Accuracy: 0.36585365853658536 Loss: 1.1322469967636932\n",
      "2500. Accuracy: 0.7073170731707317 Loss: 2.175784313095876\n",
      "2500. Accuracy: 0.6829268292682927 Loss: 0.6128106824905614\n",
      "2500. Accuracy: 0.5365853658536586 Loss: 1.086324740544307\n",
      "3000. Accuracy: 0.7073170731707317 Loss: 0.6880145709432863\n",
      "3000. Accuracy: 0.5853658536585366 Loss: 2.1341568369801287\n",
      "3000. Accuracy: 0.36585365853658536 Loss: 1.873161839464569\n",
      "3000. Accuracy: 0.7073170731707317 Loss: 2.339264149265903\n",
      "3000. Accuracy: 0.7073170731707317 Loss: 0.7304394541695175\n",
      "3000. Accuracy: 0.4634146341463415 Loss: 1.7016030067870005\n",
      "3500. Accuracy: 0.6585365853658537 Loss: 1.4384124633015951\n",
      "3500. Accuracy: 0.6097560975609756 Loss: 0.7644263253772343\n",
      "3500. Accuracy: 0.8048780487804879 Loss: 0.5050927266292633\n",
      "3500. Accuracy: 0.8780487804878049 Loss: 0.3146621627145829\n",
      "3500. Accuracy: 0.7560975609756098 Loss: 0.5014836026838613\n",
      "3500. Accuracy: 0.7804878048780488 Loss: 0.4600547290690619\n",
      "4000. Accuracy: 0.7317073170731707 Loss: 0.5854228637009657\n",
      "4000. Accuracy: 0.6341463414634146 Loss: 1.640161087653093\n",
      "4000. Accuracy: 0.3902439024390244 Loss: 1.3988678905970484\n",
      "4000. Accuracy: 0.7073170731707317 Loss: 1.853880275792788\n",
      "4000. Accuracy: 0.7560975609756098 Loss: 0.5323598213237405\n",
      "4000. Accuracy: 0.6341463414634146 Loss: 0.8848684660615046\n",
      "4500. Accuracy: 0.8048780487804879 Loss: 0.3823429016825313\n",
      "4500. Accuracy: 0.8048780487804879 Loss: 0.432886210805615\n",
      "4500. Accuracy: 0.975609756097561 Loss: 0.16487709060216027\n",
      "4500. Accuracy: 0.8048780487804879 Loss: 0.2932054468329389\n",
      "4500. Accuracy: 0.7560975609756098 Loss: 0.498526469771922\n",
      "4500. Accuracy: 0.7804878048780488 Loss: 0.6516498545980912\n",
      "5000. Accuracy: 0.7317073170731707 Loss: 0.7001490736356829\n",
      "5000. Accuracy: 0.7804878048780488 Loss: 0.5298506184130585\n",
      "5000. Accuracy: 0.8780487804878049 Loss: 0.1966047136438758\n",
      "5000. Accuracy: 0.9024390243902439 Loss: 0.24950530593212558\n",
      "5000. Accuracy: 0.8048780487804879 Loss: 0.4322082616649659\n",
      "5000. Accuracy: 0.7560975609756098 Loss: 0.5608972037640556\n",
      "5500. Accuracy: 0.7560975609756098 Loss: 0.5177177310339347\n",
      "5500. Accuracy: 0.8048780487804879 Loss: 0.45051388506158235\n",
      "5500. Accuracy: 0.9512195121951219 Loss: 0.12820909013657775\n",
      "5500. Accuracy: 0.9024390243902439 Loss: 0.24018819172466013\n",
      "5500. Accuracy: 0.8048780487804879 Loss: 0.4084917075867792\n",
      "5500. Accuracy: 0.7560975609756098 Loss: 0.48222886293352935\n",
      "6000. Accuracy: 0.7317073170731707 Loss: 0.581874858503904\n",
      "6000. Accuracy: 0.6097560975609756 Loss: 1.4072724235104894\n",
      "6000. Accuracy: 0.3902439024390244 Loss: 1.2309254062106836\n",
      "6000. Accuracy: 0.7317073170731707 Loss: 1.4435965753203375\n",
      "6000. Accuracy: 0.8048780487804879 Loss: 0.41577996941292983\n",
      "6000. Accuracy: 0.7317073170731707 Loss: 0.5069263469499354\n",
      "6500. Accuracy: 0.7560975609756098 Loss: 0.5038338866214507\n",
      "6500. Accuracy: 0.6097560975609756 Loss: 1.2071906245272215\n",
      "6500. Accuracy: 0.43902439024390244 Loss: 1.0780473543131583\n",
      "6500. Accuracy: 0.7317073170731707 Loss: 1.2366393703638137\n",
      "6500. Accuracy: 0.8536585365853658 Loss: 0.4105267720231383\n",
      "6500. Accuracy: 0.8048780487804879 Loss: 0.4160371746114937\n",
      "7000. Accuracy: 0.8048780487804879 Loss: 0.3948732201972249\n",
      "7000. Accuracy: 0.6829268292682927 Loss: 0.9628951345468063\n",
      "7000. Accuracy: 0.6341463414634146 Loss: 0.8457671195042106\n",
      "7000. Accuracy: 0.7560975609756098 Loss: 0.9709936118987148\n",
      "7000. Accuracy: 0.8048780487804879 Loss: 0.42447503238396767\n",
      "7000. Accuracy: 0.8292682926829268 Loss: 0.41240678863285657\n",
      "7500. Accuracy: 0.8536585365853658 Loss: 0.28000632768423245\n",
      "7500. Accuracy: 0.7317073170731707 Loss: 0.7271286132595105\n",
      "7500. Accuracy: 0.6829268292682927 Loss: 0.5993917870447519\n",
      "7500. Accuracy: 0.7560975609756098 Loss: 0.6780131289906083\n",
      "7500. Accuracy: 0.7317073170731707 Loss: 0.4697156476124094\n",
      "7500. Accuracy: 0.8048780487804879 Loss: 0.4883147359053887\n",
      "8000. Accuracy: 0.8780487804878049 Loss: 0.2554890890535375\n",
      "8000. Accuracy: 0.7804878048780488 Loss: 0.6572195705218886\n",
      "8000. Accuracy: 0.7560975609756098 Loss: 0.503099935634626\n",
      "8000. Accuracy: 0.7560975609756098 Loss: 0.5510584002406839\n",
      "8000. Accuracy: 0.7560975609756098 Loss: 0.4624803588006274\n",
      "8000. Accuracy: 0.8048780487804879 Loss: 0.4758927213544815\n",
      "8500. Accuracy: 0.8780487804878049 Loss: 0.24184656720695957\n",
      "8500. Accuracy: 0.8048780487804879 Loss: 0.6077070354399741\n",
      "8500. Accuracy: 0.8048780487804879 Loss: 0.43579833467938367\n",
      "8500. Accuracy: 0.7560975609756098 Loss: 0.4713876549988628\n",
      "8500. Accuracy: 0.7804878048780488 Loss: 0.44965025966581834\n",
      "8500. Accuracy: 0.8292682926829268 Loss: 0.46684709611684894\n",
      "9000. Accuracy: 0.9024390243902439 Loss: 0.21266472024219116\n",
      "9000. Accuracy: 0.7804878048780488 Loss: 0.5192506048849529\n",
      "9000. Accuracy: 0.8292682926829268 Loss: 0.3338755318130193\n",
      "9000. Accuracy: 0.8048780487804879 Loss: 0.36327564825337544\n",
      "9000. Accuracy: 0.8048780487804879 Loss: 0.41124426901666666\n",
      "9000. Accuracy: 0.8536585365853658 Loss: 0.41722458037827576\n",
      "9500. Accuracy: 0.8048780487804879 Loss: 0.3985716637585493\n",
      "9500. Accuracy: 0.8292682926829268 Loss: 0.4048006877108459\n",
      "9500. Accuracy: 1.0 Loss: 0.09032247806629691\n",
      "9500. Accuracy: 0.926829268292683 Loss: 0.21976811447998484\n",
      "9500. Accuracy: 0.8536585365853658 Loss: 0.35511713482946256\n",
      "9500. Accuracy: 0.7804878048780488 Loss: 0.5227760495451022\n",
      "10000. Accuracy: 0.8780487804878049 Loss: 0.23733259317129546\n",
      "10000. Accuracy: 0.7804878048780488 Loss: 0.5919281020651604\n",
      "10000. Accuracy: 0.7804878048780488 Loss: 0.42000661386220717\n",
      "10000. Accuracy: 0.7560975609756098 Loss: 0.4450248301372723\n",
      "10000. Accuracy: 0.8048780487804879 Loss: 0.412983485072271\n",
      "10000. Accuracy: 0.8536585365853658 Loss: 0.4447085733931536\n",
      "10500. Accuracy: 0.8536585365853658 Loss: 0.3260097525715736\n",
      "10500. Accuracy: 0.8292682926829268 Loss: 0.36351476638210695\n",
      "10500. Accuracy: 1.0 Loss: 0.08812446578613958\n",
      "10500. Accuracy: 0.926829268292683 Loss: 0.207073968616021\n",
      "10500. Accuracy: 0.8536585365853658 Loss: 0.33843020972538945\n",
      "10500. Accuracy: 0.8048780487804879 Loss: 0.4743617630979525\n",
      "11000. Accuracy: 0.8780487804878049 Loss: 0.22672586258302851\n",
      "11000. Accuracy: 0.7804878048780488 Loss: 0.5566360430014653\n",
      "11000. Accuracy: 0.8048780487804879 Loss: 0.37496395332256754\n",
      "11000. Accuracy: 0.7560975609756098 Loss: 0.38862446101158965\n",
      "11000. Accuracy: 0.8048780487804879 Loss: 0.39597028684416796\n",
      "11000. Accuracy: 0.8536585365853658 Loss: 0.42449995489349873\n",
      "11500. Accuracy: 0.8536585365853658 Loss: 0.28528613977341494\n",
      "11500. Accuracy: 0.8536585365853658 Loss: 0.3444401098509594\n",
      "11500. Accuracy: 1.0 Loss: 0.09000114381180752\n",
      "11500. Accuracy: 0.926829268292683 Loss: 0.20242755109530525\n",
      "11500. Accuracy: 0.8780487804878049 Loss: 0.32402891454155175\n",
      "11500. Accuracy: 0.8048780487804879 Loss: 0.44591848238443454\n",
      "12000. Accuracy: 0.8780487804878049 Loss: 0.25035562439229453\n",
      "12000. Accuracy: 0.8536585365853658 Loss: 0.33682579029772597\n",
      "12000. Accuracy: 1.0 Loss: 0.09671777059693633\n",
      "12000. Accuracy: 0.926829268292683 Loss: 0.19937184365231522\n",
      "12000. Accuracy: 0.8780487804878049 Loss: 0.31531683333316085\n",
      "12000. Accuracy: 0.8048780487804879 Loss: 0.42057892941077685\n",
      "12500. Accuracy: 0.9024390243902439 Loss: 0.2119931304404181\n",
      "12500. Accuracy: 0.7804878048780488 Loss: 0.5056843285133141\n",
      "12500. Accuracy: 0.8536585365853658 Loss: 0.3194082298815258\n",
      "12500. Accuracy: 0.8048780487804879 Loss: 0.3257248240993695\n",
      "12500. Accuracy: 0.8292682926829268 Loss: 0.3673724456234432\n",
      "12500. Accuracy: 0.8536585365853658 Loss: 0.3908618854305286\n",
      "13000. Accuracy: 0.8048780487804879 Loss: 0.40845933728317957\n",
      "13000. Accuracy: 0.8292682926829268 Loss: 0.4167781743649877\n",
      "13000. Accuracy: 0.9512195121951219 Loss: 0.11997737379779706\n",
      "13000. Accuracy: 0.926829268292683 Loss: 0.19861778386446005\n",
      "13000. Accuracy: 0.8292682926829268 Loss: 0.32809455249259334\n",
      "13000. Accuracy: 0.7804878048780488 Loss: 0.5294355266100174\n",
      "13500. Accuracy: 0.8780487804878049 Loss: 0.247526368743997\n",
      "13500. Accuracy: 0.7804878048780488 Loss: 0.5673515925217392\n",
      "13500. Accuracy: 0.8292682926829268 Loss: 0.36684482959770975\n",
      "13500. Accuracy: 0.7804878048780488 Loss: 0.3733897976812478\n",
      "13500. Accuracy: 0.8292682926829268 Loss: 0.3774639677199059\n",
      "13500. Accuracy: 0.8536585365853658 Loss: 0.4229022515047975\n",
      "14000. Accuracy: 0.9512195121951219 Loss: 0.1930273317476691\n",
      "14000. Accuracy: 0.7804878048780488 Loss: 0.4488552408022471\n",
      "14000. Accuracy: 0.8780487804878049 Loss: 0.25736023116912615\n",
      "14000. Accuracy: 0.8292682926829268 Loss: 0.2708345326668663\n",
      "14000. Accuracy: 0.8536585365853658 Loss: 0.3325407820469431\n",
      "14000. Accuracy: 0.8536585365853658 Loss: 0.3526055929035485\n",
      "14500. Accuracy: 0.9024390243902439 Loss: 0.21397835033349344\n",
      "14500. Accuracy: 0.8780487804878049 Loss: 0.32090455505710686\n",
      "14500. Accuracy: 0.975609756097561 Loss: 0.10273719296786922\n",
      "14500. Accuracy: 0.9024390243902439 Loss: 0.1975141219707619\n",
      "14500. Accuracy: 0.9024390243902439 Loss: 0.29072390961376005\n",
      "14500. Accuracy: 0.8536585365853658 Loss: 0.3733805181724189\n",
      "15000. Accuracy: 0.9024390243902439 Loss: 0.21703749349801976\n",
      "15000. Accuracy: 0.8780487804878049 Loss: 0.3166688332889956\n",
      "15000. Accuracy: 0.975609756097561 Loss: 0.10028794731492434\n",
      "15000. Accuracy: 0.9024390243902439 Loss: 0.19646564453970827\n",
      "15000. Accuracy: 0.9024390243902439 Loss: 0.2871564316786507\n",
      "15000. Accuracy: 0.8780487804878049 Loss: 0.3693189939125478\n",
      "15500. Accuracy: 0.9024390243902439 Loss: 0.20996790869145004\n",
      "15500. Accuracy: 0.8780487804878049 Loss: 0.3139591206635038\n",
      "15500. Accuracy: 0.975609756097561 Loss: 0.10227539523881553\n",
      "15500. Accuracy: 0.9024390243902439 Loss: 0.1943008091823636\n",
      "15500. Accuracy: 0.9024390243902439 Loss: 0.28465933976612745\n",
      "15500. Accuracy: 0.8780487804878049 Loss: 0.3653104751011265\n",
      "16000. Accuracy: 0.926829268292683 Loss: 0.1729796508013717\n",
      "16000. Accuracy: 0.8292682926829268 Loss: 0.33850344166508334\n",
      "16000. Accuracy: 0.975609756097561 Loss: 0.1524494575291244\n",
      "16000. Accuracy: 0.9024390243902439 Loss: 0.20767358048111298\n",
      "16000. Accuracy: 0.926829268292683 Loss: 0.28199438512317965\n",
      "16000. Accuracy: 0.8536585365853658 Loss: 0.3153999020201443\n",
      "16500. Accuracy: 0.9024390243902439 Loss: 0.21835074295014487\n",
      "16500. Accuracy: 0.8780487804878049 Loss: 0.30703483546139654\n",
      "16500. Accuracy: 1.0 Loss: 0.09340548010205788\n",
      "16500. Accuracy: 0.9024390243902439 Loss: 0.1902825895568544\n",
      "16500. Accuracy: 0.9024390243902439 Loss: 0.27883079313706305\n",
      "16500. Accuracy: 0.8536585365853658 Loss: 0.3697427028277434\n",
      "17000. Accuracy: 0.8780487804878049 Loss: 0.23983561799910816\n",
      "17000. Accuracy: 0.8780487804878049 Loss: 0.3039989965845627\n",
      "17000. Accuracy: 1.0 Loss: 0.0823320062144908\n",
      "17000. Accuracy: 0.926829268292683 Loss: 0.1899891184571924\n",
      "17000. Accuracy: 0.9024390243902439 Loss: 0.2811648899001614\n",
      "17000. Accuracy: 0.8292682926829268 Loss: 0.38816247704530893\n",
      "17500. Accuracy: 0.9024390243902439 Loss: 0.2023014649776888\n",
      "17500. Accuracy: 0.8536585365853658 Loss: 0.30480809994527\n",
      "17500. Accuracy: 0.975609756097561 Loss: 0.09855777172248219\n",
      "17500. Accuracy: 0.9024390243902439 Loss: 0.18885089464492924\n",
      "17500. Accuracy: 0.9024390243902439 Loss: 0.26968243951137216\n",
      "17500. Accuracy: 0.8780487804878049 Loss: 0.3503314125940337\n",
      "18000. Accuracy: 0.9512195121951219 Loss: 0.1822322972816052\n",
      "18000. Accuracy: 0.8536585365853658 Loss: 0.3097528974363219\n",
      "18000. Accuracy: 0.975609756097561 Loss: 0.11180390139083858\n",
      "18000. Accuracy: 0.9024390243902439 Loss: 0.18974694849937757\n",
      "18000. Accuracy: 0.9024390243902439 Loss: 0.26416010591837086\n",
      "18000. Accuracy: 0.8780487804878049 Loss: 0.3278974605665577\n",
      "18500. Accuracy: 0.926829268292683 Loss: 0.20359168865539903\n",
      "18500. Accuracy: 0.8780487804878049 Loss: 0.30030597618354216\n",
      "18500. Accuracy: 1.0 Loss: 0.0936126590994069\n",
      "18500. Accuracy: 0.9024390243902439 Loss: 0.18524598098394002\n",
      "18500. Accuracy: 0.9024390243902439 Loss: 0.2644868293568128\n",
      "18500. Accuracy: 0.8780487804878049 Loss: 0.35171730484457864\n",
      "19000. Accuracy: 0.9512195121951219 Loss: 0.19258660946441003\n",
      "19000. Accuracy: 0.8780487804878049 Loss: 0.2987120424013028\n",
      "19000. Accuracy: 0.975609756097561 Loss: 0.09876596273094615\n",
      "19000. Accuracy: 0.9024390243902439 Loss: 0.18309088299082632\n",
      "19000. Accuracy: 0.9024390243902439 Loss: 0.2593488687490067\n",
      "19000. Accuracy: 0.8780487804878049 Loss: 0.33725526259258565\n",
      "19500. Accuracy: 0.9512195121951219 Loss: 0.17730843274661703\n",
      "19500. Accuracy: 0.8780487804878049 Loss: 0.301521552383606\n",
      "19500. Accuracy: 0.975609756097561 Loss: 0.11009481052665952\n",
      "19500. Accuracy: 0.9024390243902439 Loss: 0.18327879094117064\n",
      "19500. Accuracy: 0.926829268292683 Loss: 0.25584793582634485\n",
      "19500. Accuracy: 0.8780487804878049 Loss: 0.31681868938834695\n",
      "20000. Accuracy: 0.9512195121951219 Loss: 0.18984504186366336\n",
      "20000. Accuracy: 0.8780487804878049 Loss: 0.2932499347976941\n",
      "20000. Accuracy: 0.975609756097561 Loss: 0.09576678539986518\n",
      "20000. Accuracy: 0.9024390243902439 Loss: 0.1804363416313365\n",
      "20000. Accuracy: 0.9024390243902439 Loss: 0.2557360575409474\n",
      "20000. Accuracy: 0.8780487804878049 Loss: 0.3327870853345542\n",
      "20500. Accuracy: 0.9512195121951219 Loss: 0.18397297452346326\n",
      "20500. Accuracy: 0.8780487804878049 Loss: 0.29067149852584645\n",
      "20500. Accuracy: 0.975609756097561 Loss: 0.09618223113117998\n",
      "20500. Accuracy: 0.9024390243902439 Loss: 0.1778944059673023\n",
      "20500. Accuracy: 0.926829268292683 Loss: 0.2532030993318771\n",
      "20500. Accuracy: 0.8780487804878049 Loss: 0.3267865003876682\n",
      "21000. Accuracy: 0.9512195121951219 Loss: 0.1762757940666103\n",
      "21000. Accuracy: 0.9024390243902439 Loss: 0.29171464936989444\n",
      "21000. Accuracy: 0.975609756097561 Loss: 0.10176344010325357\n",
      "21000. Accuracy: 0.9024390243902439 Loss: 0.1771821551924541\n",
      "21000. Accuracy: 0.926829268292683 Loss: 0.2492783818224595\n",
      "21000. Accuracy: 0.8780487804878049 Loss: 0.31307400096421656\n",
      "21500. Accuracy: 0.9512195121951219 Loss: 0.18280589356663537\n",
      "21500. Accuracy: 0.8780487804878049 Loss: 0.28523241418230055\n",
      "21500. Accuracy: 0.975609756097561 Loss: 0.0934781003961753\n",
      "21500. Accuracy: 0.9024390243902439 Loss: 0.17537834184253928\n",
      "21500. Accuracy: 0.926829268292683 Loss: 0.24833044257725367\n",
      "21500. Accuracy: 0.8780487804878049 Loss: 0.3210834277145073\n",
      "22000. Accuracy: 0.9512195121951219 Loss: 0.16829629504633478\n",
      "22000. Accuracy: 0.8780487804878049 Loss: 0.29162175932057893\n",
      "22000. Accuracy: 0.975609756097561 Loss: 0.1066357276233599\n",
      "22000. Accuracy: 0.9024390243902439 Loss: 0.17578071350469607\n",
      "22000. Accuracy: 0.926829268292683 Loss: 0.2441545500120332\n",
      "22000. Accuracy: 0.8780487804878049 Loss: 0.29773186934478124\n",
      "22500. Accuracy: 0.9512195121951219 Loss: 0.16455757935389062\n",
      "22500. Accuracy: 0.8780487804878049 Loss: 0.2921220608639213\n",
      "22500. Accuracy: 0.975609756097561 Loss: 0.1110176535462906\n",
      "22500. Accuracy: 0.9024390243902439 Loss: 0.1758128295885896\n",
      "22500. Accuracy: 0.926829268292683 Loss: 0.24236962443040558\n",
      "22500. Accuracy: 0.8780487804878049 Loss: 0.2891548314242631\n",
      "23000. Accuracy: 0.9512195121951219 Loss: 0.16540590806359512\n",
      "23000. Accuracy: 0.9024390243902439 Loss: 0.28657157845048004\n",
      "23000. Accuracy: 0.975609756097561 Loss: 0.10541625487185174\n",
      "23000. Accuracy: 0.9024390243902439 Loss: 0.17375123548138618\n",
      "23000. Accuracy: 0.926829268292683 Loss: 0.23973423795144233\n",
      "23000. Accuracy: 0.8780487804878049 Loss: 0.288846933351949\n",
      "23500. Accuracy: 0.9512195121951219 Loss: 0.17514678080384277\n",
      "23500. Accuracy: 0.8780487804878049 Loss: 0.274117559777159\n",
      "23500. Accuracy: 0.975609756097561 Loss: 0.08950836746699743\n",
      "23500. Accuracy: 0.926829268292683 Loss: 0.17054188118668487\n",
      "23500. Accuracy: 0.926829268292683 Loss: 0.2383188672686821\n",
      "23500. Accuracy: 0.8780487804878049 Loss: 0.3012520843777385\n",
      "24000. Accuracy: 0.9512195121951219 Loss: 0.1621756101189842\n",
      "24000. Accuracy: 0.8292682926829268 Loss: 0.3192984917934772\n",
      "24000. Accuracy: 0.975609756097561 Loss: 0.14994404502242226\n",
      "24000. Accuracy: 0.926829268292683 Loss: 0.18709868716422204\n",
      "24000. Accuracy: 0.926829268292683 Loss: 0.24249181654103016\n",
      "24000. Accuracy: 0.9024390243902439 Loss: 0.2653387626085574\n",
      "24500. Accuracy: 0.9512195121951219 Loss: 0.16511134460859608\n",
      "24500. Accuracy: 0.9024390243902439 Loss: 0.2768317064749453\n",
      "24500. Accuracy: 0.975609756097561 Loss: 0.0980346039270653\n",
      "24500. Accuracy: 0.926829268292683 Loss: 0.17084116219449672\n",
      "24500. Accuracy: 0.926829268292683 Loss: 0.2317600811825865\n",
      "24500. Accuracy: 0.8780487804878049 Loss: 0.2810642866961567\n",
      "25000. Accuracy: 0.9512195121951219 Loss: 0.17112519430128847\n",
      "25000. Accuracy: 0.9024390243902439 Loss: 0.26898418688579084\n",
      "25000. Accuracy: 0.975609756097561 Loss: 0.08911977389602518\n",
      "25000. Accuracy: 0.926829268292683 Loss: 0.16914214241398748\n",
      "25000. Accuracy: 0.926829268292683 Loss: 0.2300363756182497\n",
      "25000. Accuracy: 0.8780487804878049 Loss: 0.2883169343151737\n",
      "25500. Accuracy: 0.9512195121951219 Loss: 0.1655476868375306\n",
      "25500. Accuracy: 0.9024390243902439 Loss: 0.2717353014098577\n",
      "25500. Accuracy: 0.975609756097561 Loss: 0.09549666295215548\n",
      "25500. Accuracy: 0.926829268292683 Loss: 0.1693110886366206\n",
      "25500. Accuracy: 0.926829268292683 Loss: 0.2264988441563525\n",
      "25500. Accuracy: 0.8780487804878049 Loss: 0.2779250814984493\n",
      "26000. Accuracy: 0.9512195121951219 Loss: 0.16660260637418567\n",
      "26000. Accuracy: 0.9024390243902439 Loss: 0.2689584719029169\n",
      "26000. Accuracy: 0.975609756097561 Loss: 0.0938713220457516\n",
      "26000. Accuracy: 0.926829268292683 Loss: 0.16840520216203206\n",
      "26000. Accuracy: 0.926829268292683 Loss: 0.2247997135728651\n",
      "26000. Accuracy: 0.8780487804878049 Loss: 0.2777399135121256\n",
      "26500. Accuracy: 0.9512195121951219 Loss: 0.17003897077875058\n",
      "26500. Accuracy: 0.9024390243902439 Loss: 0.2634521543289351\n",
      "26500. Accuracy: 0.975609756097561 Loss: 0.0878646615237716\n",
      "26500. Accuracy: 0.926829268292683 Loss: 0.1669162675698187\n",
      "26500. Accuracy: 0.926829268292683 Loss: 0.22384517328267675\n",
      "26500. Accuracy: 0.8780487804878049 Loss: 0.280835438756133\n",
      "27000. Accuracy: 0.9512195121951219 Loss: 0.16059450495922273\n",
      "27000. Accuracy: 0.9024390243902439 Loss: 0.2703149490670479\n",
      "27000. Accuracy: 0.975609756097561 Loss: 0.10214339045135364\n",
      "27000. Accuracy: 0.926829268292683 Loss: 0.16770854986494882\n",
      "27000. Accuracy: 0.926829268292683 Loss: 0.22072354675420952\n",
      "27000. Accuracy: 0.9024390243902439 Loss: 0.26436185680643226\n",
      "27500. Accuracy: 0.9512195121951219 Loss: 0.16265574197015817\n",
      "27500. Accuracy: 0.9024390243902439 Loss: 0.2637283421587404\n",
      "27500. Accuracy: 0.975609756097561 Loss: 0.09519854578935269\n",
      "27500. Accuracy: 0.926829268292683 Loss: 0.16557068062170432\n",
      "27500. Accuracy: 0.926829268292683 Loss: 0.21978064581761086\n",
      "27500. Accuracy: 0.9024390243902439 Loss: 0.2673540730494899\n",
      "28000. Accuracy: 0.9512195121951219 Loss: 0.1683492125670667\n",
      "28000. Accuracy: 0.9024390243902439 Loss: 0.25471959837314057\n",
      "28000. Accuracy: 0.975609756097561 Loss: 0.0848995348380151\n",
      "28000. Accuracy: 0.9512195121951219 Loss: 0.1632405532272206\n",
      "28000. Accuracy: 0.926829268292683 Loss: 0.21900883413696465\n",
      "28000. Accuracy: 0.8780487804878049 Loss: 0.2754874878292792\n",
      "28500. Accuracy: 0.9512195121951219 Loss: 0.16621686068715927\n",
      "28500. Accuracy: 0.9024390243902439 Loss: 0.25344547849075116\n",
      "28500. Accuracy: 0.975609756097561 Loss: 0.08517223307457093\n",
      "28500. Accuracy: 0.9512195121951219 Loss: 0.16215500908993283\n",
      "28500. Accuracy: 0.926829268292683 Loss: 0.2181635248466792\n",
      "28500. Accuracy: 0.8780487804878049 Loss: 0.27342100777327555\n",
      "29000. Accuracy: 0.9512195121951219 Loss: 0.16349334240456118\n",
      "29000. Accuracy: 0.9024390243902439 Loss: 0.2521597249014607\n",
      "29000. Accuracy: 0.975609756097561 Loss: 0.08689869793422825\n",
      "29000. Accuracy: 0.9512195121951219 Loss: 0.1619205664684624\n",
      "29000. Accuracy: 0.926829268292683 Loss: 0.21627009462995256\n",
      "29000. Accuracy: 0.9024390243902439 Loss: 0.2676728953395809\n",
      "29500. Accuracy: 0.9512195121951219 Loss: 0.16090832946701483\n",
      "29500. Accuracy: 0.9024390243902439 Loss: 0.25016936668515327\n",
      "29500. Accuracy: 0.975609756097561 Loss: 0.0876203812628549\n",
      "29500. Accuracy: 0.9512195121951219 Loss: 0.16118653259006127\n",
      "29500. Accuracy: 0.926829268292683 Loss: 0.2146251659400078\n",
      "29500. Accuracy: 0.9024390243902439 Loss: 0.2640079688653904\n",
      "30000. Accuracy: 0.9512195121951219 Loss: 0.15871655350591393\n",
      "30000. Accuracy: 0.9024390243902439 Loss: 0.2491163053734452\n",
      "30000. Accuracy: 0.975609756097561 Loss: 0.08883326092157189\n",
      "30000. Accuracy: 0.9512195121951219 Loss: 0.1605920957508196\n",
      "30000. Accuracy: 0.926829268292683 Loss: 0.21313258967521082\n",
      "30000. Accuracy: 0.9024390243902439 Loss: 0.26024652177045476\n",
      "30500. Accuracy: 0.9512195121951219 Loss: 0.1582976414227843\n",
      "30500. Accuracy: 0.9024390243902439 Loss: 0.24677891909543062\n",
      "30500. Accuracy: 0.975609756097561 Loss: 0.08847381633806639\n",
      "30500. Accuracy: 0.9512195121951219 Loss: 0.1596955845247632\n",
      "30500. Accuracy: 0.926829268292683 Loss: 0.21193382451896084\n",
      "30500. Accuracy: 0.9024390243902439 Loss: 0.2593853860551458\n",
      "31000. Accuracy: 0.9512195121951219 Loss: 0.15370281830667748\n",
      "31000. Accuracy: 0.9024390243902439 Loss: 0.24868417362558265\n",
      "31000. Accuracy: 0.975609756097561 Loss: 0.09372850391791318\n",
      "31000. Accuracy: 0.9512195121951219 Loss: 0.1594758080202339\n",
      "31000. Accuracy: 0.926829268292683 Loss: 0.21049775671533089\n",
      "31000. Accuracy: 0.9024390243902439 Loss: 0.25330538147788\n",
      "31500. Accuracy: 0.9512195121951219 Loss: 0.15283761931627476\n",
      "31500. Accuracy: 0.9024390243902439 Loss: 0.2471078840602431\n",
      "31500. Accuracy: 0.975609756097561 Loss: 0.09383254157911321\n",
      "31500. Accuracy: 0.9512195121951219 Loss: 0.1584219064214021\n",
      "31500. Accuracy: 0.926829268292683 Loss: 0.20909080323435147\n",
      "31500. Accuracy: 0.9024390243902439 Loss: 0.25256737883256\n",
      "32000. Accuracy: 0.975609756097561 Loss: 0.1491049762603003\n",
      "32000. Accuracy: 0.9024390243902439 Loss: 0.2543729080167081\n",
      "32000. Accuracy: 0.975609756097561 Loss: 0.1060842877459144\n",
      "32000. Accuracy: 0.9512195121951219 Loss: 0.15953118881345196\n",
      "32000. Accuracy: 0.926829268292683 Loss: 0.2082999382139244\n",
      "32000. Accuracy: 0.926829268292683 Loss: 0.24323987258630053\n",
      "32500. Accuracy: 0.9512195121951219 Loss: 0.15726765503349915\n",
      "32500. Accuracy: 0.9024390243902439 Loss: 0.23797586766751527\n",
      "32500. Accuracy: 0.975609756097561 Loss: 0.08474259543753639\n",
      "32500. Accuracy: 0.9512195121951219 Loss: 0.15485120637569874\n",
      "32500. Accuracy: 0.926829268292683 Loss: 0.20841199207486963\n",
      "32500. Accuracy: 0.9024390243902439 Loss: 0.2590321760562904\n",
      "33000. Accuracy: 0.9512195121951219 Loss: 0.15384731021875836\n",
      "33000. Accuracy: 0.9024390243902439 Loss: 0.23857829175395096\n",
      "33000. Accuracy: 0.975609756097561 Loss: 0.08754054270725099\n",
      "33000. Accuracy: 0.9512195121951219 Loss: 0.1543207184167549\n",
      "33000. Accuracy: 0.926829268292683 Loss: 0.20626317005004477\n",
      "33000. Accuracy: 0.9024390243902439 Loss: 0.25337735110776993\n",
      "33500. Accuracy: 0.9512195121951219 Loss: 0.15337653137135063\n",
      "33500. Accuracy: 0.9024390243902439 Loss: 0.23720096782329686\n",
      "33500. Accuracy: 0.975609756097561 Loss: 0.0864129233583705\n",
      "33500. Accuracy: 0.9512195121951219 Loss: 0.15320615678007626\n",
      "33500. Accuracy: 0.926829268292683 Loss: 0.205881609494787\n",
      "33500. Accuracy: 0.9024390243902439 Loss: 0.2539408429895431\n",
      "34000. Accuracy: 0.9512195121951219 Loss: 0.15234996166951964\n",
      "34000. Accuracy: 0.9024390243902439 Loss: 0.2361245643214063\n",
      "34000. Accuracy: 0.975609756097561 Loss: 0.08756891903907543\n",
      "34000. Accuracy: 0.9512195121951219 Loss: 0.1524002122979432\n",
      "34000. Accuracy: 0.926829268292683 Loss: 0.20525734409002513\n",
      "34000. Accuracy: 0.9024390243902439 Loss: 0.2507404995876696\n",
      "34500. Accuracy: 0.9512195121951219 Loss: 0.16144050827988896\n",
      "34500. Accuracy: 0.926829268292683 Loss: 0.22952808490396062\n",
      "34500. Accuracy: 1.0 Loss: 0.07595270599449293\n",
      "34500. Accuracy: 0.9512195121951219 Loss: 0.15126335033688704\n",
      "34500. Accuracy: 0.926829268292683 Loss: 0.2076252610927472\n",
      "34500. Accuracy: 0.9024390243902439 Loss: 0.2656280343401502\n",
      "35000. Accuracy: 0.9512195121951219 Loss: 0.14952987457689126\n",
      "35000. Accuracy: 0.9024390243902439 Loss: 0.23439595841632394\n",
      "35000. Accuracy: 0.975609756097561 Loss: 0.08812676931463066\n",
      "35000. Accuracy: 0.9512195121951219 Loss: 0.15115269435701828\n",
      "35000. Accuracy: 0.926829268292683 Loss: 0.20330442351357159\n",
      "35000. Accuracy: 0.9024390243902439 Loss: 0.24743682470527292\n",
      "35500. Accuracy: 0.9512195121951219 Loss: 0.15064301778298841\n",
      "35500. Accuracy: 0.9024390243902439 Loss: 0.2307640702758045\n",
      "35500. Accuracy: 0.975609756097561 Loss: 0.0843544262325123\n",
      "35500. Accuracy: 0.9512195121951219 Loss: 0.14979209860127174\n",
      "35500. Accuracy: 0.926829268292683 Loss: 0.20260560324487364\n",
      "35500. Accuracy: 0.9024390243902439 Loss: 0.25086603563516036\n",
      "36000. Accuracy: 0.9512195121951219 Loss: 0.1494496150877486\n",
      "36000. Accuracy: 0.9024390243902439 Loss: 0.23071965550295892\n",
      "36000. Accuracy: 0.975609756097561 Loss: 0.08515321732111496\n",
      "36000. Accuracy: 0.9512195121951219 Loss: 0.1488101416026209\n",
      "36000. Accuracy: 0.926829268292683 Loss: 0.20096759111718066\n",
      "36000. Accuracy: 0.9024390243902439 Loss: 0.24721452147017461\n",
      "36500. Accuracy: 0.9512195121951219 Loss: 0.15031503981625816\n",
      "36500. Accuracy: 0.926829268292683 Loss: 0.2277153630476844\n",
      "36500. Accuracy: 0.975609756097561 Loss: 0.08226592035944526\n",
      "36500. Accuracy: 0.9512195121951219 Loss: 0.14743397571568595\n",
      "36500. Accuracy: 0.926829268292683 Loss: 0.20145764544356295\n",
      "36500. Accuracy: 0.9024390243902439 Loss: 0.24995242377551996\n",
      "37000. Accuracy: 0.9512195121951219 Loss: 0.14800615167026812\n",
      "37000. Accuracy: 0.926829268292683 Loss: 0.22734232825167722\n",
      "37000. Accuracy: 0.975609756097561 Loss: 0.08326656837867084\n",
      "37000. Accuracy: 0.9512195121951219 Loss: 0.14640246911105106\n",
      "37000. Accuracy: 0.926829268292683 Loss: 0.20043803578316863\n",
      "37000. Accuracy: 0.9024390243902439 Loss: 0.24802083855718815\n",
      "37500. Accuracy: 0.9512195121951219 Loss: 0.14734468255327782\n",
      "37500. Accuracy: 0.926829268292683 Loss: 0.22550935768323088\n",
      "37500. Accuracy: 0.975609756097561 Loss: 0.08240458241258936\n",
      "37500. Accuracy: 0.9512195121951219 Loss: 0.14492780348688095\n",
      "37500. Accuracy: 0.926829268292683 Loss: 0.1995537007369619\n",
      "37500. Accuracy: 0.9024390243902439 Loss: 0.2476470482010227\n",
      "38000. Accuracy: 0.9512195121951219 Loss: 0.14948096162993682\n",
      "38000. Accuracy: 0.926829268292683 Loss: 0.22231267765381174\n",
      "38000. Accuracy: 1.0 Loss: 0.07882622583499738\n",
      "38000. Accuracy: 0.9512195121951219 Loss: 0.14374608031865554\n",
      "38000. Accuracy: 0.9512195121951219 Loss: 0.1985105607158993\n",
      "38000. Accuracy: 0.9024390243902439 Loss: 0.24986016222865629\n",
      "38500. Accuracy: 0.9512195121951219 Loss: 0.14934349530959787\n",
      "38500. Accuracy: 0.926829268292683 Loss: 0.22152762445855237\n",
      "38500. Accuracy: 1.0 Loss: 0.077601199208296\n",
      "38500. Accuracy: 0.9512195121951219 Loss: 0.14276873720041378\n",
      "38500. Accuracy: 0.9512195121951219 Loss: 0.19716191498401453\n",
      "38500. Accuracy: 0.9024390243902439 Loss: 0.24879412745309407\n",
      "39000. Accuracy: 0.9512195121951219 Loss: 0.14456953661962355\n",
      "39000. Accuracy: 0.926829268292683 Loss: 0.22393866087820388\n",
      "39000. Accuracy: 0.975609756097561 Loss: 0.08196044217666495\n",
      "39000. Accuracy: 0.9512195121951219 Loss: 0.14270984341018902\n",
      "39000. Accuracy: 0.9512195121951219 Loss: 0.19387883439771186\n",
      "39000. Accuracy: 0.9024390243902439 Loss: 0.24024356220614326\n",
      "39500. Accuracy: 0.9512195121951219 Loss: 0.14824123343311937\n",
      "39500. Accuracy: 0.926829268292683 Loss: 0.2189083198767962\n",
      "39500. Accuracy: 1.0 Loss: 0.07577832065449239\n",
      "39500. Accuracy: 0.9512195121951219 Loss: 0.14143157935373674\n",
      "39500. Accuracy: 0.9512195121951219 Loss: 0.1936893491274503\n",
      "39500. Accuracy: 0.9024390243902439 Loss: 0.2477255848410224\n",
      "40000. Accuracy: 0.9512195121951219 Loss: 0.14737364142212173\n",
      "40000. Accuracy: 0.926829268292683 Loss: 0.218045009960544\n",
      "40000. Accuracy: 1.0 Loss: 0.0760611291940518\n",
      "40000. Accuracy: 0.9512195121951219 Loss: 0.14092501292096185\n",
      "40000. Accuracy: 0.9512195121951219 Loss: 0.19145150258013652\n",
      "40000. Accuracy: 0.9024390243902439 Loss: 0.2438330116755347\n",
      "40500. Accuracy: 0.9512195121951219 Loss: 0.14116727350677605\n",
      "40500. Accuracy: 0.926829268292683 Loss: 0.22187699423182125\n",
      "40500. Accuracy: 0.975609756097561 Loss: 0.08367742742184003\n",
      "40500. Accuracy: 0.9512195121951219 Loss: 0.14072634194863054\n",
      "40500. Accuracy: 0.9512195121951219 Loss: 0.18906866797651004\n",
      "40500. Accuracy: 0.9024390243902439 Loss: 0.2329492107964042\n",
      "41000. Accuracy: 0.9512195121951219 Loss: 0.14455178455693632\n",
      "41000. Accuracy: 0.926829268292683 Loss: 0.21516538702717738\n",
      "41000. Accuracy: 1.0 Loss: 0.07600246227793522\n",
      "41000. Accuracy: 0.9512195121951219 Loss: 0.13934442575786085\n",
      "41000. Accuracy: 0.9512195121951219 Loss: 0.18881927542903004\n",
      "41000. Accuracy: 0.9024390243902439 Loss: 0.2402381864022308\n",
      "41500. Accuracy: 0.9512195121951219 Loss: 0.1460524025291778\n",
      "41500. Accuracy: 0.926829268292683 Loss: 0.21153009713611992\n",
      "41500. Accuracy: 1.0 Loss: 0.07340076210817947\n",
      "41500. Accuracy: 0.9512195121951219 Loss: 0.1387243211186935\n",
      "41500. Accuracy: 0.9512195121951219 Loss: 0.1880757752684493\n",
      "41500. Accuracy: 0.9024390243902439 Loss: 0.24259767393579063\n",
      "42000. Accuracy: 0.9512195121951219 Loss: 0.1464866123004126\n",
      "42000. Accuracy: 0.926829268292683 Loss: 0.20910372858752446\n",
      "42000. Accuracy: 1.0 Loss: 0.0718095969766408\n",
      "42000. Accuracy: 0.9512195121951219 Loss: 0.13819570865496764\n",
      "42000. Accuracy: 0.9512195121951219 Loss: 0.18770988350843723\n",
      "42000. Accuracy: 0.9024390243902439 Loss: 0.24339697492203682\n",
      "42500. Accuracy: 0.9512195121951219 Loss: 0.1433971014340572\n",
      "42500. Accuracy: 0.926829268292683 Loss: 0.20919332116311842\n",
      "42500. Accuracy: 1.0 Loss: 0.07365983439989147\n",
      "42500. Accuracy: 0.9512195121951219 Loss: 0.13793028122975842\n",
      "42500. Accuracy: 0.9512195121951219 Loss: 0.1866581252875692\n",
      "42500. Accuracy: 0.9024390243902439 Loss: 0.23828630859094246\n",
      "43000. Accuracy: 0.9512195121951219 Loss: 0.139828259212253\n",
      "43000. Accuracy: 0.926829268292683 Loss: 0.20975314343042165\n",
      "43000. Accuracy: 1.0 Loss: 0.07616162042524592\n",
      "43000. Accuracy: 0.9512195121951219 Loss: 0.13712052455357332\n",
      "43000. Accuracy: 0.9512195121951219 Loss: 0.18552543395838433\n",
      "43000. Accuracy: 0.9024390243902439 Loss: 0.23344617315510632\n",
      "43500. Accuracy: 0.9512195121951219 Loss: 0.1435834205333715\n",
      "43500. Accuracy: 0.926829268292683 Loss: 0.20697710976005174\n",
      "43500. Accuracy: 1.0 Loss: 0.07320938346197274\n",
      "43500. Accuracy: 0.9512195121951219 Loss: 0.13655735087448764\n",
      "43500. Accuracy: 0.9512195121951219 Loss: 0.18590340855291193\n",
      "43500. Accuracy: 0.9024390243902439 Loss: 0.23574901923223887\n",
      "44000. Accuracy: 0.9512195121951219 Loss: 0.14413516441758148\n",
      "44000. Accuracy: 0.926829268292683 Loss: 0.20533670587160752\n",
      "44000. Accuracy: 1.0 Loss: 0.07198514525409266\n",
      "44000. Accuracy: 0.9512195121951219 Loss: 0.13595050035868994\n",
      "44000. Accuracy: 0.9512195121951219 Loss: 0.18639531368546547\n",
      "44000. Accuracy: 0.9024390243902439 Loss: 0.23477511252546465\n",
      "44500. Accuracy: 0.9512195121951219 Loss: 0.14339582005050402\n",
      "44500. Accuracy: 0.926829268292683 Loss: 0.20491970586536537\n",
      "44500. Accuracy: 1.0 Loss: 0.07211800258321585\n",
      "44500. Accuracy: 0.9512195121951219 Loss: 0.13607318426583767\n",
      "44500. Accuracy: 0.9512195121951219 Loss: 0.1852005861409677\n",
      "44500. Accuracy: 0.9024390243902439 Loss: 0.23179525088555702\n",
      "45000. Accuracy: 0.9512195121951219 Loss: 0.14769912976028307\n",
      "45000. Accuracy: 0.926829268292683 Loss: 0.20146108297189688\n",
      "45000. Accuracy: 1.0 Loss: 0.06832413062703806\n",
      "45000. Accuracy: 0.9512195121951219 Loss: 0.13600716858018524\n",
      "45000. Accuracy: 0.9512195121951219 Loss: 0.18613013488090624\n",
      "45000. Accuracy: 0.9024390243902439 Loss: 0.2365822860599347\n",
      "45500. Accuracy: 0.9512195121951219 Loss: 0.14679141104486707\n",
      "45500. Accuracy: 0.926829268292683 Loss: 0.19999967480346692\n",
      "45500. Accuracy: 1.0 Loss: 0.06823627758868224\n",
      "45500. Accuracy: 0.9512195121951219 Loss: 0.13531960015585107\n",
      "45500. Accuracy: 0.9512195121951219 Loss: 0.18541911172417194\n",
      "45500. Accuracy: 0.9024390243902439 Loss: 0.23522590571396151\n",
      "46000. Accuracy: 0.9512195121951219 Loss: 0.1461018765851547\n",
      "46000. Accuracy: 0.926829268292683 Loss: 0.19876991800799282\n",
      "46000. Accuracy: 1.0 Loss: 0.06868579994223419\n",
      "46000. Accuracy: 0.9512195121951219 Loss: 0.13450594526703574\n",
      "46000. Accuracy: 0.9512195121951219 Loss: 0.18380066549495128\n",
      "46000. Accuracy: 0.9024390243902439 Loss: 0.23432290865456476\n",
      "46500. Accuracy: 0.9512195121951219 Loss: 0.14046541086222472\n",
      "46500. Accuracy: 0.926829268292683 Loss: 0.19967061199126898\n",
      "46500. Accuracy: 1.0 Loss: 0.07225899216984788\n",
      "46500. Accuracy: 0.9512195121951219 Loss: 0.1342322260795741\n",
      "46500. Accuracy: 0.9512195121951219 Loss: 0.18060772064083333\n",
      "46500. Accuracy: 0.9024390243902439 Loss: 0.22499790725906518\n",
      "47000. Accuracy: 0.9512195121951219 Loss: 0.14267508450112726\n",
      "47000. Accuracy: 0.926829268292683 Loss: 0.19592505212192474\n",
      "47000. Accuracy: 1.0 Loss: 0.06856746552408449\n",
      "47000. Accuracy: 0.9512195121951219 Loss: 0.13286291876187428\n",
      "47000. Accuracy: 0.9512195121951219 Loss: 0.18088670374227597\n",
      "47000. Accuracy: 0.9024390243902439 Loss: 0.22789984994207485\n",
      "47500. Accuracy: 0.9512195121951219 Loss: 0.14072360486486826\n",
      "47500. Accuracy: 0.926829268292683 Loss: 0.19512381523443081\n",
      "47500. Accuracy: 1.0 Loss: 0.0690547521875559\n",
      "47500. Accuracy: 0.9512195121951219 Loss: 0.13171540074499813\n",
      "47500. Accuracy: 0.9512195121951219 Loss: 0.17922360869459636\n",
      "47500. Accuracy: 0.9024390243902439 Loss: 0.2256391523391277\n",
      "48000. Accuracy: 0.9512195121951219 Loss: 0.14185051465521292\n",
      "48000. Accuracy: 0.926829268292683 Loss: 0.1932416698447525\n",
      "48000. Accuracy: 1.0 Loss: 0.06720952289934022\n",
      "48000. Accuracy: 0.9512195121951219 Loss: 0.13082343686562684\n",
      "48000. Accuracy: 0.9512195121951219 Loss: 0.17889880832097907\n",
      "48000. Accuracy: 0.9024390243902439 Loss: 0.22627547678462087\n",
      "48500. Accuracy: 0.9512195121951219 Loss: 0.13979915149860345\n",
      "48500. Accuracy: 0.926829268292683 Loss: 0.19347107228255297\n",
      "48500. Accuracy: 1.0 Loss: 0.06863036720051843\n",
      "48500. Accuracy: 0.9512195121951219 Loss: 0.13064799928021514\n",
      "48500. Accuracy: 0.9512195121951219 Loss: 0.17594072388273801\n",
      "48500. Accuracy: 0.9024390243902439 Loss: 0.22269040842105048\n",
      "49000. Accuracy: 0.9512195121951219 Loss: 0.13880195929915942\n",
      "49000. Accuracy: 0.926829268292683 Loss: 0.1921174581607784\n",
      "49000. Accuracy: 1.0 Loss: 0.06826670604363497\n",
      "49000. Accuracy: 0.9512195121951219 Loss: 0.1298579164456819\n",
      "49000. Accuracy: 0.9512195121951219 Loss: 0.17373875054164462\n",
      "49000. Accuracy: 0.9024390243902439 Loss: 0.2206411755432004\n",
      "49500. Accuracy: 0.9512195121951219 Loss: 0.1366524737452368\n",
      "49500. Accuracy: 0.926829268292683 Loss: 0.19197028802535943\n",
      "49500. Accuracy: 1.0 Loss: 0.06896055538817819\n",
      "49500. Accuracy: 0.9512195121951219 Loss: 0.12947548229827807\n",
      "49500. Accuracy: 0.9512195121951219 Loss: 0.1708148326768224\n",
      "49500. Accuracy: 0.9024390243902439 Loss: 0.21683917749946247\n"
     ]
    }
   ],
   "source": [
    "train = Train(network1c, learning_rate, batch_size, epochs, loss_function)\n",
    "cost, accuracies = train.train(inputs_train, outputs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f5ccbe98-0252-4cf9-90ed-4330b111c717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([a for a in range(len(cost))],cost)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fab66a3-6e6d-4ce8-89b9-12100cffff33",
   "metadata": {},
   "source": [
    "## 2. Measuring the impact of hyperparameters (number of epochs, learning rate, activation function) on model performance (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b416d8-5efa-48c6-9665-771e17a71a90",
   "metadata": {},
   "source": [
    "### a) decrease number of epochs to 10000 (change hidden dim to 100 for all experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "aa7c44e8-666a-4796-8422-6002a8140d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "hidden_dim=100\n",
    "network2a = NeuralNetwork(input_dim,\n",
    "                        hidden_dim,\n",
    "                        output_dim,\n",
    "                        num_of_hidden_layers,\n",
    "                        activation,\n",
    "                        activation_output,\n",
    "                        initialization,\n",
    "                        output_initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "de555841-a963-4840-8c69-7ed467b740f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Accuracy: 0.34146341463414637 Loss: 2.4617613177567823\n",
      "0. Accuracy: 0.43902439024390244 Loss: 1.566659194579306\n",
      "0. Accuracy: 0.5121951219512195 Loss: 1.571443670204103\n",
      "0. Accuracy: 0.4146341463414634 Loss: 1.962574487347974\n",
      "0. Accuracy: 0.4634146341463415 Loss: 1.786460906165779\n",
      "0. Accuracy: 0.4878048780487805 Loss: 1.4566438998217908\n",
      "500. Accuracy: 0.7804878048780488 Loss: 0.4846210257339458\n",
      "500. Accuracy: 0.7073170731707317 Loss: 0.6372873129866897\n",
      "500. Accuracy: 0.7560975609756098 Loss: 0.5357587082198056\n",
      "500. Accuracy: 0.7073170731707317 Loss: 0.5590840629944749\n",
      "500. Accuracy: 0.6097560975609756 Loss: 0.6242486789501075\n",
      "500. Accuracy: 0.6829268292682927 Loss: 0.5945993748749733\n",
      "1000. Accuracy: 0.7317073170731707 Loss: 0.48110105526774555\n",
      "1000. Accuracy: 0.7073170731707317 Loss: 0.6278710872851975\n",
      "1000. Accuracy: 0.7560975609756098 Loss: 0.5236005329003268\n",
      "1000. Accuracy: 0.7317073170731707 Loss: 0.5517581807476709\n",
      "1000. Accuracy: 0.6097560975609756 Loss: 0.6249644436511294\n",
      "1000. Accuracy: 0.6829268292682927 Loss: 0.5849058985499335\n",
      "1500. Accuracy: 0.7317073170731707 Loss: 0.4769528643669659\n",
      "1500. Accuracy: 0.7073170731707317 Loss: 0.6215103125092648\n",
      "1500. Accuracy: 0.7560975609756098 Loss: 0.516356184413203\n",
      "1500. Accuracy: 0.7317073170731707 Loss: 0.5474616526438978\n",
      "1500. Accuracy: 0.6097560975609756 Loss: 0.6245199088002782\n",
      "1500. Accuracy: 0.7073170731707317 Loss: 0.5796182896679193\n",
      "2000. Accuracy: 0.7804878048780488 Loss: 0.47171779854593293\n",
      "2000. Accuracy: 0.7073170731707317 Loss: 0.6154760255995912\n",
      "2000. Accuracy: 0.7804878048780488 Loss: 0.5105381441406\n",
      "2000. Accuracy: 0.7317073170731707 Loss: 0.5416160888264842\n",
      "2000. Accuracy: 0.6097560975609756 Loss: 0.6234630302178947\n",
      "2000. Accuracy: 0.7073170731707317 Loss: 0.5747539414857455\n",
      "2500. Accuracy: 0.7804878048780488 Loss: 0.4690417441260207\n",
      "2500. Accuracy: 0.7073170731707317 Loss: 0.6103367572963432\n",
      "2500. Accuracy: 0.7804878048780488 Loss: 0.5052024336514995\n",
      "2500. Accuracy: 0.7317073170731707 Loss: 0.5366208566012833\n",
      "2500. Accuracy: 0.6097560975609756 Loss: 0.6227778274501815\n",
      "2500. Accuracy: 0.7317073170731707 Loss: 0.5711150678417811\n",
      "3000. Accuracy: 0.8048780487804879 Loss: 0.4662674575941097\n",
      "3000. Accuracy: 0.7073170731707317 Loss: 0.6069322854937061\n",
      "3000. Accuracy: 0.8048780487804879 Loss: 0.4986688312177895\n",
      "3000. Accuracy: 0.7560975609756098 Loss: 0.5325445856694709\n",
      "3000. Accuracy: 0.6097560975609756 Loss: 0.62149347758529\n",
      "3000. Accuracy: 0.7317073170731707 Loss: 0.5685203354807578\n",
      "3500. Accuracy: 0.8048780487804879 Loss: 0.463657266585182\n",
      "3500. Accuracy: 0.7073170731707317 Loss: 0.6039868196088989\n",
      "3500. Accuracy: 0.8048780487804879 Loss: 0.49334828234068584\n",
      "3500. Accuracy: 0.7560975609756098 Loss: 0.5293609353126085\n",
      "3500. Accuracy: 0.6097560975609756 Loss: 0.6197700895680098\n",
      "3500. Accuracy: 0.7317073170731707 Loss: 0.5658875557828678\n",
      "4000. Accuracy: 0.8048780487804879 Loss: 0.4613623058834936\n",
      "4000. Accuracy: 0.7073170731707317 Loss: 0.6011262421521545\n",
      "4000. Accuracy: 0.8048780487804879 Loss: 0.4890686452319679\n",
      "4000. Accuracy: 0.7560975609756098 Loss: 0.5264287322267335\n",
      "4000. Accuracy: 0.6097560975609756 Loss: 0.6178712199475099\n",
      "4000. Accuracy: 0.7317073170731707 Loss: 0.5631185786123446\n",
      "4500. Accuracy: 0.8048780487804879 Loss: 0.4589789140140196\n",
      "4500. Accuracy: 0.7073170731707317 Loss: 0.5986249732309985\n",
      "4500. Accuracy: 0.8048780487804879 Loss: 0.4849762484506921\n",
      "4500. Accuracy: 0.7317073170731707 Loss: 0.5236035919849369\n",
      "4500. Accuracy: 0.6097560975609756 Loss: 0.6154022257351106\n",
      "4500. Accuracy: 0.7317073170731707 Loss: 0.5606077624574407\n",
      "5000. Accuracy: 0.8048780487804879 Loss: 0.45696784405991103\n",
      "5000. Accuracy: 0.7073170731707317 Loss: 0.5966478683393298\n",
      "5000. Accuracy: 0.8048780487804879 Loss: 0.48085413801095034\n",
      "5000. Accuracy: 0.7317073170731707 Loss: 0.520892903836828\n",
      "5000. Accuracy: 0.6341463414634146 Loss: 0.6131551698339341\n",
      "5000. Accuracy: 0.7317073170731707 Loss: 0.5586285851876206\n",
      "5500. Accuracy: 0.8292682926829268 Loss: 0.4547138071463942\n",
      "5500. Accuracy: 0.7073170731707317 Loss: 0.5940870595118593\n",
      "5500. Accuracy: 0.8048780487804879 Loss: 0.476811751152599\n",
      "5500. Accuracy: 0.7317073170731707 Loss: 0.5182984594619011\n",
      "5500. Accuracy: 0.6829268292682927 Loss: 0.610945576615433\n",
      "5500. Accuracy: 0.7317073170731707 Loss: 0.556437157246831\n",
      "6000. Accuracy: 0.8536585365853658 Loss: 0.45232329724212345\n",
      "6000. Accuracy: 0.7073170731707317 Loss: 0.5905741396349714\n",
      "6000. Accuracy: 0.8048780487804879 Loss: 0.4731408852483608\n",
      "6000. Accuracy: 0.7317073170731707 Loss: 0.5159521386964925\n",
      "6000. Accuracy: 0.6829268292682927 Loss: 0.6086939761726966\n",
      "6000. Accuracy: 0.7317073170731707 Loss: 0.5539607808768725\n",
      "6500. Accuracy: 0.8536585365853658 Loss: 0.4500681569721473\n",
      "6500. Accuracy: 0.7073170731707317 Loss: 0.5884881805495825\n",
      "6500. Accuracy: 0.8048780487804879 Loss: 0.468772973250086\n",
      "6500. Accuracy: 0.7560975609756098 Loss: 0.5134640039802453\n",
      "6500. Accuracy: 0.6829268292682927 Loss: 0.6067613380488859\n",
      "6500. Accuracy: 0.7317073170731707 Loss: 0.5514111148772797\n",
      "7000. Accuracy: 0.8292682926829268 Loss: 0.4478305505746537\n",
      "7000. Accuracy: 0.7073170731707317 Loss: 0.5864211540564731\n",
      "7000. Accuracy: 0.8048780487804879 Loss: 0.4645934461198292\n",
      "7000. Accuracy: 0.7560975609756098 Loss: 0.5110054111315587\n",
      "7000. Accuracy: 0.7073170731707317 Loss: 0.604513529033484\n",
      "7000. Accuracy: 0.7317073170731707 Loss: 0.5489078623303545\n",
      "7500. Accuracy: 0.8292682926829268 Loss: 0.44572688821702333\n",
      "7500. Accuracy: 0.7073170731707317 Loss: 0.5842903929734217\n",
      "7500. Accuracy: 0.8048780487804879 Loss: 0.46045080481423345\n",
      "7500. Accuracy: 0.7560975609756098 Loss: 0.508555902100798\n",
      "7500. Accuracy: 0.7073170731707317 Loss: 0.6020880211391613\n",
      "7500. Accuracy: 0.7317073170731707 Loss: 0.5463926857171585\n",
      "8000. Accuracy: 0.8292682926829268 Loss: 0.4437614836686022\n",
      "8000. Accuracy: 0.7073170731707317 Loss: 0.5819745350666873\n",
      "8000. Accuracy: 0.8048780487804879 Loss: 0.4567129192733232\n",
      "8000. Accuracy: 0.7560975609756098 Loss: 0.5063468356776547\n",
      "8000. Accuracy: 0.7073170731707317 Loss: 0.5993932500708835\n",
      "8000. Accuracy: 0.7317073170731707 Loss: 0.5436728422476583\n",
      "8500. Accuracy: 0.8292682926829268 Loss: 0.44182374291026294\n",
      "8500. Accuracy: 0.7073170731707317 Loss: 0.5796073176635904\n",
      "8500. Accuracy: 0.8292682926829268 Loss: 0.4529786543865135\n",
      "8500. Accuracy: 0.7560975609756098 Loss: 0.5040927016976087\n",
      "8500. Accuracy: 0.7073170731707317 Loss: 0.596451302536238\n",
      "8500. Accuracy: 0.7317073170731707 Loss: 0.5408634846884142\n",
      "9000. Accuracy: 0.8048780487804879 Loss: 0.4402454485285264\n",
      "9000. Accuracy: 0.7073170731707317 Loss: 0.5773912442979467\n",
      "9000. Accuracy: 0.8292682926829268 Loss: 0.44521657963526695\n",
      "9000. Accuracy: 0.7560975609756098 Loss: 0.5011163770449185\n",
      "9000. Accuracy: 0.7073170731707317 Loss: 0.5945816278522992\n",
      "9000. Accuracy: 0.7317073170731707 Loss: 0.537233431192447\n",
      "9500. Accuracy: 0.8292682926829268 Loss: 0.4361544462565545\n",
      "9500. Accuracy: 0.6829268292682927 Loss: 0.5759844530146409\n",
      "9500. Accuracy: 0.8292682926829268 Loss: 0.44097637343545026\n",
      "9500. Accuracy: 0.7560975609756098 Loss: 0.4980927241589659\n",
      "9500. Accuracy: 0.7073170731707317 Loss: 0.5926546305971265\n",
      "9500. Accuracy: 0.7317073170731707 Loss: 0.5347449618115021\n"
     ]
    }
   ],
   "source": [
    "train = Train(network2a, learning_rate, batch_size, epochs, loss_function)\n",
    "cost, accuracies = train.train(inputs_train, outputs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3c75d8a8-646d-4a0e-8e4a-29725faf06f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([a for a in range(len(cost))],cost)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149e94d9-c4af-4a53-a330-d6ecdff9f9a7",
   "metadata": {},
   "source": [
    "### b) decrease number of epochs to 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9625b793-bdc1-4825-bfcf-f79b276eedd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 25000\n",
    "network2b = NeuralNetwork(input_dim,\n",
    "                        hidden_dim,\n",
    "                        output_dim,\n",
    "                        num_of_hidden_layers,\n",
    "                        activation,\n",
    "                        activation_output,\n",
    "                        initialization,\n",
    "                        output_initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3f4b0952-da4e-4d2c-a962-ae6ac204339b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Accuracy: 0.5365853658536586 Loss: 4.240830933657353\n",
      "0. Accuracy: 0.5609756097560976 Loss: 4.083305850312597\n",
      "0. Accuracy: 0.6829268292682927 Loss: 2.2220996082770235\n",
      "0. Accuracy: 0.6341463414634146 Loss: 2.37529711236903\n",
      "0. Accuracy: 0.5609756097560976 Loss: 3.35491879198033\n",
      "0. Accuracy: 0.6097560975609756 Loss: 2.515234270603626\n",
      "500. Accuracy: 0.7560975609756098 Loss: 0.48812824940670496\n",
      "500. Accuracy: 0.6829268292682927 Loss: 0.6396887212049329\n",
      "500. Accuracy: 0.8048780487804879 Loss: 0.5176494128102266\n",
      "500. Accuracy: 0.7560975609756098 Loss: 0.5555300184599422\n",
      "500. Accuracy: 0.6341463414634146 Loss: 0.5957513725991488\n",
      "500. Accuracy: 0.7317073170731707 Loss: 0.5911100618635106\n",
      "1000. Accuracy: 0.7804878048780488 Loss: 0.48464512987944725\n",
      "1000. Accuracy: 0.6829268292682927 Loss: 0.6267636153394351\n",
      "1000. Accuracy: 0.7804878048780488 Loss: 0.509577711375229\n",
      "1000. Accuracy: 0.7560975609756098 Loss: 0.5451552225100165\n",
      "1000. Accuracy: 0.6341463414634146 Loss: 0.5941477351897306\n",
      "1000. Accuracy: 0.7317073170731707 Loss: 0.5783532942599998\n",
      "1500. Accuracy: 0.7804878048780488 Loss: 0.4795245234545756\n",
      "1500. Accuracy: 0.6829268292682927 Loss: 0.6237056351964755\n",
      "1500. Accuracy: 0.7804878048780488 Loss: 0.5008961059501246\n",
      "1500. Accuracy: 0.7804878048780488 Loss: 0.5377924865275199\n",
      "1500. Accuracy: 0.6585365853658537 Loss: 0.588783570181493\n",
      "1500. Accuracy: 0.7317073170731707 Loss: 0.569436410239727\n",
      "2000. Accuracy: 0.7560975609756098 Loss: 0.4780191362094102\n",
      "2000. Accuracy: 0.6829268292682927 Loss: 0.6193466024109724\n",
      "2000. Accuracy: 0.8292682926829268 Loss: 0.4926750915619614\n",
      "2000. Accuracy: 0.7804878048780488 Loss: 0.5329522739510562\n",
      "2000. Accuracy: 0.6585365853658537 Loss: 0.5863770168953875\n",
      "2000. Accuracy: 0.7073170731707317 Loss: 0.5635512620440961\n",
      "2500. Accuracy: 0.7560975609756098 Loss: 0.4764390585698057\n",
      "2500. Accuracy: 0.6829268292682927 Loss: 0.6158946662013852\n",
      "2500. Accuracy: 0.8292682926829268 Loss: 0.4856800924088512\n",
      "2500. Accuracy: 0.7804878048780488 Loss: 0.5281607004940997\n",
      "2500. Accuracy: 0.6585365853658537 Loss: 0.5836337672484857\n",
      "2500. Accuracy: 0.7073170731707317 Loss: 0.5592790185936662\n",
      "3000. Accuracy: 0.7560975609756098 Loss: 0.47269878809437116\n",
      "3000. Accuracy: 0.6829268292682927 Loss: 0.6143128793813282\n",
      "3000. Accuracy: 0.8292682926829268 Loss: 0.47949119253841554\n",
      "3000. Accuracy: 0.8048780487804879 Loss: 0.5236645625916588\n",
      "3000. Accuracy: 0.6341463414634146 Loss: 0.578680005593724\n",
      "3000. Accuracy: 0.7073170731707317 Loss: 0.5557866286791748\n",
      "3500. Accuracy: 0.7804878048780488 Loss: 0.47022496127901287\n",
      "3500. Accuracy: 0.6829268292682927 Loss: 0.6102186926709734\n",
      "3500. Accuracy: 0.8292682926829268 Loss: 0.47352139493967804\n",
      "3500. Accuracy: 0.8048780487804879 Loss: 0.5196657194152894\n",
      "3500. Accuracy: 0.6585365853658537 Loss: 0.5761910154333906\n",
      "3500. Accuracy: 0.7317073170731707 Loss: 0.5526883071952895\n",
      "4000. Accuracy: 0.8048780487804879 Loss: 0.46541536506903536\n",
      "4000. Accuracy: 0.6829268292682927 Loss: 0.6077232704494061\n",
      "4000. Accuracy: 0.8292682926829268 Loss: 0.46839152323090494\n",
      "4000. Accuracy: 0.8048780487804879 Loss: 0.5135048499044139\n",
      "4000. Accuracy: 0.6585365853658537 Loss: 0.5740981622568788\n",
      "4000. Accuracy: 0.7317073170731707 Loss: 0.5504227130815811\n",
      "4500. Accuracy: 0.8048780487804879 Loss: 0.4603786442949585\n",
      "4500. Accuracy: 0.6829268292682927 Loss: 0.6037359298354598\n",
      "4500. Accuracy: 0.8292682926829268 Loss: 0.46408798273329466\n",
      "4500. Accuracy: 0.8048780487804879 Loss: 0.5071869757767092\n",
      "4500. Accuracy: 0.6829268292682927 Loss: 0.572597708234283\n",
      "4500. Accuracy: 0.7317073170731707 Loss: 0.5479484246111912\n",
      "5000. Accuracy: 0.8048780487804879 Loss: 0.45334274830897486\n",
      "5000. Accuracy: 0.6829268292682927 Loss: 0.5983958720747964\n",
      "5000. Accuracy: 0.8292682926829268 Loss: 0.46019096497728196\n",
      "5000. Accuracy: 0.8048780487804879 Loss: 0.5029913794573567\n",
      "5000. Accuracy: 0.6829268292682927 Loss: 0.5708950384490424\n",
      "5000. Accuracy: 0.7317073170731707 Loss: 0.5457126823598696\n",
      "5500. Accuracy: 0.8048780487804879 Loss: 0.45095466466073786\n",
      "5500. Accuracy: 0.6829268292682927 Loss: 0.5971778983167906\n",
      "5500. Accuracy: 0.8292682926829268 Loss: 0.4560984212333211\n",
      "5500. Accuracy: 0.8048780487804879 Loss: 0.4980112396355782\n",
      "5500. Accuracy: 0.6829268292682927 Loss: 0.5663251810172\n",
      "5500. Accuracy: 0.7317073170731707 Loss: 0.5436740568422546\n",
      "6000. Accuracy: 0.8048780487804879 Loss: 0.4497691367148307\n",
      "6000. Accuracy: 0.6829268292682927 Loss: 0.5963240380088496\n",
      "6000. Accuracy: 0.8292682926829268 Loss: 0.45261754348723293\n",
      "6000. Accuracy: 0.8048780487804879 Loss: 0.4948943116908224\n",
      "6000. Accuracy: 0.6829268292682927 Loss: 0.5641671974958511\n",
      "6000. Accuracy: 0.7317073170731707 Loss: 0.5382367478763934\n",
      "6500. Accuracy: 0.8292682926829268 Loss: 0.44838159626970214\n",
      "6500. Accuracy: 0.6829268292682927 Loss: 0.5935046414142567\n",
      "6500. Accuracy: 0.8292682926829268 Loss: 0.44886362705025473\n",
      "6500. Accuracy: 0.8048780487804879 Loss: 0.4917293259332533\n",
      "6500. Accuracy: 0.6829268292682927 Loss: 0.5638362958409819\n",
      "6500. Accuracy: 0.7317073170731707 Loss: 0.5367595183595788\n",
      "7000. Accuracy: 0.8292682926829268 Loss: 0.44488185703007105\n",
      "7000. Accuracy: 0.6829268292682927 Loss: 0.5898212160781722\n",
      "7000. Accuracy: 0.8292682926829268 Loss: 0.44507660511770186\n",
      "7000. Accuracy: 0.7804878048780488 Loss: 0.48692085680164304\n",
      "7000. Accuracy: 0.6829268292682927 Loss: 0.565409944444934\n",
      "7000. Accuracy: 0.7317073170731707 Loss: 0.5344856660765461\n",
      "7500. Accuracy: 0.8292682926829268 Loss: 0.4409931391721619\n",
      "7500. Accuracy: 0.6829268292682927 Loss: 0.5863778597391623\n",
      "7500. Accuracy: 0.8292682926829268 Loss: 0.4405693041846207\n",
      "7500. Accuracy: 0.7804878048780488 Loss: 0.48275095979604044\n",
      "7500. Accuracy: 0.7073170731707317 Loss: 0.5660177825052283\n",
      "7500. Accuracy: 0.7317073170731707 Loss: 0.5326488872515686\n",
      "8000. Accuracy: 0.8292682926829268 Loss: 0.4381558267962661\n",
      "8000. Accuracy: 0.6829268292682927 Loss: 0.5834419052396587\n",
      "8000. Accuracy: 0.8292682926829268 Loss: 0.4351906004613717\n",
      "8000. Accuracy: 0.7804878048780488 Loss: 0.47882070542552324\n",
      "8000. Accuracy: 0.7073170731707317 Loss: 0.5660738335021889\n",
      "8000. Accuracy: 0.7317073170731707 Loss: 0.530105246139354\n",
      "8500. Accuracy: 0.8292682926829268 Loss: 0.43594876456666537\n",
      "8500. Accuracy: 0.6829268292682927 Loss: 0.5805521523971777\n",
      "8500. Accuracy: 0.8292682926829268 Loss: 0.42997767911806933\n",
      "8500. Accuracy: 0.7804878048780488 Loss: 0.47605394449263083\n",
      "8500. Accuracy: 0.7317073170731707 Loss: 0.564846172654395\n",
      "8500. Accuracy: 0.7560975609756098 Loss: 0.5263478356669535\n",
      "9000. Accuracy: 0.8292682926829268 Loss: 0.43478243865743854\n",
      "9000. Accuracy: 0.6829268292682927 Loss: 0.5777308794830247\n",
      "9000. Accuracy: 0.8292682926829268 Loss: 0.42439891975477134\n",
      "9000. Accuracy: 0.7804878048780488 Loss: 0.47209210690802567\n",
      "9000. Accuracy: 0.7560975609756098 Loss: 0.5620487388953829\n",
      "9000. Accuracy: 0.7804878048780488 Loss: 0.5228836557617434\n",
      "9500. Accuracy: 0.8292682926829268 Loss: 0.43246152124111353\n",
      "9500. Accuracy: 0.6829268292682927 Loss: 0.5753429181288008\n",
      "9500. Accuracy: 0.8292682926829268 Loss: 0.419655101202526\n",
      "9500. Accuracy: 0.7804878048780488 Loss: 0.46897257262345615\n",
      "9500. Accuracy: 0.7560975609756098 Loss: 0.5575817107510659\n",
      "9500. Accuracy: 0.7560975609756098 Loss: 0.5190786631587729\n",
      "10000. Accuracy: 0.8292682926829268 Loss: 0.42891057608667704\n",
      "10000. Accuracy: 0.6829268292682927 Loss: 0.5733453060779551\n",
      "10000. Accuracy: 0.8292682926829268 Loss: 0.4161770361347442\n",
      "10000. Accuracy: 0.7804878048780488 Loss: 0.4657884319401346\n",
      "10000. Accuracy: 0.7317073170731707 Loss: 0.5533134523514875\n",
      "10000. Accuracy: 0.7560975609756098 Loss: 0.5154286355366955\n",
      "10500. Accuracy: 0.8292682926829268 Loss: 0.4257718540715008\n",
      "10500. Accuracy: 0.6829268292682927 Loss: 0.5694700351897644\n",
      "10500. Accuracy: 0.8292682926829268 Loss: 0.41109857518573156\n",
      "10500. Accuracy: 0.7804878048780488 Loss: 0.4621057017774224\n",
      "10500. Accuracy: 0.7317073170731707 Loss: 0.5516004249948432\n",
      "10500. Accuracy: 0.7560975609756098 Loss: 0.5133305281489335\n",
      "11000. Accuracy: 0.8292682926829268 Loss: 0.4228123553071466\n",
      "11000. Accuracy: 0.7073170731707317 Loss: 0.5658488051437399\n",
      "11000. Accuracy: 0.8536585365853658 Loss: 0.40572143037782765\n",
      "11000. Accuracy: 0.7804878048780488 Loss: 0.45924907199618925\n",
      "11000. Accuracy: 0.7317073170731707 Loss: 0.5498013908553848\n",
      "11000. Accuracy: 0.7560975609756098 Loss: 0.5117702671795903\n",
      "11500. Accuracy: 0.8292682926829268 Loss: 0.41987232539561853\n",
      "11500. Accuracy: 0.7073170731707317 Loss: 0.5631259674449457\n",
      "11500. Accuracy: 0.8536585365853658 Loss: 0.4010944033416276\n",
      "11500. Accuracy: 0.7804878048780488 Loss: 0.45657338810397385\n",
      "11500. Accuracy: 0.7317073170731707 Loss: 0.5470516388962539\n",
      "11500. Accuracy: 0.7560975609756098 Loss: 0.5098359264925396\n",
      "12000. Accuracy: 0.8292682926829268 Loss: 0.4170100764232165\n",
      "12000. Accuracy: 0.7073170731707317 Loss: 0.5608494507785099\n",
      "12000. Accuracy: 0.8536585365853658 Loss: 0.39754853655335726\n",
      "12000. Accuracy: 0.7804878048780488 Loss: 0.45387132205256053\n",
      "12000. Accuracy: 0.7560975609756098 Loss: 0.5439965952922644\n",
      "12000. Accuracy: 0.7560975609756098 Loss: 0.5081454799903182\n",
      "12500. Accuracy: 0.8536585365853658 Loss: 0.4142389629444263\n",
      "12500. Accuracy: 0.7073170731707317 Loss: 0.5586707669447672\n",
      "12500. Accuracy: 0.8780487804878049 Loss: 0.3948868945243581\n",
      "12500. Accuracy: 0.7804878048780488 Loss: 0.45165914915300637\n",
      "12500. Accuracy: 0.7560975609756098 Loss: 0.5414586109473997\n",
      "12500. Accuracy: 0.7560975609756098 Loss: 0.5063985758859981\n",
      "13000. Accuracy: 0.8536585365853658 Loss: 0.41131726723775613\n",
      "13000. Accuracy: 0.7317073170731707 Loss: 0.5570574983768922\n",
      "13000. Accuracy: 0.8780487804878049 Loss: 0.39240110743474504\n",
      "13000. Accuracy: 0.7804878048780488 Loss: 0.4492992718774594\n",
      "13000. Accuracy: 0.7560975609756098 Loss: 0.5398517886887603\n",
      "13000. Accuracy: 0.7560975609756098 Loss: 0.5041962103558547\n",
      "13500. Accuracy: 0.8536585365853658 Loss: 0.40857586330103407\n",
      "13500. Accuracy: 0.7073170731707317 Loss: 0.5540336922967842\n",
      "13500. Accuracy: 0.8780487804878049 Loss: 0.3891370823519989\n",
      "13500. Accuracy: 0.7804878048780488 Loss: 0.44672588741333846\n",
      "13500. Accuracy: 0.7560975609756098 Loss: 0.5373166450007053\n",
      "13500. Accuracy: 0.7560975609756098 Loss: 0.5032587785526141\n",
      "14000. Accuracy: 0.8536585365853658 Loss: 0.4060787045934048\n",
      "14000. Accuracy: 0.7073170731707317 Loss: 0.5502729532946097\n",
      "14000. Accuracy: 0.8780487804878049 Loss: 0.3846193597914753\n",
      "14000. Accuracy: 0.7804878048780488 Loss: 0.4443565423760968\n",
      "14000. Accuracy: 0.7804878048780488 Loss: 0.5338166158380893\n",
      "14000. Accuracy: 0.7560975609756098 Loss: 0.5021281036229007\n",
      "14500. Accuracy: 0.8536585365853658 Loss: 0.4034235464499825\n",
      "14500. Accuracy: 0.7073170731707317 Loss: 0.5466118397302299\n",
      "14500. Accuracy: 0.8780487804878049 Loss: 0.3810209289076425\n",
      "14500. Accuracy: 0.7804878048780488 Loss: 0.4421475169329758\n",
      "14500. Accuracy: 0.7804878048780488 Loss: 0.5303040160223867\n",
      "14500. Accuracy: 0.7560975609756098 Loss: 0.5001682641052532\n",
      "15000. Accuracy: 0.8536585365853658 Loss: 0.4001788339582858\n",
      "15000. Accuracy: 0.7073170731707317 Loss: 0.5440105497579393\n",
      "15000. Accuracy: 0.9024390243902439 Loss: 0.3775031820001604\n",
      "15000. Accuracy: 0.8048780487804879 Loss: 0.4394680085901714\n",
      "15000. Accuracy: 0.7804878048780488 Loss: 0.5281367930937236\n",
      "15000. Accuracy: 0.7560975609756098 Loss: 0.497786236780147\n",
      "15500. Accuracy: 0.8536585365853658 Loss: 0.39664800781767223\n",
      "15500. Accuracy: 0.7073170731707317 Loss: 0.5421630529584803\n",
      "15500. Accuracy: 0.9024390243902439 Loss: 0.37440552916849723\n",
      "15500. Accuracy: 0.8048780487804879 Loss: 0.4370712251325725\n",
      "15500. Accuracy: 0.7804878048780488 Loss: 0.5254903240345291\n",
      "15500. Accuracy: 0.7560975609756098 Loss: 0.4949083331091242\n",
      "16000. Accuracy: 0.8536585365853658 Loss: 0.3929317291310654\n",
      "16000. Accuracy: 0.7073170731707317 Loss: 0.5397745456394553\n",
      "16000. Accuracy: 0.9024390243902439 Loss: 0.37108681913358504\n",
      "16000. Accuracy: 0.8048780487804879 Loss: 0.43462547211205643\n",
      "16000. Accuracy: 0.7804878048780488 Loss: 0.5227841507119473\n",
      "16000. Accuracy: 0.7317073170731707 Loss: 0.4923876643476404\n",
      "16500. Accuracy: 0.8536585365853658 Loss: 0.38974625963616244\n",
      "16500. Accuracy: 0.7073170731707317 Loss: 0.5372550030300514\n",
      "16500. Accuracy: 0.9024390243902439 Loss: 0.3672485124085415\n",
      "16500. Accuracy: 0.8048780487804879 Loss: 0.4325895587619733\n",
      "16500. Accuracy: 0.7804878048780488 Loss: 0.5207053453583486\n",
      "16500. Accuracy: 0.7560975609756098 Loss: 0.4893400128916936\n",
      "17000. Accuracy: 0.8536585365853658 Loss: 0.3869035895917989\n",
      "17000. Accuracy: 0.7073170731707317 Loss: 0.534660919328008\n",
      "17000. Accuracy: 0.9024390243902439 Loss: 0.3618072720013989\n",
      "17000. Accuracy: 0.8048780487804879 Loss: 0.42739330310304585\n",
      "17000. Accuracy: 0.7804878048780488 Loss: 0.5181713872767845\n",
      "17000. Accuracy: 0.7317073170731707 Loss: 0.4868231065507234\n",
      "17500. Accuracy: 0.8536585365853658 Loss: 0.38319965417466934\n",
      "17500. Accuracy: 0.7073170731707317 Loss: 0.5320043322521296\n",
      "17500. Accuracy: 0.9024390243902439 Loss: 0.35841073839204896\n",
      "17500. Accuracy: 0.8048780487804879 Loss: 0.42449714867524785\n",
      "17500. Accuracy: 0.7804878048780488 Loss: 0.5174377494628531\n",
      "17500. Accuracy: 0.7317073170731707 Loss: 0.48414632525985024\n",
      "18000. Accuracy: 0.8536585365853658 Loss: 0.37988075218684997\n",
      "18000. Accuracy: 0.7073170731707317 Loss: 0.529037719137234\n",
      "18000. Accuracy: 0.9024390243902439 Loss: 0.35521439962461143\n",
      "18000. Accuracy: 0.8048780487804879 Loss: 0.4215728699873694\n",
      "18000. Accuracy: 0.7804878048780488 Loss: 0.5164166425615092\n",
      "18000. Accuracy: 0.7317073170731707 Loss: 0.4814759061763958\n",
      "18500. Accuracy: 0.8536585365853658 Loss: 0.3768277029447657\n",
      "18500. Accuracy: 0.7073170731707317 Loss: 0.5268355214577769\n",
      "18500. Accuracy: 0.9024390243902439 Loss: 0.3517911019844169\n",
      "18500. Accuracy: 0.8048780487804879 Loss: 0.4186646421185074\n",
      "18500. Accuracy: 0.7804878048780488 Loss: 0.5148090453829745\n",
      "18500. Accuracy: 0.7560975609756098 Loss: 0.47900331830272613\n",
      "19000. Accuracy: 0.8536585365853658 Loss: 0.3741788834732934\n",
      "19000. Accuracy: 0.7073170731707317 Loss: 0.5244354109549765\n",
      "19000. Accuracy: 0.926829268292683 Loss: 0.3482294399756912\n",
      "19000. Accuracy: 0.8048780487804879 Loss: 0.4155114286063695\n",
      "19000. Accuracy: 0.7804878048780488 Loss: 0.5137444086693888\n",
      "19000. Accuracy: 0.7560975609756098 Loss: 0.4763824312857734\n",
      "19500. Accuracy: 0.8536585365853658 Loss: 0.37131511870602124\n",
      "19500. Accuracy: 0.7073170731707317 Loss: 0.5220629446297517\n",
      "19500. Accuracy: 0.9512195121951219 Loss: 0.3446902561254938\n",
      "19500. Accuracy: 0.8292682926829268 Loss: 0.41277180488735643\n",
      "19500. Accuracy: 0.7804878048780488 Loss: 0.5124917975754102\n",
      "19500. Accuracy: 0.7560975609756098 Loss: 0.47334855618782984\n",
      "20000. Accuracy: 0.8536585365853658 Loss: 0.3684250616544825\n",
      "20000. Accuracy: 0.7073170731707317 Loss: 0.519369740947767\n",
      "20000. Accuracy: 0.9512195121951219 Loss: 0.3410769215244716\n",
      "20000. Accuracy: 0.8292682926829268 Loss: 0.41069025209548177\n",
      "20000. Accuracy: 0.7804878048780488 Loss: 0.5110177156102307\n",
      "20000. Accuracy: 0.7560975609756098 Loss: 0.4690638048033078\n",
      "20500. Accuracy: 0.8536585365853658 Loss: 0.36531303771478524\n",
      "20500. Accuracy: 0.7073170731707317 Loss: 0.5174771633474957\n",
      "20500. Accuracy: 0.9512195121951219 Loss: 0.3375171962383453\n",
      "20500. Accuracy: 0.8292682926829268 Loss: 0.4085188190186411\n",
      "20500. Accuracy: 0.7804878048780488 Loss: 0.5090228557969401\n",
      "20500. Accuracy: 0.7560975609756098 Loss: 0.46638191904913\n",
      "21000. Accuracy: 0.8536585365853658 Loss: 0.36256932836777367\n",
      "21000. Accuracy: 0.7073170731707317 Loss: 0.5152113429085918\n",
      "21000. Accuracy: 0.9512195121951219 Loss: 0.33320561089281114\n",
      "21000. Accuracy: 0.8292682926829268 Loss: 0.40615673577584827\n",
      "21000. Accuracy: 0.7804878048780488 Loss: 0.5067850113081637\n",
      "21000. Accuracy: 0.7560975609756098 Loss: 0.4641014494034213\n",
      "21500. Accuracy: 0.8536585365853658 Loss: 0.3604797841825999\n",
      "21500. Accuracy: 0.7073170731707317 Loss: 0.5147686795957832\n",
      "21500. Accuracy: 0.9512195121951219 Loss: 0.32920273371805236\n",
      "21500. Accuracy: 0.8292682926829268 Loss: 0.4036175282351258\n",
      "21500. Accuracy: 0.7804878048780488 Loss: 0.503846755265138\n",
      "21500. Accuracy: 0.7560975609756098 Loss: 0.46238157333981145\n",
      "22000. Accuracy: 0.8536585365853658 Loss: 0.35733475048854413\n",
      "22000. Accuracy: 0.7073170731707317 Loss: 0.5135621227380869\n",
      "22000. Accuracy: 0.9512195121951219 Loss: 0.32582988013049075\n",
      "22000. Accuracy: 0.8048780487804879 Loss: 0.40102996989265405\n",
      "22000. Accuracy: 0.7804878048780488 Loss: 0.5015939898169354\n",
      "22000. Accuracy: 0.7560975609756098 Loss: 0.460184195131945\n",
      "22500. Accuracy: 0.8536585365853658 Loss: 0.354581745507934\n",
      "22500. Accuracy: 0.7073170731707317 Loss: 0.5113670502749769\n",
      "22500. Accuracy: 0.9512195121951219 Loss: 0.3223634058758966\n",
      "22500. Accuracy: 0.8048780487804879 Loss: 0.39778684694753264\n",
      "22500. Accuracy: 0.7804878048780488 Loss: 0.5007856340530443\n",
      "22500. Accuracy: 0.7804878048780488 Loss: 0.4585993270820753\n",
      "23000. Accuracy: 0.8536585365853658 Loss: 0.35217708826544036\n",
      "23000. Accuracy: 0.7073170731707317 Loss: 0.5092484623578285\n",
      "23000. Accuracy: 0.9512195121951219 Loss: 0.31967223795057803\n",
      "23000. Accuracy: 0.8292682926829268 Loss: 0.39381419614647256\n",
      "23000. Accuracy: 0.7804878048780488 Loss: 0.4999418660917231\n",
      "23000. Accuracy: 0.7804878048780488 Loss: 0.45721154078938553\n",
      "23500. Accuracy: 0.8536585365853658 Loss: 0.3503179790060169\n",
      "23500. Accuracy: 0.7073170731707317 Loss: 0.5074762442985782\n",
      "23500. Accuracy: 0.9512195121951219 Loss: 0.3173020806346292\n",
      "23500. Accuracy: 0.8292682926829268 Loss: 0.38967588473274684\n",
      "23500. Accuracy: 0.7804878048780488 Loss: 0.4994867872313439\n",
      "23500. Accuracy: 0.8048780487804879 Loss: 0.455572541166325\n",
      "24000. Accuracy: 0.8536585365853658 Loss: 0.3472691147779512\n",
      "24000. Accuracy: 0.7073170731707317 Loss: 0.5059949385375334\n",
      "24000. Accuracy: 0.9512195121951219 Loss: 0.3148569129311456\n",
      "24000. Accuracy: 0.8292682926829268 Loss: 0.3858404044941506\n",
      "24000. Accuracy: 0.7560975609756098 Loss: 0.4976149568199358\n",
      "24000. Accuracy: 0.8048780487804879 Loss: 0.45475630847324033\n",
      "24500. Accuracy: 0.8536585365853658 Loss: 0.345631067494666\n",
      "24500. Accuracy: 0.7073170731707317 Loss: 0.5041527456967025\n",
      "24500. Accuracy: 0.9512195121951219 Loss: 0.31295781459351935\n",
      "24500. Accuracy: 0.8536585365853658 Loss: 0.381952724520942\n",
      "24500. Accuracy: 0.7804878048780488 Loss: 0.49498861295934016\n",
      "24500. Accuracy: 0.8048780487804879 Loss: 0.4525261750361659\n"
     ]
    }
   ],
   "source": [
    "train = Train(network2b, learning_rate, batch_size, epochs, loss_function)\n",
    "cost, accuracies = train.train(inputs_train, outputs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b96c05a3-dfe2-4603-933f-28a12f9ee475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAsVElEQVR4nO3de3RU5b3/8c9MQiaBZCbckhBIEAsFuQcQCLZiaxQpP4XTs6jlxzG0Bz1HG1ahuNDmtLW/o8uGU+qtloLUIu1RGsVyOUWUUjAgElCQKAGNokgCZIIIZJIgCWSe3x8epk4hMZPbk8y8X2vttZw9z977+x0Xmc/as5+9HcYYIwAAAEuctgsAAACRjTACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwKpo2wU0hd/v14kTJ5SQkCCHw2G7HAAA0ATGGFVVVSk1NVVOZ8PnPzpFGDlx4oTS0tJslwEAAJqhrKxM/fr1a/D9ThFGEhISJH3ejNvttlwNAABoCp/Pp7S0tMD3eEM6RRi59NOM2+0mjAAA0Ml82SUWXMAKAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwqlM8KK+t/H7nER07c063X5umISk8gA8AABsi+szIS++c0DOvf6zST8/ZLgUAgIgV0WEEAADYRxgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGJFkbBcAAEAEi+gw4nA4bJcAAEDEi+gwAgAA7COMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCOSDDcaAQDAmogOI9xlBAAA+yI6jAAAAPtaFEYWL14sh8OhBQsWNDpuzZo1GjJkiGJjYzVixAht2rSpJYcFAABhpNlh5M0339RTTz2lkSNHNjpu165dmjVrlubOnav9+/drxowZmjFjhoqLi5t7aAAAEEaaFUaqq6s1e/Zs/e53v1P37t0bHfvEE0/olltu0aJFi3TNNdfooYce0pgxY/Sb3/ymWQUDAIDw0qwwkpOTo2nTpikrK+tLxxYWFl42bsqUKSosLGxwm9raWvl8vqAFAACEp+hQN8jPz9dbb72lN998s0njvV6vkpOTg9YlJyfL6/U2uE1eXp7+8z//M9TSWoC5vQAA2BLSmZGysjLNnz9fzz33nGJjY9uqJuXm5qqysjKwlJWVtclxHMztBQDAupDOjOzbt08nT57UmDFjAuvq6+u1Y8cO/eY3v1Ftba2ioqKCtklJSVFFRUXQuoqKCqWkpDR4HJfLJZfLFUppAACgkwrpzMiNN96oAwcOqKioKLCMGzdOs2fPVlFR0WVBRJIyMzO1devWoHVbtmxRZmZmyyoHAABhIaQzIwkJCRo+fHjQum7duqlnz56B9dnZ2erbt6/y8vIkSfPnz9fkyZP1yCOPaNq0acrPz9fevXu1YsWKVmoBAAB0Zq1+B9bS0lKVl5cHXk+aNEmrV6/WihUrNGrUKL344otav379ZaEGAABEppBn0/yjgoKCRl9L0syZMzVz5syWHgoAAIQhnk0jntoLAIBNER1GHDy3FwAA6yI6jAAAAPsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgj4pm9AADYFNlhhJm9AABYF9lhBAAAWEcYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYkGW40AgCANREdRrjNCAAA9kV0GAEAAPYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGJBkxtxcAAFsiOow4mNsLAIB1ER1GAACAfYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBHx1F4AAGyK6DDi4Lm9AABYF9FhBAAA2BdSGFm2bJlGjhwpt9stt9utzMxMvfzyyw2OX7VqlRwOR9ASGxvb4qIBAED4iA5lcL9+/bR48WINGjRIxhj94Q9/0PTp07V//34NGzbsitu43W6VlJQEXju47SkAAPiCkMLIrbfeGvT64Ycf1rJly7R79+4Gw4jD4VBKSkrzKwQAAGGt2deM1NfXKz8/XzU1NcrMzGxwXHV1tfr376+0tDRNnz5dBw8e/NJ919bWyufzBS0AACA8hRxGDhw4oPj4eLlcLt19991at26dhg4desWxgwcP1sqVK7VhwwY9++yz8vv9mjRpko4dO9boMfLy8uTxeAJLWlpaqGWGhJm9AADY4zAmtLts1NXVqbS0VJWVlXrxxRf19NNPa/v27Q0Gki+6cOGCrrnmGs2aNUsPPfRQg+Nqa2tVW1sbeO3z+ZSWlqbKykq53e5Qym3U//3dbu368FP9elaGbhuV2mr7BQAAn39/ezyeL/3+DumaEUmKiYnRwIEDJUljx47Vm2++qSeeeEJPPfXUl27bpUsXZWRk6PDhw42Oc7lccrlcoZYGAAA6oRbfZ8Tv9wedxWhMfX29Dhw4oD59+rT0sAAAIEyEdGYkNzdXU6dOVXp6uqqqqrR69WoVFBRo8+bNkqTs7Gz17dtXeXl5kqQHH3xQEydO1MCBA3X27FktWbJER48e1Z133tn6nQAAgE4ppDBy8uRJZWdnq7y8XB6PRyNHjtTmzZt10003SZJKS0vldP79ZMuZM2d01113yev1qnv37ho7dqx27drVpOtLAABAZAj5AlYbmnoBTKi4gBUAgLbT1O9vnk0DAACsIoxI6gQnhwAACFsRHUZ4TA4AAPZFdBgBAAD2EUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFURHUYcYm4vAAC2RXQYAQAA9hFGAACAVYQRAABgFWEEAABYRRgBAABWEUYk8dBeAADsiegwwlN7AQCwL6LDCAAAsI8wAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIoxIMuJGIwAA2EIYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBFJhpm9AABYE1IYWbZsmUaOHCm32y23263MzEy9/PLLjW6zZs0aDRkyRLGxsRoxYoQ2bdrUooJbk8PhsF0CAAARL6Qw0q9fPy1evFj79u3T3r179c1vflPTp0/XwYMHrzh+165dmjVrlubOnav9+/drxowZmjFjhoqLi1uleAAA0Pk5jGnZjxQ9evTQkiVLNHfu3Mveu/3221VTU6ONGzcG1k2cOFGjR4/W8uXLm3wMn88nj8ejyspKud3ulpQbJHvlG9rx/id69Duj9O0x/VptvwAAoOnf382+ZqS+vl75+fmqqalRZmbmFccUFhYqKysraN2UKVNUWFjY3MMCAIAwEx3qBgcOHFBmZqbOnz+v+Ph4rVu3TkOHDr3iWK/Xq+Tk5KB1ycnJ8nq9jR6jtrZWtbW1gdc+ny/UMgEAQCcR8pmRwYMHq6ioSHv27NE999yjOXPm6NChQ61aVF5enjweT2BJS0tr1f0DAICOI+QwEhMTo4EDB2rs2LHKy8vTqFGj9MQTT1xxbEpKiioqKoLWVVRUKCUlpdFj5ObmqrKyMrCUlZWFWmZImNoLAIA9Lb7PiN/vD/pJ5YsyMzO1devWoHVbtmxp8BqTS1wuV2D68KWlLTCxFwAA+0K6ZiQ3N1dTp05Venq6qqqqtHr1ahUUFGjz5s2SpOzsbPXt21d5eXmSpPnz52vy5Ml65JFHNG3aNOXn52vv3r1asWJF63cCAAA6pZDCyMmTJ5Wdna3y8nJ5PB6NHDlSmzdv1k033SRJKi0tldP595MtkyZN0urVq/XTn/5U//Ef/6FBgwZp/fr1Gj58eOt2AQAAOq2Qwsjvf//7Rt8vKCi4bN3MmTM1c+bMkIoCAACRg2fTAAAAqwgjAADAKsKIJGb2AgBgT0SHER7aCwCAfREdRgAAgH2EEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWFEkjHcaQQAAFsiOoxwmxEAAOyL6DACAADsI4wAAACrCCMAAMAqwggAALCKMAIAAKwijEhiYi8AAPZEdBhxOJjcCwCAbREdRgAAgH2EEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRibm9AABYFNFhhIm9AADYF9FhBAAA2EcYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWhRRG8vLydO211yohIUFJSUmaMWOGSkpKGt1m1apVcjgcQUtsbGyLim5thhuNAABgTUhhZPv27crJydHu3bu1ZcsWXbhwQTfffLNqamoa3c7tdqu8vDywHD16tEVFtxYHNxoBAMC66FAGv/LKK0GvV61apaSkJO3bt0/XX399g9s5HA6lpKQ0r0IAABDWWnTNSGVlpSSpR48ejY6rrq5W//79lZaWpunTp+vgwYONjq+trZXP5wtaAABAeGp2GPH7/VqwYIGuu+46DR8+vMFxgwcP1sqVK7VhwwY9++yz8vv9mjRpko4dO9bgNnl5efJ4PIElLS2tuWUCAIAOrtlhJCcnR8XFxcrPz290XGZmprKzszV69GhNnjxZa9euVe/evfXUU081uE1ubq4qKysDS1lZWXPLBAAAHVxI14xcMm/ePG3cuFE7duxQv379Qtq2S5cuysjI0OHDhxsc43K55HK5mlMaAADoZEI6M2KM0bx587Ru3Tpt27ZNAwYMCPmA9fX1OnDggPr06RPytm3FMLMXAABrQjozkpOTo9WrV2vDhg1KSEiQ1+uVJHk8HsXFxUmSsrOz1bdvX+Xl5UmSHnzwQU2cOFEDBw7U2bNntWTJEh09elR33nlnK7fSHMztBQDAtpDCyLJlyyRJN9xwQ9D6Z555Rt/73vckSaWlpXI6/37C5cyZM7rrrrvk9XrVvXt3jR07Vrt27dLQoUNbVjkAAAgLIYUR04TfMwoKCoJeP/bYY3rsscdCKgoAAEQOnk0DAACsIowAAACrCCMAAMAqwojEM3sBALAoosMIT+0FAMC+iA4jAADAPsIIAACwijACAACsIowAAACrCCMAAMAqwoh4ai8AADZFdBhhZi8AAPZFdBgBAAD2EUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEUlG3GgEAABbIjqMOLjRCAAA1kV0GAEAAPYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGJBlm9gIAYE1EhxGHmNsLAIBtER1GAACAfYQRAABgFWEEAABYRRgBAABWEUYAAIBVIYWRvLw8XXvttUpISFBSUpJmzJihkpKSL91uzZo1GjJkiGJjYzVixAht2rSp2QW3BWb2AgBgT0hhZPv27crJydHu3bu1ZcsWXbhwQTfffLNqamoa3GbXrl2aNWuW5s6dq/3792vGjBmaMWOGiouLW1x8S/HUXgAA7HMY0/xbfn3yySdKSkrS9u3bdf31119xzO23366amhpt3LgxsG7ixIkaPXq0li9f3qTj+Hw+eTweVVZWyu12N7fcy9zz7D69XOzVQzOG646J/VttvwAAoOnf3y26ZqSyslKS1KNHjwbHFBYWKisrK2jdlClTVFhY2OA2tbW18vl8QQsAAAhPzQ4jfr9fCxYs0HXXXafhw4c3OM7r9So5OTloXXJysrxeb4Pb5OXlyePxBJa0tLTmlgkAADq4ZoeRnJwcFRcXKz8/vzXrkSTl5uaqsrIysJSVlbX6MQAAQMcQ3ZyN5s2bp40bN2rHjh3q169fo2NTUlJUUVERtK6iokIpKSkNbuNyueRyuZpTGgAA6GRCOjNijNG8efO0bt06bdu2TQMGDPjSbTIzM7V169agdVu2bFFmZmZolQIAgLAU0pmRnJwcrV69Whs2bFBCQkLgug+Px6O4uDhJUnZ2tvr27au8vDxJ0vz58zV58mQ98sgjmjZtmvLz87V3716tWLGilVtpgeZPKAIAAC0U0pmRZcuWqbKyUjfccIP69OkTWJ5//vnAmNLSUpWXlwdeT5o0SatXr9aKFSs0atQovfjii1q/fn2jF722F+4zAgCAfSGdGWnKLUkKCgouWzdz5kzNnDkzlEMBAIAIwbNpAACAVYQRAABgFWEEAABYRRgBAABWEUYkMbEXAAB7IjqMOMTcXgAAbIvoMAIAAOwjjAAAAKsIIwAAwCrCCAAAsIowAgAArCKMiIf2AgBgU2SHEWb2AgBgXWSHEQAAYB1hBAAAWEUYAQAAVhFGAACAVYQRAABgFWFEkmFuLwAA1kR0GGFmLwAA9kV0GAEAAPYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRSdxlBAAAeyI6jDgc3GkEAADbIjqMAAAA+wgjAADAKsIIAACwijACAACsCjmM7NixQ7feeqtSU1PlcDi0fv36RscXFBTI4XBctni93ubWDAAAwkjIYaSmpkajRo3S0qVLQ9qupKRE5eXlgSUpKSnUQ7cZw9xeAACsiQ51g6lTp2rq1KkhHygpKUmJiYkhb9eWmNgLAIB97XbNyOjRo9WnTx/ddNNNev311xsdW1tbK5/PF7QAAIDw1OZhpE+fPlq+fLn+/Oc/689//rPS0tJ0ww036K233mpwm7y8PHk8nsCSlpbW1mUCAABLQv6ZJlSDBw/W4MGDA68nTZqkDz/8UI899pj++7//+4rb5ObmauHChYHXPp+PQAIAQJhq8zByJePHj9fOnTsbfN/lcsnlcrVjRQAAwBYr9xkpKipSnz59bBwaAAB0MCGfGamurtbhw4cDr48cOaKioiL16NFD6enpys3N1fHjx/XHP/5RkvT4449rwIABGjZsmM6fP6+nn35a27Zt01//+tfW66KFmNkLAIA9IYeRvXv36hvf+Ebg9aVrO+bMmaNVq1apvLxcpaWlgffr6up077336vjx4+ratatGjhypv/3tb0H7sIWH9gIAYJ/DmI5/yy+fzyePx6PKykq53e5W2+/8/P3aUHRCP/s/QzX3awNabb8AAKDp3988mwYAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYkdQJJhQBABC2IjqMcJsRAADsi+gwAgAA7COMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrIjqMOBxM7gUAwLaIDiMAAMA+wggAALCKMAIAAKwijAAAAKsIIwAAwCrCiCQe2gsAgD0RHUaY2AsAgH0RHUYAAIB9hBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEUlGzO0FAMCWyA4jzO0FAMC6yA4jAADAOsIIAACwijACAACsCjmM7NixQ7feeqtSU1PlcDi0fv36L92moKBAY8aMkcvl0sCBA7Vq1apmlAoAAMJRyGGkpqZGo0aN0tKlS5s0/siRI5o2bZq+8Y1vqKioSAsWLNCdd96pzZs3h1wsAAAIP9GhbjB16lRNnTq1yeOXL1+uAQMG6JFHHpEkXXPNNdq5c6cee+wxTZkyJdTDAwCAMNPm14wUFhYqKysraN2UKVNUWFjY1oduMsNtRgAAsCbkMyOh8nq9Sk5ODlqXnJwsn8+nzz77THFxcZdtU1tbq9ra2sBrn8/XJrU5uNEIAADWdcjZNHl5efJ4PIElLS3NdkkAAKCNtHkYSUlJUUVFRdC6iooKud3uK54VkaTc3FxVVlYGlrKysrYuEwAAWNLmP9NkZmZq06ZNQeu2bNmizMzMBrdxuVxyuVxtXRoAAOgAQj4zUl1draKiIhUVFUn6fOpuUVGRSktLJX1+ViM7Ozsw/u6779ZHH32k++67T++9955++9vf6oUXXtCPfvSj1ukAAAB0aiGHkb179yojI0MZGRmSpIULFyojI0MPPPCAJKm8vDwQTCRpwIABeumll7RlyxaNGjVKjzzyiJ5++mmm9QIAAEnN+JnmhhtukGlkLuyV7q56ww03aP/+/aEeqt0wsxcAAHs65Gya9uJgZi8AANZFdBgBAAD2EUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRsRTewEAsCmiwwgzewEAsC+iwwgAALCPMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMSDLiRiMAANgS0WHEwY1GAACwLqLDCAAAsI8wAgAArIroMHKquk6SVH3+ouVKAACIXBEdRra9d1KS9NuCDy1XAgBA5IroMAIAAOwjjPyvq378ku0SAACISNG2C+hI/jGQvP3AzfJ07WKpGgAAIgNhpBGjHvzrFddPH52qn986TD26xbRzRQAAhB/CSDNsKDqhDUUnWryfoX3cum10qkb09WhQUrx6dItRdBS/nAEAIgthxKJD5T4dKvfZLkPDUt0akuLW+AHdFRcTrRR3rNJ7dFWv+BhFOR1ycKtaAEAbIoxAB0/4dPCET39+61ibHicjPVEDenbTyH4eXd07XtFRDpWfPa9PqmuVlOBS/57dJBkldo2RK9qphNgu6hYTJafDISOp7qJfTqfUxemUwyFCEgCECcII2s3+0rPaX3pWa/cft13Kl7q6dzfVXfRr+uhUXXtVD3XvGqNkd6zccdGKjY6S00kQAoDWQhgBruCjT2okSUtf/VBSx7opXky0U5lX99S1V3VXiidO0U6HYrtEqWtMlK7q2U1Jbpdc0U7OHAHoNAgjQCdTd9Gv7e9/ou3vf2K1joz0RE36Sk/16ObSV3p3U2LXGKW4YxUXEyVXtFMxUfycBqBpCCMAmuXSz24dncMhfW1gL00b0Uf9unfVV5Pj1TPepSh+agM6DMIIgLBmjPTaB6f02genbJdyRRnpiRrYO17jruqu7l1jdHXvbureNUbxsdHq4nRyfRIiQrPCyNKlS7VkyRJ5vV6NGjVKTz75pMaPH3/FsatWrdL3v//9oHUul0vnz59vzqFb1a2jUvWXt1t+vxAAaK5LZ5jW7Gvb2WzNleqJ1ej0RI3ql6gUT6ySEmLVNzFO8bHR6uaKIjChVYQcRp5//nktXLhQy5cv14QJE/T4449rypQpKikpUVJS0hW3cbvdKikpCbzuKL8hP377aMIIADTiROV5nTjg1aYDXtulNEmKO1YJsdEalByvgb3jFeV0qm/3OA1Mile006F41+dfe3H/e9uAaKdDXaKdMsbI6PMzaZIU7XQoOsqhaKdTTq59anMhh5FHH31Ud911V+Bsx/Lly/XSSy9p5cqV+vGPf3zFbRwOh1JSUlpWaRvgN2MACC9e33l5fdIHJ6ttl2JNr/gYxcVEKcUdK09cjNJ7dFVajzhJUjdXtPp4YtU1JloJsZ8vXWOiFe+KtvqdGFIYqaur0759+5SbmxtY53Q6lZWVpcLCwga3q66uVv/+/eX3+zVmzBj94he/0LBhwxocX1tbq9ra2sBrn6/t7lL6t4WTlfXo9jbbPwAA7elUdZ0kqez0ZyFtt/enWeoV72qLkr5USA9COXXqlOrr65WcnBy0Pjk5WV7vlU/hDR48WCtXrtSGDRv07LPPyu/3a9KkSTp2rOHfR/Py8uTxeAJLWlpaKGWGZGBSvMakJ7bZ/gEA6Ay+u2K3tWO3+VPZMjMzlZ2drdGjR2vy5Mlau3atevfuraeeeqrBbXJzc1VZWRlYysrK2rTGtT+4TqvvnNCmxwAAoCOzeeVCSD/T9OrVS1FRUaqoqAhaX1FR0eRrQrp06aKMjAwdPny4wTEul0suV/ueKpo0sJc+XjxNklTvN1pWcFi/+uv77VoDAAC2ONRJrhmJiYnR2LFjtXXrVs2YMUOS5Pf7tXXrVs2bN69J+6ivr9eBAwf0rW99K+Ri20uU06F53xyked8c1Gr7vFjv1+lzdSo/e16+8xd0uqZO71dU6VRVnWov1qukolpnaurk9dmf8gwAQHsKeTbNwoULNWfOHI0bN07jx4/X448/rpqamsDsmuzsbPXt21d5eXmSpAcffFATJ07UwIEDdfbsWS1ZskRHjx7VnXfe2bqddHDRUU4lJXw+R78j8/uN3j9ZpQ1FJ/THXR+rpq7edkkAgHZQUlFl7dghh5Hbb79dn3zyiR544AF5vV6NHj1ar7zySuCi1tLSUjmdf78U5cyZM7rrrrvk9XrVvXt3jR07Vrt27dLQoUNbrwu0GqfToSEpbg25xa37bxnSrH0YY3S6pk6r95TqkS381AUAaJzDmEu3eOm4fD6fPB6PKisr5Xa7bZeDTs4YI7+Rqmsv6kxNnQ6V+/Set0q/3vqB7dIAwJqE2Ggd+H9TWnWfTf3+5tk0iDgOh0NRDskT10WeuC66qlc3fWtEHy286ast2q8xRucv+FVSUaWt71aooOQTHThe2UpVA0Dbiu4sNz0D0DCHw6G4mCiNTkvU6LRE3Xvz4Bbtr95vVHX+gkpPn9MbR05r9Z5SfXSqppWqBYBgneYOrADaT5TTocSuMUrsGqOR/RJ159evbtX9+/1Gp2pqVfjhp9r4Trm2HKr48o0AhC3CCIB253Q6lJQQq+mj+2r66L6tuu96v1F17UXV1F7UmXN1+qCiWkdO1Wjf0TN659hZ+c5fbNXjAWi5KIsPAySMAGh1UU5H4Jqc1MQ4DUv1WKvlYr1fn1TX6oOKar2475jeKj2jY2dCe2YHEAmcnBkBgLYRHeVUH0+c+njidP1Xe7fLMf1+o88u1OtUda2On/lMe4+eUU3dRW0u9urjT8+1Sw1AqLiAFQDCiNPpUDdXtLq5otW/ZzdNGthLkpQ79ZpWPU693+jYmXM6duYz7Tx8Srs+/FRvl51t1WMgcnBmBAAQsiinQ/17dlP/nt103f8GnvZgjNG5unpV+M7L6zuv3R+dVuW5Ov2h8Gi71YDWxzUjAIBOw+H4/MzP1b3jdXXveE36yudB6D+nD2+zYxpjdKH+8+nuJ86e18ETldr14afa+/FpnajkmV6tgdk0AAA0wuFwKCbaoZ7xLvWMd2lEP4++Oz69zY53KfycrqnTqepavX74lI6cqlH+m2VtdkzbZmS07qy6UHA7eAAAOrBLj7C46PerprZeNbUXdbKqVh+fqtEbR07rzLk6fVJdq+LjlXI4HKq76G/WcT5ePK2VK2/69zdhBAAAtImmfn87G3wHAACgHRBGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVkXbLqApLj1Y2OfzWa4EAAA01aXv7Uvf4w3pFGGkqqpKkpSWlma5EgAAEKqqqip5PJ4G33eYL4srHYDf79eJEyeUkJAgh8PRavv1+XxKS0tTWVmZ3G53q+23o4q0fqXI65l+wxv9hrdw7NcYo6qqKqWmpsrpbPjKkE5xZsTpdKpfv35ttn+32x02/+ObItL6lSKvZ/oNb/Qb3sKt38bOiFzCBawAAMAqwggAALAqosOIy+XSz3/+c7lcLtultItI61eKvJ7pN7zRb3iLtH6/qFNcwAoAAMJXRJ8ZAQAA9hFGAACAVYQRAABgFWEEAABYFdFhZOnSpbrqqqsUGxurCRMm6I033rBd0mXy8vJ07bXXKiEhQUlJSZoxY4ZKSkqCxpw/f145OTnq2bOn4uPj9c///M+qqKgIGlNaWqpp06apa9euSkpK0qJFi3Tx4sWgMQUFBRozZoxcLpcGDhyoVatWXVZPe35mixcvlsPh0IIFCwLrwrHX48eP61/+5V/Us2dPxcXFacSIEdq7d2/gfWOMHnjgAfXp00dxcXHKysrSBx98ELSP06dPa/bs2XK73UpMTNTcuXNVXV0dNOadd97R17/+dcXGxiotLU2//OUvL6tlzZo1GjJkiGJjYzVixAht2rSpVXutr6/Xz372Mw0YMEBxcXH6yle+ooceeijouRWdud8dO3bo1ltvVWpqqhwOh9avXx/0fkfqrSm1tKTfCxcu6P7779eIESPUrVs3paamKjs7WydOnAjLfv/R3XffLYfDoccff7zT9tuuTITKz883MTExZuXKlebgwYPmrrvuMomJiaaiosJ2aUGmTJlinnnmGVNcXGyKiorMt771LZOenm6qq6sDY+6++26TlpZmtm7davbu3WsmTpxoJk2aFHj/4sWLZvjw4SYrK8vs37/fbNq0yfTq1cvk5uYGxnz00Uema9euZuHChebQoUPmySefNFFRUeaVV14JjGnPz+yNN94wV111lRk5cqSZP39+2PZ6+vRp079/f/O9733P7Nmzx3z00Udm8+bN5vDhw4ExixcvNh6Px6xfv968/fbb5rbbbjMDBgwwn332WWDMLbfcYkaNGmV2795tXnvtNTNw4EAza9aswPuVlZUmOTnZzJ492xQXF5s//elPJi4uzjz11FOBMa+//rqJiooyv/zlL82hQ4fMT3/6U9OlSxdz4MCBVuv34YcfNj179jQbN240R44cMWvWrDHx8fHmiSeeCIt+N23aZH7yk5+YtWvXGklm3bp1Qe93pN6aUktL+j179qzJysoyzz//vHnvvfdMYWGhGT9+vBk7dmzQPsKl3y9au3atGTVqlElNTTWPPfZYp+23PUVsGBk/frzJyckJvK6vrzepqakmLy/PYlVf7uTJk0aS2b59uzHm83/wXbp0MWvWrAmMeffdd40kU1hYaIz5/B+Q0+k0Xq83MGbZsmXG7Xab2tpaY4wx9913nxk2bFjQsW6//XYzZcqUwOv2+syqqqrMoEGDzJYtW8zkyZMDYSQce73//vvN1772tQbf9/v9JiUlxSxZsiSw7uzZs8blcpk//elPxhhjDh06ZCSZN998MzDm5ZdfNg6Hwxw/ftwYY8xvf/tb071798BncOnYgwcPDrz+zne+Y6ZNmxZ0/AkTJph///d/b1mTXzBt2jTzr//6r0Hrvv3tb5vZs2cbY8Kr33/8supIvTWllpb2eyVvvPGGkWSOHj0atv0eO3bM9O3b1xQXF5v+/fsHhZHO3G9bi8ifaerq6rRv3z5lZWUF1jmdTmVlZamwsNBiZV+usrJSktSjRw9J0r59+3ThwoWgXoYMGaL09PRAL4WFhRoxYoSSk5MDY6ZMmSKfz6eDBw8GxnxxH5fGXNpHe35mOTk5mjZt2mX1hGOv//M//6Nx48Zp5syZSkpKUkZGhn73u98F3j9y5Ii8Xm9QLR6PRxMmTAjqOTExUePGjQuMycrKktPp1J49ewJjrr/+esXExAT1XFJSojNnzgTGNPa5tIZJkyZp69atev/99yVJb7/9tnbu3KmpU6eGZb9f1JF6a0otbaGyslIOh0OJiYmBOsOpX7/frzvuuEOLFi3SsGHDLns/3PptTREZRk6dOqX6+vqgLyxJSk5OltfrtVTVl/P7/VqwYIGuu+46DR8+XJLk9XoVExMT+Md9yRd78Xq9V+z10nuNjfH5fPrss8/a7TPLz8/XW2+9pby8vMveC7deJemjjz7SsmXLNGjQIG3evFn33HOPfvjDH+oPf/hDUM2N1eL1epWUlBT0fnR0tHr06NEqn0tr9vzjH/9Y3/3udzVkyBB16dJFGRkZWrBggWbPnh1US7j0+0Udqbem1NLazp8/r/vvv1+zZs0KPAQu3Pr9r//6L0VHR+uHP/zhFd8Pt35bU6d4ai8+l5OTo+LiYu3cudN2KW2irKxM8+fP15YtWxQbG2u7nHbh9/s1btw4/eIXv5AkZWRkqLi4WMuXL9ecOXMsV9f6XnjhBT333HNavXq1hg0bpqKiIi1YsECpqalh2S8+d+HCBX3nO9+RMUbLli2zXU6b2Ldvn5544gm99dZbcjgctsvpdCLyzEivXr0UFRV12SyMiooKpaSkWKqqcfPmzdPGjRv16quvql+/foH1KSkpqqur09mzZ4PGf7GXlJSUK/Z66b3GxrjdbsXFxbXLZ7Zv3z6dPHlSY8aMUXR0tKKjo7V9+3b9+te/VnR0tJKTk8Om10v69OmjoUOHBq275pprVFpaGlRzY7WkpKTo5MmTQe9fvHhRp0+fbpXPpTV7XrRoUeDsyIgRI3THHXfoRz/6UeBMWLj1+0Udqbem1NJaLgWRo0ePasuWLYGzIpfqCJd+X3vtNZ08eVLp6emBv19Hjx7Vvffeq6uuuipQR7j029oiMozExMRo7Nix2rp1a2Cd3+/X1q1blZmZabGyyxljNG/ePK1bt07btm3TgAEDgt4fO3asunTpEtRLSUmJSktLA71kZmbqwIEDQf8ILv1RuPRFmJmZGbSPS2Mu7aM9PrMbb7xRBw4cUFFRUWAZN26cZs+eHfjvcOn1kuuuu+6yqdrvv/+++vfvL0kaMGCAUlJSgmrx+Xzas2dPUM9nz57Vvn37AmO2bdsmv9+vCRMmBMbs2LFDFy5cCOp58ODB6t69e2BMY59Lazh37pyczuA/O1FRUfL7/WHZ7xd1pN6aUktruBREPvjgA/3tb39Tz549g94Pp37vuOMOvfPOO0F/v1JTU7Vo0SJt3rw57PptdbavoLUlPz/fuFwus2rVKnPo0CHzb//2byYxMTFoFkZHcM899xiPx2MKCgpMeXl5YDl37lxgzN13323S09PNtm3bzN69e01mZqbJzMwMvH9puuvNN99sioqKzCuvvGJ69+59xemuixYtMu+++65ZunTpFae7tvdn9sXZNOHY6xtvvGGio6PNww8/bD744APz3HPPma5du5pnn302MGbx4sUmMTHRbNiwwbzzzjtm+vTpV5wOmpGRYfbs2WN27txpBg0aFDRd8OzZsyY5Odnccccdpri42OTn55uuXbteNl0wOjra/OpXvzLvvvuu+fnPf97qU3vnzJlj+vbtG5jau3btWtOrVy9z3333hUW/VVVVZv/+/Wb//v1Gknn00UfN/v37A7NHOlJvTamlJf3W1dWZ2267zfTr188UFRUF/f364kyRcOn3Sv5xNk1n67c9RWwYMcaYJ5980qSnp5uYmBgzfvx4s3v3btslXUbSFZdnnnkmMOazzz4zP/jBD0z37t1N165dzT/90z+Z8vLyoP18/PHHZurUqSYuLs706tXL3HvvvebChQtBY1599VUzevRoExMTY66++uqgY1zS3p/ZP4aRcOz1L3/5ixk+fLhxuVxmyJAhZsWKFUHv+/1+87Of/cwkJycbl8tlbrzxRlNSUhI05tNPPzWzZs0y8fHxxu12m+9///umqqoqaMzbb79tvva1rxmXy2X69u1rFi9efFktL7zwgvnqV79qYmJizLBhw8xLL73Uqr36fD4zf/58k56ebmJjY83VV19tfvKTnwR9OXXmfl999dUr/nudM2dOh+utKbW0pN8jR440+Pfr1VdfDbt+r+RKYaQz9dueHMZ84daHAAAA7SwirxkBAAAdB2EEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVf8fxeVzC0Ub2GUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([a for a in range(len(cost))],cost)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bda8a0-4cb5-4ae9-a0f1-3c4a5546b715",
   "metadata": {},
   "source": [
    "### c) get back to 50000 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8aadc2c9-a507-4766-8264-a424337246bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50000\n",
    "network2c = NeuralNetwork(input_dim,\n",
    "                        hidden_dim,\n",
    "                        output_dim,\n",
    "                        num_of_hidden_layers,\n",
    "                        activation,\n",
    "                        activation_output,\n",
    "                        initialization,\n",
    "                        output_initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bba5131a-6957-4244-a665-a06fdb3cd50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Accuracy: 0.4878048780487805 Loss: 3.387236368767095\n",
      "0. Accuracy: 0.5121951219512195 Loss: 2.0389991301378516\n",
      "0. Accuracy: 0.5853658536585366 Loss: 1.8702675785672944\n",
      "0. Accuracy: 0.36585365853658536 Loss: 1.7567479537363337\n",
      "0. Accuracy: 0.5365853658536586 Loss: 1.9479080247150125\n",
      "0. Accuracy: 0.4634146341463415 Loss: 1.7620455305110423\n",
      "500. Accuracy: 0.7317073170731707 Loss: 0.4841861715316891\n",
      "500. Accuracy: 0.6829268292682927 Loss: 0.6485404932316863\n",
      "500. Accuracy: 0.7317073170731707 Loss: 0.556480923565915\n",
      "500. Accuracy: 0.7073170731707317 Loss: 0.5923335965830938\n",
      "500. Accuracy: 0.5609756097560976 Loss: 0.6587773583663814\n",
      "500. Accuracy: 0.6341463414634146 Loss: 0.6084312766445162\n",
      "1000. Accuracy: 0.7560975609756098 Loss: 0.47881874277723757\n",
      "1000. Accuracy: 0.6829268292682927 Loss: 0.6403283684716007\n",
      "1000. Accuracy: 0.7317073170731707 Loss: 0.5441161977900213\n",
      "1000. Accuracy: 0.7073170731707317 Loss: 0.575251638099501\n",
      "1000. Accuracy: 0.5853658536585366 Loss: 0.6332669941674774\n",
      "1000. Accuracy: 0.6585365853658537 Loss: 0.5950420076705772\n",
      "1500. Accuracy: 0.7804878048780488 Loss: 0.4733049554772847\n",
      "1500. Accuracy: 0.6829268292682927 Loss: 0.6348628632523236\n",
      "1500. Accuracy: 0.6829268292682927 Loss: 0.5349527739835681\n",
      "1500. Accuracy: 0.7560975609756098 Loss: 0.5617930829086308\n",
      "1500. Accuracy: 0.6097560975609756 Loss: 0.6209676873795384\n",
      "1500. Accuracy: 0.6585365853658537 Loss: 0.5845981239833019\n",
      "2000. Accuracy: 0.7804878048780488 Loss: 0.4679482494112748\n",
      "2000. Accuracy: 0.6585365853658537 Loss: 0.6302162188014042\n",
      "2000. Accuracy: 0.7317073170731707 Loss: 0.5253416629483966\n",
      "2000. Accuracy: 0.7560975609756098 Loss: 0.5506167929232519\n",
      "2000. Accuracy: 0.6097560975609756 Loss: 0.6122753587834856\n",
      "2000. Accuracy: 0.6585365853658537 Loss: 0.5759902386925998\n",
      "2500. Accuracy: 0.7560975609756098 Loss: 0.46286106712900227\n",
      "2500. Accuracy: 0.6585365853658537 Loss: 0.6262777708812347\n",
      "2500. Accuracy: 0.7317073170731707 Loss: 0.5151756583642282\n",
      "2500. Accuracy: 0.7560975609756098 Loss: 0.5390352807548195\n",
      "2500. Accuracy: 0.6341463414634146 Loss: 0.604608821818724\n",
      "2500. Accuracy: 0.7073170731707317 Loss: 0.5692071498631674\n",
      "3000. Accuracy: 0.7804878048780488 Loss: 0.4576605596846517\n",
      "3000. Accuracy: 0.6585365853658537 Loss: 0.6211229164400164\n",
      "3000. Accuracy: 0.7560975609756098 Loss: 0.5092650344412334\n",
      "3000. Accuracy: 0.7560975609756098 Loss: 0.5274307236033745\n",
      "3000. Accuracy: 0.6341463414634146 Loss: 0.5969818584394535\n",
      "3000. Accuracy: 0.7073170731707317 Loss: 0.5637192607419927\n",
      "3500. Accuracy: 0.7560975609756098 Loss: 0.45308440495519153\n",
      "3500. Accuracy: 0.6585365853658537 Loss: 0.6149199264359836\n",
      "3500. Accuracy: 0.7560975609756098 Loss: 0.5025512331137492\n",
      "3500. Accuracy: 0.7560975609756098 Loss: 0.5183318826444023\n",
      "3500. Accuracy: 0.6585365853658537 Loss: 0.5905379864495282\n",
      "3500. Accuracy: 0.7073170731707317 Loss: 0.5583618569647244\n",
      "4000. Accuracy: 0.7804878048780488 Loss: 0.449006845624591\n",
      "4000. Accuracy: 0.6097560975609756 Loss: 0.61062973749027\n",
      "4000. Accuracy: 0.8048780487804879 Loss: 0.49355150098582506\n",
      "4000. Accuracy: 0.7560975609756098 Loss: 0.5109392198268612\n",
      "4000. Accuracy: 0.6829268292682927 Loss: 0.5856449140333526\n",
      "4000. Accuracy: 0.7073170731707317 Loss: 0.5528898752009584\n",
      "4500. Accuracy: 0.7804878048780488 Loss: 0.4443902277017213\n",
      "4500. Accuracy: 0.6097560975609756 Loss: 0.606019700116593\n",
      "4500. Accuracy: 0.8048780487804879 Loss: 0.484129796928866\n",
      "4500. Accuracy: 0.7560975609756098 Loss: 0.5044510707186252\n",
      "4500. Accuracy: 0.6829268292682927 Loss: 0.5810386417129872\n",
      "4500. Accuracy: 0.7073170731707317 Loss: 0.5488458963750554\n",
      "5000. Accuracy: 0.7804878048780488 Loss: 0.4385748987339799\n",
      "5000. Accuracy: 0.6341463414634146 Loss: 0.6019155878008866\n",
      "5000. Accuracy: 0.8048780487804879 Loss: 0.4764548699052665\n",
      "5000. Accuracy: 0.7804878048780488 Loss: 0.4985178430328679\n",
      "5000. Accuracy: 0.6585365853658537 Loss: 0.5785168206709499\n",
      "5000. Accuracy: 0.7073170731707317 Loss: 0.5446835530048681\n",
      "5500. Accuracy: 0.8048780487804879 Loss: 0.4333996897827421\n",
      "5500. Accuracy: 0.6585365853658537 Loss: 0.5980613597987384\n",
      "5500. Accuracy: 0.8292682926829268 Loss: 0.46946935961102326\n",
      "5500. Accuracy: 0.7804878048780488 Loss: 0.4934911632101712\n",
      "5500. Accuracy: 0.6585365853658537 Loss: 0.5756253868746194\n",
      "5500. Accuracy: 0.7317073170731707 Loss: 0.5408404554225682\n",
      "6000. Accuracy: 0.8048780487804879 Loss: 0.42902006085414257\n",
      "6000. Accuracy: 0.6585365853658537 Loss: 0.594836050278229\n",
      "6000. Accuracy: 0.8292682926829268 Loss: 0.46281418331943447\n",
      "6000. Accuracy: 0.7804878048780488 Loss: 0.488920665517876\n",
      "6000. Accuracy: 0.6829268292682927 Loss: 0.5732594571317985\n",
      "6000. Accuracy: 0.7317073170731707 Loss: 0.5373891228434189\n",
      "6500. Accuracy: 0.8048780487804879 Loss: 0.4248252907624424\n",
      "6500. Accuracy: 0.6585365853658537 Loss: 0.5918404404825847\n",
      "6500. Accuracy: 0.8292682926829268 Loss: 0.4567260884162294\n",
      "6500. Accuracy: 0.7560975609756098 Loss: 0.4843318910520132\n",
      "6500. Accuracy: 0.6829268292682927 Loss: 0.571064231817828\n",
      "6500. Accuracy: 0.7560975609756098 Loss: 0.5339521970068429\n",
      "7000. Accuracy: 0.8048780487804879 Loss: 0.42066732737056794\n",
      "7000. Accuracy: 0.6585365853658537 Loss: 0.5884900006031116\n",
      "7000. Accuracy: 0.8292682926829268 Loss: 0.45104606953671866\n",
      "7000. Accuracy: 0.7560975609756098 Loss: 0.47989160926431956\n",
      "7000. Accuracy: 0.7073170731707317 Loss: 0.5694981848115687\n",
      "7000. Accuracy: 0.7317073170731707 Loss: 0.5306363632283556\n",
      "7500. Accuracy: 0.8048780487804879 Loss: 0.4166971115603795\n",
      "7500. Accuracy: 0.6585365853658537 Loss: 0.5850510839873583\n",
      "7500. Accuracy: 0.8536585365853658 Loss: 0.4454245778266749\n",
      "7500. Accuracy: 0.7804878048780488 Loss: 0.47551829336942125\n",
      "7500. Accuracy: 0.7073170731707317 Loss: 0.5669147171678358\n",
      "7500. Accuracy: 0.7317073170731707 Loss: 0.52668690712917\n",
      "8000. Accuracy: 0.8292682926829268 Loss: 0.41309420588630563\n",
      "8000. Accuracy: 0.6829268292682927 Loss: 0.5817551432140258\n",
      "8000. Accuracy: 0.8536585365853658 Loss: 0.4400004627500926\n",
      "8000. Accuracy: 0.7804878048780488 Loss: 0.471261257270793\n",
      "8000. Accuracy: 0.7317073170731707 Loss: 0.5636862683934315\n",
      "8000. Accuracy: 0.7317073170731707 Loss: 0.5228407668603392\n",
      "8500. Accuracy: 0.8292682926829268 Loss: 0.40973182018684073\n",
      "8500. Accuracy: 0.6829268292682927 Loss: 0.5783095572945408\n",
      "8500. Accuracy: 0.8536585365853658 Loss: 0.4346563409449617\n",
      "8500. Accuracy: 0.8048780487804879 Loss: 0.46714891043743395\n",
      "8500. Accuracy: 0.7317073170731707 Loss: 0.56049862730957\n",
      "8500. Accuracy: 0.7317073170731707 Loss: 0.5190228346463138\n",
      "9000. Accuracy: 0.8048780487804879 Loss: 0.4062602228000736\n",
      "9000. Accuracy: 0.6829268292682927 Loss: 0.5755899773947624\n",
      "9000. Accuracy: 0.8536585365853658 Loss: 0.42893412970491634\n",
      "9000. Accuracy: 0.8048780487804879 Loss: 0.4631029137481204\n",
      "9000. Accuracy: 0.7317073170731707 Loss: 0.5572569766656366\n",
      "9000. Accuracy: 0.7560975609756098 Loss: 0.5156197030343624\n",
      "9500. Accuracy: 0.8048780487804879 Loss: 0.40324568335525046\n",
      "9500. Accuracy: 0.6829268292682927 Loss: 0.5736722439838372\n",
      "9500. Accuracy: 0.8536585365853658 Loss: 0.4232363564810472\n",
      "9500. Accuracy: 0.7804878048780488 Loss: 0.4590884730255988\n",
      "9500. Accuracy: 0.7317073170731707 Loss: 0.5539839588048755\n",
      "9500. Accuracy: 0.7560975609756098 Loss: 0.5128700064704251\n",
      "10000. Accuracy: 0.8292682926829268 Loss: 0.4004280232027025\n",
      "10000. Accuracy: 0.6829268292682927 Loss: 0.57187409658007\n",
      "10000. Accuracy: 0.9024390243902439 Loss: 0.4176783955485016\n",
      "10000. Accuracy: 0.7804878048780488 Loss: 0.4550395628786322\n",
      "10000. Accuracy: 0.7317073170731707 Loss: 0.5510694600298449\n",
      "10000. Accuracy: 0.7560975609756098 Loss: 0.5102687348624984\n",
      "10500. Accuracy: 0.8536585365853658 Loss: 0.39791786732445067\n",
      "10500. Accuracy: 0.6829268292682927 Loss: 0.5698914329060274\n",
      "10500. Accuracy: 0.926829268292683 Loss: 0.4123778100446242\n",
      "10500. Accuracy: 0.7804878048780488 Loss: 0.45097078338890806\n",
      "10500. Accuracy: 0.7317073170731707 Loss: 0.5481526196658528\n",
      "10500. Accuracy: 0.7804878048780488 Loss: 0.5077896729081526\n",
      "11000. Accuracy: 0.8536585365853658 Loss: 0.3954759733660973\n",
      "11000. Accuracy: 0.6829268292682927 Loss: 0.5682241217374173\n",
      "11000. Accuracy: 0.926829268292683 Loss: 0.40709376922139756\n",
      "11000. Accuracy: 0.7804878048780488 Loss: 0.4472493543850746\n",
      "11000. Accuracy: 0.7317073170731707 Loss: 0.5455083442772583\n",
      "11000. Accuracy: 0.7804878048780488 Loss: 0.5060868023357894\n",
      "11500. Accuracy: 0.8536585365853658 Loss: 0.39239719806947093\n",
      "11500. Accuracy: 0.7073170731707317 Loss: 0.5669337466386116\n",
      "11500. Accuracy: 0.926829268292683 Loss: 0.40200437799206273\n",
      "11500. Accuracy: 0.7804878048780488 Loss: 0.44358724031454616\n",
      "11500. Accuracy: 0.7317073170731707 Loss: 0.542818741476981\n",
      "11500. Accuracy: 0.7804878048780488 Loss: 0.5042285457605186\n",
      "12000. Accuracy: 0.8536585365853658 Loss: 0.38889336913961337\n",
      "12000. Accuracy: 0.7073170731707317 Loss: 0.5651697319250755\n",
      "12000. Accuracy: 0.926829268292683 Loss: 0.3966413279298578\n",
      "12000. Accuracy: 0.7804878048780488 Loss: 0.43972974328790204\n",
      "12000. Accuracy: 0.7317073170731707 Loss: 0.5405960765158832\n",
      "12000. Accuracy: 0.7804878048780488 Loss: 0.5025188977864209\n",
      "12500. Accuracy: 0.8536585365853658 Loss: 0.385517014618471\n",
      "12500. Accuracy: 0.7073170731707317 Loss: 0.5631503272973194\n",
      "12500. Accuracy: 0.926829268292683 Loss: 0.39119049695900066\n",
      "12500. Accuracy: 0.7804878048780488 Loss: 0.43588992149822553\n",
      "12500. Accuracy: 0.7317073170731707 Loss: 0.5385400860294719\n",
      "12500. Accuracy: 0.7804878048780488 Loss: 0.5008416981927062\n",
      "13000. Accuracy: 0.8536585365853658 Loss: 0.3820027135522445\n",
      "13000. Accuracy: 0.7073170731707317 Loss: 0.5608529314625638\n",
      "13000. Accuracy: 0.926829268292683 Loss: 0.38614227021200787\n",
      "13000. Accuracy: 0.7804878048780488 Loss: 0.432112452939303\n",
      "13000. Accuracy: 0.7317073170731707 Loss: 0.5368525118971538\n",
      "13000. Accuracy: 0.7804878048780488 Loss: 0.498988613921469\n",
      "13500. Accuracy: 0.8536585365853658 Loss: 0.3786908644497228\n",
      "13500. Accuracy: 0.7317073170731707 Loss: 0.5585156475998388\n",
      "13500. Accuracy: 0.926829268292683 Loss: 0.3812769347865721\n",
      "13500. Accuracy: 0.7804878048780488 Loss: 0.42821608406122114\n",
      "13500. Accuracy: 0.7317073170731707 Loss: 0.5350493911411114\n",
      "13500. Accuracy: 0.7804878048780488 Loss: 0.4971656839819327\n",
      "14000. Accuracy: 0.8536585365853658 Loss: 0.3758049613562309\n",
      "14000. Accuracy: 0.7317073170731707 Loss: 0.556291243751383\n",
      "14000. Accuracy: 0.926829268292683 Loss: 0.37669943315913684\n",
      "14000. Accuracy: 0.7804878048780488 Loss: 0.4241866823275333\n",
      "14000. Accuracy: 0.7317073170731707 Loss: 0.5338189374222742\n",
      "14000. Accuracy: 0.8048780487804879 Loss: 0.4952408489349273\n",
      "14500. Accuracy: 0.8536585365853658 Loss: 0.3726958544281243\n",
      "14500. Accuracy: 0.7560975609756098 Loss: 0.5540017027365614\n",
      "14500. Accuracy: 0.926829268292683 Loss: 0.3724969592628894\n",
      "14500. Accuracy: 0.7804878048780488 Loss: 0.4203998816831546\n",
      "14500. Accuracy: 0.7317073170731707 Loss: 0.5327178837255381\n",
      "14500. Accuracy: 0.8048780487804879 Loss: 0.4934782528702214\n",
      "15000. Accuracy: 0.8536585365853658 Loss: 0.3696374420794428\n",
      "15000. Accuracy: 0.7560975609756098 Loss: 0.5516876911526715\n",
      "15000. Accuracy: 0.926829268292683 Loss: 0.36831457910883547\n",
      "15000. Accuracy: 0.7804878048780488 Loss: 0.41645903963700714\n",
      "15000. Accuracy: 0.7317073170731707 Loss: 0.5314282455079294\n",
      "15000. Accuracy: 0.8048780487804879 Loss: 0.4916362290906147\n",
      "15500. Accuracy: 0.8536585365853658 Loss: 0.3667760244156804\n",
      "15500. Accuracy: 0.7560975609756098 Loss: 0.5497015986241274\n",
      "15500. Accuracy: 0.926829268292683 Loss: 0.3639604882604618\n",
      "15500. Accuracy: 0.7804878048780488 Loss: 0.4130199930272688\n",
      "15500. Accuracy: 0.7317073170731707 Loss: 0.5302333316290202\n",
      "15500. Accuracy: 0.8048780487804879 Loss: 0.48975259890505163\n",
      "16000. Accuracy: 0.8536585365853658 Loss: 0.3639634089859061\n",
      "16000. Accuracy: 0.7560975609756098 Loss: 0.5477373151891841\n",
      "16000. Accuracy: 0.926829268292683 Loss: 0.36009115646528356\n",
      "16000. Accuracy: 0.7804878048780488 Loss: 0.40950927435792156\n",
      "16000. Accuracy: 0.7560975609756098 Loss: 0.5286741981060801\n",
      "16000. Accuracy: 0.8048780487804879 Loss: 0.48835095499547165\n",
      "16500. Accuracy: 0.8536585365853658 Loss: 0.36116429161656455\n",
      "16500. Accuracy: 0.7560975609756098 Loss: 0.5458645756085112\n",
      "16500. Accuracy: 0.926829268292683 Loss: 0.35636972877550704\n",
      "16500. Accuracy: 0.7804878048780488 Loss: 0.40605486665120843\n",
      "16500. Accuracy: 0.7317073170731707 Loss: 0.527233470011856\n",
      "16500. Accuracy: 0.8292682926829268 Loss: 0.4866899437511857\n",
      "17000. Accuracy: 0.8536585365853658 Loss: 0.35865604607533785\n",
      "17000. Accuracy: 0.7560975609756098 Loss: 0.5439962676471478\n",
      "17000. Accuracy: 0.926829268292683 Loss: 0.3528814817471235\n",
      "17000. Accuracy: 0.7804878048780488 Loss: 0.4026347768756873\n",
      "17000. Accuracy: 0.7317073170731707 Loss: 0.5258819345268254\n",
      "17000. Accuracy: 0.8292682926829268 Loss: 0.4850839437129924\n",
      "17500. Accuracy: 0.8536585365853658 Loss: 0.3560845977895128\n",
      "17500. Accuracy: 0.7560975609756098 Loss: 0.5421853287429467\n",
      "17500. Accuracy: 0.926829268292683 Loss: 0.349551653315863\n",
      "17500. Accuracy: 0.7804878048780488 Loss: 0.3992897952047631\n",
      "17500. Accuracy: 0.7317073170731707 Loss: 0.5245252845561607\n",
      "17500. Accuracy: 0.8048780487804879 Loss: 0.48340208801237716\n",
      "18000. Accuracy: 0.8536585365853658 Loss: 0.35354885992600926\n",
      "18000. Accuracy: 0.7560975609756098 Loss: 0.5403399061257983\n",
      "18000. Accuracy: 0.926829268292683 Loss: 0.3462033796105149\n",
      "18000. Accuracy: 0.7804878048780488 Loss: 0.3960740314856308\n",
      "18000. Accuracy: 0.7317073170731707 Loss: 0.5227542116462202\n",
      "18000. Accuracy: 0.8048780487804879 Loss: 0.4820086933960279\n",
      "18500. Accuracy: 0.8536585365853658 Loss: 0.3511796834775564\n",
      "18500. Accuracy: 0.7560975609756098 Loss: 0.5386567272405121\n",
      "18500. Accuracy: 0.926829268292683 Loss: 0.34318770290319955\n",
      "18500. Accuracy: 0.7804878048780488 Loss: 0.3928990786130673\n",
      "18500. Accuracy: 0.7317073170731707 Loss: 0.5213340910035174\n",
      "18500. Accuracy: 0.7804878048780488 Loss: 0.48034850627393183\n",
      "19000. Accuracy: 0.8292682926829268 Loss: 0.3486850856352352\n",
      "19000. Accuracy: 0.7560975609756098 Loss: 0.5369373746214092\n",
      "19000. Accuracy: 0.926829268292683 Loss: 0.34028678065943213\n",
      "19000. Accuracy: 0.7804878048780488 Loss: 0.38981721684166787\n",
      "19000. Accuracy: 0.7317073170731707 Loss: 0.5203644969193066\n",
      "19000. Accuracy: 0.7804878048780488 Loss: 0.4789247022777532\n",
      "19500. Accuracy: 0.8292682926829268 Loss: 0.3461966694111704\n",
      "19500. Accuracy: 0.7560975609756098 Loss: 0.5351181512696029\n",
      "19500. Accuracy: 0.926829268292683 Loss: 0.3374659313461786\n",
      "19500. Accuracy: 0.7804878048780488 Loss: 0.3867879034678665\n",
      "19500. Accuracy: 0.7317073170731707 Loss: 0.5189718854992237\n",
      "19500. Accuracy: 0.7804878048780488 Loss: 0.47741834280233514\n",
      "20000. Accuracy: 0.8292682926829268 Loss: 0.34385568787931803\n",
      "20000. Accuracy: 0.7560975609756098 Loss: 0.5333938587847248\n",
      "20000. Accuracy: 0.926829268292683 Loss: 0.3347190684699459\n",
      "20000. Accuracy: 0.7804878048780488 Loss: 0.3838537098530776\n",
      "20000. Accuracy: 0.7317073170731707 Loss: 0.517240064638934\n",
      "20000. Accuracy: 0.7804878048780488 Loss: 0.47603670534056747\n",
      "20500. Accuracy: 0.8292682926829268 Loss: 0.3414282773563383\n",
      "20500. Accuracy: 0.7560975609756098 Loss: 0.5315963709487451\n",
      "20500. Accuracy: 0.926829268292683 Loss: 0.3319157226861296\n",
      "20500. Accuracy: 0.7804878048780488 Loss: 0.3809272584926203\n",
      "20500. Accuracy: 0.7317073170731707 Loss: 0.5154201378055268\n",
      "20500. Accuracy: 0.7804878048780488 Loss: 0.47486699873821625\n",
      "21000. Accuracy: 0.8292682926829268 Loss: 0.33908914477183444\n",
      "21000. Accuracy: 0.7560975609756098 Loss: 0.5297242295768737\n",
      "21000. Accuracy: 0.926829268292683 Loss: 0.3287524370954142\n",
      "21000. Accuracy: 0.7804878048780488 Loss: 0.37798351292832827\n",
      "21000. Accuracy: 0.7317073170731707 Loss: 0.5136207436040859\n",
      "21000. Accuracy: 0.7804878048780488 Loss: 0.47348965320860736\n",
      "21500. Accuracy: 0.8292682926829268 Loss: 0.3367561484614212\n",
      "21500. Accuracy: 0.7560975609756098 Loss: 0.527872974386481\n",
      "21500. Accuracy: 0.926829268292683 Loss: 0.3256040415557182\n",
      "21500. Accuracy: 0.7804878048780488 Loss: 0.3750873895618495\n",
      "21500. Accuracy: 0.7317073170731707 Loss: 0.5115209365652402\n",
      "21500. Accuracy: 0.7804878048780488 Loss: 0.4716557077903304\n",
      "22000. Accuracy: 0.8292682926829268 Loss: 0.33473639756823725\n",
      "22000. Accuracy: 0.7560975609756098 Loss: 0.5257062727404234\n",
      "22000. Accuracy: 0.926829268292683 Loss: 0.32264015919500644\n",
      "22000. Accuracy: 0.7804878048780488 Loss: 0.3722984588666795\n",
      "22000. Accuracy: 0.7317073170731707 Loss: 0.5094364892680441\n",
      "22000. Accuracy: 0.7804878048780488 Loss: 0.4701281115810988\n",
      "22500. Accuracy: 0.8292682926829268 Loss: 0.3327803907828767\n",
      "22500. Accuracy: 0.7560975609756098 Loss: 0.523815053891795\n",
      "22500. Accuracy: 0.926829268292683 Loss: 0.31958425780248806\n",
      "22500. Accuracy: 0.7804878048780488 Loss: 0.36956839357943505\n",
      "22500. Accuracy: 0.7317073170731707 Loss: 0.5072251684001944\n",
      "22500. Accuracy: 0.7804878048780488 Loss: 0.4683853070978771\n",
      "23000. Accuracy: 0.8292682926829268 Loss: 0.3308761303321388\n",
      "23000. Accuracy: 0.7560975609756098 Loss: 0.5217259780559046\n",
      "23000. Accuracy: 0.926829268292683 Loss: 0.3163481804166032\n",
      "23000. Accuracy: 0.7804878048780488 Loss: 0.3671249707488147\n",
      "23000. Accuracy: 0.7317073170731707 Loss: 0.5052292041281301\n",
      "23000. Accuracy: 0.7560975609756098 Loss: 0.46718170284803656\n",
      "23500. Accuracy: 0.8292682926829268 Loss: 0.32913509452221956\n",
      "23500. Accuracy: 0.7560975609756098 Loss: 0.5192242726396001\n",
      "23500. Accuracy: 0.926829268292683 Loss: 0.3130190187688624\n",
      "23500. Accuracy: 0.7804878048780488 Loss: 0.3649631835852058\n",
      "23500. Accuracy: 0.7317073170731707 Loss: 0.5028792060432221\n",
      "23500. Accuracy: 0.7560975609756098 Loss: 0.4655346271392479\n",
      "24000. Accuracy: 0.8292682926829268 Loss: 0.3273938459842038\n",
      "24000. Accuracy: 0.7560975609756098 Loss: 0.5172897396939198\n",
      "24000. Accuracy: 0.9512195121951219 Loss: 0.30947451327302183\n",
      "24000. Accuracy: 0.7804878048780488 Loss: 0.3624483039003502\n",
      "24000. Accuracy: 0.7317073170731707 Loss: 0.500521813983644\n",
      "24000. Accuracy: 0.7560975609756098 Loss: 0.46453537700165115\n",
      "24500. Accuracy: 0.8292682926829268 Loss: 0.3256218486643896\n",
      "24500. Accuracy: 0.7560975609756098 Loss: 0.5156994644589264\n",
      "24500. Accuracy: 0.9512195121951219 Loss: 0.3068082811778069\n",
      "24500. Accuracy: 0.7804878048780488 Loss: 0.3599494190459869\n",
      "24500. Accuracy: 0.7317073170731707 Loss: 0.49835975060295934\n",
      "24500. Accuracy: 0.7560975609756098 Loss: 0.46328590809257575\n",
      "25000. Accuracy: 0.8292682926829268 Loss: 0.3237859282229006\n",
      "25000. Accuracy: 0.7317073170731707 Loss: 0.5142544126170406\n",
      "25000. Accuracy: 0.9512195121951219 Loss: 0.3037144465286008\n",
      "25000. Accuracy: 0.8048780487804879 Loss: 0.3577739726463711\n",
      "25000. Accuracy: 0.7317073170731707 Loss: 0.49605720570255785\n",
      "25000. Accuracy: 0.7560975609756098 Loss: 0.4626087861671448\n",
      "25500. Accuracy: 0.8292682926829268 Loss: 0.32183110531181397\n",
      "25500. Accuracy: 0.7317073170731707 Loss: 0.5130852267499638\n",
      "25500. Accuracy: 0.9512195121951219 Loss: 0.3002661957867757\n",
      "25500. Accuracy: 0.8048780487804879 Loss: 0.355627553938644\n",
      "25500. Accuracy: 0.7317073170731707 Loss: 0.49392870507479747\n",
      "25500. Accuracy: 0.7560975609756098 Loss: 0.4624102763393904\n",
      "26000. Accuracy: 0.8292682926829268 Loss: 0.3198780943352353\n",
      "26000. Accuracy: 0.7317073170731707 Loss: 0.5116076691459974\n",
      "26000. Accuracy: 0.9512195121951219 Loss: 0.2971763334362934\n",
      "26000. Accuracy: 0.8048780487804879 Loss: 0.3534908485996934\n",
      "26000. Accuracy: 0.7317073170731707 Loss: 0.49154731544152935\n",
      "26000. Accuracy: 0.7560975609756098 Loss: 0.46118092253827775\n",
      "26500. Accuracy: 0.8292682926829268 Loss: 0.3181190291549551\n",
      "26500. Accuracy: 0.7317073170731707 Loss: 0.5101078937472807\n",
      "26500. Accuracy: 0.9512195121951219 Loss: 0.29492101061662895\n",
      "26500. Accuracy: 0.8048780487804879 Loss: 0.351356557512377\n",
      "26500. Accuracy: 0.7317073170731707 Loss: 0.4892958341688989\n",
      "26500. Accuracy: 0.7560975609756098 Loss: 0.4608517267454818\n",
      "27000. Accuracy: 0.8536585365853658 Loss: 0.3163988009078371\n",
      "27000. Accuracy: 0.7317073170731707 Loss: 0.509012971002843\n",
      "27000. Accuracy: 0.9512195121951219 Loss: 0.29213428041026285\n",
      "27000. Accuracy: 0.8292682926829268 Loss: 0.3494246121507535\n",
      "27000. Accuracy: 0.7560975609756098 Loss: 0.48704028499977836\n",
      "27000. Accuracy: 0.7560975609756098 Loss: 0.4604527125931935\n",
      "27500. Accuracy: 0.8536585365853658 Loss: 0.3147281139323895\n",
      "27500. Accuracy: 0.7317073170731707 Loss: 0.5081130682591881\n",
      "27500. Accuracy: 0.9512195121951219 Loss: 0.29010393949774077\n",
      "27500. Accuracy: 0.8048780487804879 Loss: 0.34776013047446036\n",
      "27500. Accuracy: 0.8048780487804879 Loss: 0.4849133815707789\n",
      "27500. Accuracy: 0.7560975609756098 Loss: 0.46061574214142625\n",
      "28000. Accuracy: 0.8536585365853658 Loss: 0.3130621384083492\n",
      "28000. Accuracy: 0.7317073170731707 Loss: 0.5072894082499174\n",
      "28000. Accuracy: 0.9512195121951219 Loss: 0.2879128509930636\n",
      "28000. Accuracy: 0.8048780487804879 Loss: 0.3461960523495535\n",
      "28000. Accuracy: 0.8048780487804879 Loss: 0.4828921825572019\n",
      "28000. Accuracy: 0.7560975609756098 Loss: 0.46044540517314814\n",
      "28500. Accuracy: 0.8536585365853658 Loss: 0.311331241082588\n",
      "28500. Accuracy: 0.7317073170731707 Loss: 0.5064397285391045\n",
      "28500. Accuracy: 0.9512195121951219 Loss: 0.28573960368419066\n",
      "28500. Accuracy: 0.8048780487804879 Loss: 0.3447294594319418\n",
      "28500. Accuracy: 0.8048780487804879 Loss: 0.4807947837624902\n",
      "28500. Accuracy: 0.7560975609756098 Loss: 0.46059952133677934\n",
      "29000. Accuracy: 0.8536585365853658 Loss: 0.30982836411750353\n",
      "29000. Accuracy: 0.7317073170731707 Loss: 0.5058593401230207\n",
      "29000. Accuracy: 0.9512195121951219 Loss: 0.28438772714561417\n",
      "29000. Accuracy: 0.8292682926829268 Loss: 0.3432139205267773\n",
      "29000. Accuracy: 0.8048780487804879 Loss: 0.47852347188954436\n",
      "29000. Accuracy: 0.7560975609756098 Loss: 0.4600160125073179\n",
      "29500. Accuracy: 0.8536585365853658 Loss: 0.3083490118749073\n",
      "29500. Accuracy: 0.7317073170731707 Loss: 0.5054465639597601\n",
      "29500. Accuracy: 0.9512195121951219 Loss: 0.282308626642187\n",
      "29500. Accuracy: 0.8292682926829268 Loss: 0.34176856499203634\n",
      "29500. Accuracy: 0.8048780487804879 Loss: 0.47620177818620896\n",
      "29500. Accuracy: 0.7560975609756098 Loss: 0.4594865055241894\n",
      "30000. Accuracy: 0.8536585365853658 Loss: 0.3071948359871559\n",
      "30000. Accuracy: 0.7317073170731707 Loss: 0.5046519417181379\n",
      "30000. Accuracy: 0.9512195121951219 Loss: 0.28053675346600493\n",
      "30000. Accuracy: 0.8292682926829268 Loss: 0.3402251697073307\n",
      "30000. Accuracy: 0.8048780487804879 Loss: 0.47388727995866486\n",
      "30000. Accuracy: 0.7560975609756098 Loss: 0.4592231753355418\n",
      "30500. Accuracy: 0.8536585365853658 Loss: 0.3058591640451395\n",
      "30500. Accuracy: 0.7317073170731707 Loss: 0.5041331552447276\n",
      "30500. Accuracy: 0.9512195121951219 Loss: 0.2788035410967532\n",
      "30500. Accuracy: 0.8292682926829268 Loss: 0.33863239829045944\n",
      "30500. Accuracy: 0.8048780487804879 Loss: 0.4718799137278485\n",
      "30500. Accuracy: 0.7560975609756098 Loss: 0.45907490196506295\n",
      "31000. Accuracy: 0.8292682926829268 Loss: 0.3045415467775231\n",
      "31000. Accuracy: 0.7317073170731707 Loss: 0.5035439076298857\n",
      "31000. Accuracy: 0.9512195121951219 Loss: 0.27754353555838257\n",
      "31000. Accuracy: 0.8292682926829268 Loss: 0.337280836617854\n",
      "31000. Accuracy: 0.8048780487804879 Loss: 0.47006536036151453\n",
      "31000. Accuracy: 0.7804878048780488 Loss: 0.4588981716199843\n",
      "31500. Accuracy: 0.8292682926829268 Loss: 0.30316043644943064\n",
      "31500. Accuracy: 0.7317073170731707 Loss: 0.5030344158414869\n",
      "31500. Accuracy: 0.9512195121951219 Loss: 0.2757952298720023\n",
      "31500. Accuracy: 0.8292682926829268 Loss: 0.3360161906040047\n",
      "31500. Accuracy: 0.8048780487804879 Loss: 0.4681826710700324\n",
      "31500. Accuracy: 0.7804878048780488 Loss: 0.45920507585738257\n",
      "32000. Accuracy: 0.8292682926829268 Loss: 0.30171132957131996\n",
      "32000. Accuracy: 0.7317073170731707 Loss: 0.5026430184177796\n",
      "32000. Accuracy: 0.9512195121951219 Loss: 0.273912577295582\n",
      "32000. Accuracy: 0.8292682926829268 Loss: 0.33487203023796736\n",
      "32000. Accuracy: 0.8048780487804879 Loss: 0.4662736263087378\n",
      "32000. Accuracy: 0.7804878048780488 Loss: 0.458776151720269\n",
      "32500. Accuracy: 0.8292682926829268 Loss: 0.30050692454555344\n",
      "32500. Accuracy: 0.7317073170731707 Loss: 0.5018429148322894\n",
      "32500. Accuracy: 0.9512195121951219 Loss: 0.27163432739708593\n",
      "32500. Accuracy: 0.8292682926829268 Loss: 0.33367767695332157\n",
      "32500. Accuracy: 0.8048780487804879 Loss: 0.4638901929443175\n",
      "32500. Accuracy: 0.7804878048780488 Loss: 0.4581796031836459\n",
      "33000. Accuracy: 0.8292682926829268 Loss: 0.2992545175564994\n",
      "33000. Accuracy: 0.7317073170731707 Loss: 0.5013485254516308\n",
      "33000. Accuracy: 0.9512195121951219 Loss: 0.27062982640532873\n",
      "33000. Accuracy: 0.8292682926829268 Loss: 0.33237661881403635\n",
      "33000. Accuracy: 0.8048780487804879 Loss: 0.46143549965143615\n",
      "33000. Accuracy: 0.7804878048780488 Loss: 0.4578509206544402\n",
      "33500. Accuracy: 0.8292682926829268 Loss: 0.29808031587700895\n",
      "33500. Accuracy: 0.7317073170731707 Loss: 0.5009352082722215\n",
      "33500. Accuracy: 0.9512195121951219 Loss: 0.2693565133182719\n",
      "33500. Accuracy: 0.8292682926829268 Loss: 0.33078417221772494\n",
      "33500. Accuracy: 0.8048780487804879 Loss: 0.459098861746701\n",
      "33500. Accuracy: 0.7804878048780488 Loss: 0.45762563805114226\n",
      "34000. Accuracy: 0.8292682926829268 Loss: 0.29663958315498135\n",
      "34000. Accuracy: 0.7317073170731707 Loss: 0.5005149184483084\n",
      "34000. Accuracy: 0.9512195121951219 Loss: 0.2674759817298371\n",
      "34000. Accuracy: 0.8292682926829268 Loss: 0.3293497156337164\n",
      "34000. Accuracy: 0.8048780487804879 Loss: 0.4563455623463259\n",
      "34000. Accuracy: 0.7804878048780488 Loss: 0.45721792283379115\n",
      "34500. Accuracy: 0.8292682926829268 Loss: 0.29545049119637373\n",
      "34500. Accuracy: 0.7560975609756098 Loss: 0.4999892846684133\n",
      "34500. Accuracy: 0.9512195121951219 Loss: 0.26606096819184777\n",
      "34500. Accuracy: 0.8292682926829268 Loss: 0.32782343675652\n",
      "34500. Accuracy: 0.8048780487804879 Loss: 0.45348525824287583\n",
      "34500. Accuracy: 0.7804878048780488 Loss: 0.45723985621569846\n",
      "35000. Accuracy: 0.8292682926829268 Loss: 0.2942943670006671\n",
      "35000. Accuracy: 0.7560975609756098 Loss: 0.4991561288714956\n",
      "35000. Accuracy: 0.9512195121951219 Loss: 0.264910095806959\n",
      "35000. Accuracy: 0.8292682926829268 Loss: 0.3262983560184235\n",
      "35000. Accuracy: 0.8048780487804879 Loss: 0.4505256114217593\n",
      "35000. Accuracy: 0.7804878048780488 Loss: 0.4564408080000944\n",
      "35500. Accuracy: 0.8292682926829268 Loss: 0.29314216536084725\n",
      "35500. Accuracy: 0.7560975609756098 Loss: 0.49875164999320265\n",
      "35500. Accuracy: 0.9512195121951219 Loss: 0.26315206618144654\n",
      "35500. Accuracy: 0.8292682926829268 Loss: 0.32495415802544386\n",
      "35500. Accuracy: 0.8048780487804879 Loss: 0.4478075379296375\n",
      "35500. Accuracy: 0.7804878048780488 Loss: 0.45651575419010615\n",
      "36000. Accuracy: 0.8536585365853658 Loss: 0.29166648327945655\n",
      "36000. Accuracy: 0.7560975609756098 Loss: 0.4981410644978689\n",
      "36000. Accuracy: 0.9512195121951219 Loss: 0.26174014954604535\n",
      "36000. Accuracy: 0.8292682926829268 Loss: 0.3237238275321773\n",
      "36000. Accuracy: 0.8048780487804879 Loss: 0.4452593639970272\n",
      "36000. Accuracy: 0.7804878048780488 Loss: 0.4561950451421525\n",
      "36500. Accuracy: 0.8536585365853658 Loss: 0.29032304805017484\n",
      "36500. Accuracy: 0.7560975609756098 Loss: 0.4976504697011733\n",
      "36500. Accuracy: 0.9512195121951219 Loss: 0.26085981007274195\n",
      "36500. Accuracy: 0.8292682926829268 Loss: 0.32262437534854177\n",
      "36500. Accuracy: 0.8292682926829268 Loss: 0.4428657134723853\n",
      "36500. Accuracy: 0.7804878048780488 Loss: 0.4556899802294007\n",
      "37000. Accuracy: 0.8536585365853658 Loss: 0.2890174553928232\n",
      "37000. Accuracy: 0.7560975609756098 Loss: 0.49694139354456\n",
      "37000. Accuracy: 0.9512195121951219 Loss: 0.2587410634307445\n",
      "37000. Accuracy: 0.8292682926829268 Loss: 0.32142427279475155\n",
      "37000. Accuracy: 0.8292682926829268 Loss: 0.4402846548867242\n",
      "37000. Accuracy: 0.7804878048780488 Loss: 0.45515629839950694\n",
      "37500. Accuracy: 0.8536585365853658 Loss: 0.28769045707331214\n",
      "37500. Accuracy: 0.7560975609756098 Loss: 0.49656802591366667\n",
      "37500. Accuracy: 0.9512195121951219 Loss: 0.2573873860400606\n",
      "37500. Accuracy: 0.8292682926829268 Loss: 0.3202340320465617\n",
      "37500. Accuracy: 0.8292682926829268 Loss: 0.4378272848689408\n",
      "37500. Accuracy: 0.7804878048780488 Loss: 0.454645422418229\n",
      "38000. Accuracy: 0.8536585365853658 Loss: 0.28671719343154056\n",
      "38000. Accuracy: 0.7560975609756098 Loss: 0.49604148508859786\n",
      "38000. Accuracy: 0.975609756097561 Loss: 0.2568814100775643\n",
      "38000. Accuracy: 0.8292682926829268 Loss: 0.31904939077963823\n",
      "38000. Accuracy: 0.8292682926829268 Loss: 0.4355123922362827\n",
      "38000. Accuracy: 0.7804878048780488 Loss: 0.45357011941042014\n",
      "38500. Accuracy: 0.8536585365853658 Loss: 0.28622494209835747\n",
      "38500. Accuracy: 0.7560975609756098 Loss: 0.49539952523240494\n",
      "38500. Accuracy: 0.975609756097561 Loss: 0.25433273711564225\n",
      "38500. Accuracy: 0.8292682926829268 Loss: 0.3180021303849052\n",
      "38500. Accuracy: 0.8292682926829268 Loss: 0.4330485102327727\n",
      "38500. Accuracy: 0.7804878048780488 Loss: 0.45358329558198907\n",
      "39000. Accuracy: 0.8536585365853658 Loss: 0.28579666118005176\n",
      "39000. Accuracy: 0.7560975609756098 Loss: 0.4949240751589806\n",
      "39000. Accuracy: 0.975609756097561 Loss: 0.25316540028327505\n",
      "39000. Accuracy: 0.8292682926829268 Loss: 0.3168673356627227\n",
      "39000. Accuracy: 0.8292682926829268 Loss: 0.43065153187422023\n",
      "39000. Accuracy: 0.7804878048780488 Loss: 0.4528339337680971\n",
      "39500. Accuracy: 0.8536585365853658 Loss: 0.285226125370008\n",
      "39500. Accuracy: 0.7560975609756098 Loss: 0.49514635986089583\n",
      "39500. Accuracy: 0.975609756097561 Loss: 0.25163832588633084\n",
      "39500. Accuracy: 0.8292682926829268 Loss: 0.31531210960986533\n",
      "39500. Accuracy: 0.8292682926829268 Loss: 0.428412831139323\n",
      "39500. Accuracy: 0.7804878048780488 Loss: 0.45258081711143483\n",
      "40000. Accuracy: 0.8536585365853658 Loss: 0.2844616259764929\n",
      "40000. Accuracy: 0.7560975609756098 Loss: 0.4951293473500427\n",
      "40000. Accuracy: 0.975609756097561 Loss: 0.2504130944514643\n",
      "40000. Accuracy: 0.8292682926829268 Loss: 0.31406062441678645\n",
      "40000. Accuracy: 0.8292682926829268 Loss: 0.42591501621200967\n",
      "40000. Accuracy: 0.7804878048780488 Loss: 0.4523200055113235\n",
      "40500. Accuracy: 0.8536585365853658 Loss: 0.28357967335491213\n",
      "40500. Accuracy: 0.7560975609756098 Loss: 0.4956460968389902\n",
      "40500. Accuracy: 0.975609756097561 Loss: 0.24912484311168415\n",
      "40500. Accuracy: 0.8292682926829268 Loss: 0.31265006572141973\n",
      "40500. Accuracy: 0.8292682926829268 Loss: 0.4235798864970587\n",
      "40500. Accuracy: 0.7804878048780488 Loss: 0.4516574165095602\n",
      "41000. Accuracy: 0.8536585365853658 Loss: 0.28267283252463965\n",
      "41000. Accuracy: 0.7560975609756098 Loss: 0.4952470318912675\n",
      "41000. Accuracy: 0.975609756097561 Loss: 0.24791842819890977\n",
      "41000. Accuracy: 0.8292682926829268 Loss: 0.31120295091653416\n",
      "41000. Accuracy: 0.8292682926829268 Loss: 0.42160201240944783\n",
      "41000. Accuracy: 0.7804878048780488 Loss: 0.45145886987322437\n",
      "41500. Accuracy: 0.8536585365853658 Loss: 0.2820036784988601\n",
      "41500. Accuracy: 0.7560975609756098 Loss: 0.49461317082487694\n",
      "41500. Accuracy: 0.975609756097561 Loss: 0.2466350528897211\n",
      "41500. Accuracy: 0.8292682926829268 Loss: 0.3098541339963961\n",
      "41500. Accuracy: 0.8292682926829268 Loss: 0.41979959835771763\n",
      "41500. Accuracy: 0.7804878048780488 Loss: 0.45069988128765553\n",
      "42000. Accuracy: 0.8536585365853658 Loss: 0.28129666273261433\n",
      "42000. Accuracy: 0.7560975609756098 Loss: 0.49350396275888747\n",
      "42000. Accuracy: 0.975609756097561 Loss: 0.24474140105388334\n",
      "42000. Accuracy: 0.8292682926829268 Loss: 0.30865188448762804\n",
      "42000. Accuracy: 0.8292682926829268 Loss: 0.4180488427097236\n",
      "42000. Accuracy: 0.7804878048780488 Loss: 0.45095906770905886\n",
      "42500. Accuracy: 0.8536585365853658 Loss: 0.2804121062923529\n",
      "42500. Accuracy: 0.7560975609756098 Loss: 0.49238222840370277\n",
      "42500. Accuracy: 0.975609756097561 Loss: 0.24389452222464808\n",
      "42500. Accuracy: 0.8292682926829268 Loss: 0.30728864411297335\n",
      "42500. Accuracy: 0.8292682926829268 Loss: 0.4163073442119762\n",
      "42500. Accuracy: 0.7804878048780488 Loss: 0.4507914604053303\n",
      "43000. Accuracy: 0.8536585365853658 Loss: 0.27940075682485127\n",
      "43000. Accuracy: 0.7560975609756098 Loss: 0.49204567882628714\n",
      "43000. Accuracy: 0.975609756097561 Loss: 0.24360949109794228\n",
      "43000. Accuracy: 0.8292682926829268 Loss: 0.3055768027595619\n",
      "43000. Accuracy: 0.8292682926829268 Loss: 0.4144765128392793\n",
      "43000. Accuracy: 0.7804878048780488 Loss: 0.45030439225025326\n",
      "43500. Accuracy: 0.8536585365853658 Loss: 0.2784769277847991\n",
      "43500. Accuracy: 0.7560975609756098 Loss: 0.4916151183486703\n",
      "43500. Accuracy: 0.975609756097561 Loss: 0.2420963355915745\n",
      "43500. Accuracy: 0.8292682926829268 Loss: 0.30382115414237665\n",
      "43500. Accuracy: 0.8292682926829268 Loss: 0.4125333813776752\n",
      "43500. Accuracy: 0.7804878048780488 Loss: 0.45121870121921426\n",
      "44000. Accuracy: 0.8536585365853658 Loss: 0.27743792832512254\n",
      "44000. Accuracy: 0.7560975609756098 Loss: 0.491289880640058\n",
      "44000. Accuracy: 0.975609756097561 Loss: 0.24041740228508865\n",
      "44000. Accuracy: 0.8292682926829268 Loss: 0.30259741233976845\n",
      "44000. Accuracy: 0.8536585365853658 Loss: 0.41093847965794605\n",
      "44000. Accuracy: 0.7804878048780488 Loss: 0.4518549122514083\n",
      "44500. Accuracy: 0.8536585365853658 Loss: 0.27656967351888717\n",
      "44500. Accuracy: 0.7560975609756098 Loss: 0.490818166567055\n",
      "44500. Accuracy: 0.975609756097561 Loss: 0.23946233437892014\n",
      "44500. Accuracy: 0.8292682926829268 Loss: 0.3021530469579855\n",
      "44500. Accuracy: 0.8536585365853658 Loss: 0.40926140366150154\n",
      "44500. Accuracy: 0.7804878048780488 Loss: 0.4526443798042622\n",
      "45000. Accuracy: 0.8780487804878049 Loss: 0.2762831211122145\n",
      "45000. Accuracy: 0.7560975609756098 Loss: 0.48922740083020666\n",
      "45000. Accuracy: 0.975609756097561 Loss: 0.23746954530650907\n",
      "45000. Accuracy: 0.8292682926829268 Loss: 0.3018596803565234\n",
      "45000. Accuracy: 0.8536585365853658 Loss: 0.4069945941790533\n",
      "45000. Accuracy: 0.7804878048780488 Loss: 0.45245823069612723\n",
      "45500. Accuracy: 0.8780487804878049 Loss: 0.2762647222812433\n",
      "45500. Accuracy: 0.7560975609756098 Loss: 0.48748974946492707\n",
      "45500. Accuracy: 0.975609756097561 Loss: 0.23546799647926228\n",
      "45500. Accuracy: 0.8292682926829268 Loss: 0.30133589001302485\n",
      "45500. Accuracy: 0.8536585365853658 Loss: 0.40485542129715874\n",
      "45500. Accuracy: 0.7804878048780488 Loss: 0.45351657344192176\n",
      "46000. Accuracy: 0.8780487804878049 Loss: 0.2754723873489467\n",
      "46000. Accuracy: 0.7560975609756098 Loss: 0.4868022358126546\n",
      "46000. Accuracy: 0.975609756097561 Loss: 0.23322900934657592\n",
      "46000. Accuracy: 0.8292682926829268 Loss: 0.30159755833783664\n",
      "46000. Accuracy: 0.8536585365853658 Loss: 0.40229927435307594\n",
      "46000. Accuracy: 0.7804878048780488 Loss: 0.4533866821408866\n",
      "46500. Accuracy: 0.8780487804878049 Loss: 0.2750960237534889\n",
      "46500. Accuracy: 0.7317073170731707 Loss: 0.485800880719082\n",
      "46500. Accuracy: 0.975609756097561 Loss: 0.2314625470820115\n",
      "46500. Accuracy: 0.8292682926829268 Loss: 0.30142094223256294\n",
      "46500. Accuracy: 0.8536585365853658 Loss: 0.4005396067595843\n",
      "46500. Accuracy: 0.7804878048780488 Loss: 0.452609392440758\n",
      "47000. Accuracy: 0.8780487804878049 Loss: 0.27429743925062433\n",
      "47000. Accuracy: 0.7317073170731707 Loss: 0.4851472981155088\n",
      "47000. Accuracy: 0.975609756097561 Loss: 0.22922750896204802\n",
      "47000. Accuracy: 0.8292682926829268 Loss: 0.3003820781557737\n",
      "47000. Accuracy: 0.8536585365853658 Loss: 0.3992741949575749\n",
      "47000. Accuracy: 0.7804878048780488 Loss: 0.45179181170272825\n",
      "47500. Accuracy: 0.8780487804878049 Loss: 0.2736356060629301\n",
      "47500. Accuracy: 0.7317073170731707 Loss: 0.4840467639757848\n",
      "47500. Accuracy: 0.975609756097561 Loss: 0.22708253011374746\n",
      "47500. Accuracy: 0.8536585365853658 Loss: 0.29953867847381976\n",
      "47500. Accuracy: 0.8536585365853658 Loss: 0.39851721430314396\n",
      "47500. Accuracy: 0.7804878048780488 Loss: 0.4508563844632233\n",
      "48000. Accuracy: 0.8780487804878049 Loss: 0.2727122265019369\n",
      "48000. Accuracy: 0.7317073170731707 Loss: 0.4828382818087413\n",
      "48000. Accuracy: 0.975609756097561 Loss: 0.22526821942307027\n",
      "48000. Accuracy: 0.8536585365853658 Loss: 0.29993762823865\n",
      "48000. Accuracy: 0.8536585365853658 Loss: 0.39609262236285575\n",
      "48000. Accuracy: 0.7804878048780488 Loss: 0.4498636257288836\n",
      "48500. Accuracy: 0.8780487804878049 Loss: 0.2718220472618856\n",
      "48500. Accuracy: 0.7317073170731707 Loss: 0.4843510229528168\n",
      "48500. Accuracy: 0.975609756097561 Loss: 0.22546242057359941\n",
      "48500. Accuracy: 0.8536585365853658 Loss: 0.29755382422081456\n",
      "48500. Accuracy: 0.8536585365853658 Loss: 0.3944768037205801\n",
      "48500. Accuracy: 0.7804878048780488 Loss: 0.4490004604676231\n",
      "49000. Accuracy: 0.8780487804878049 Loss: 0.2710843863533529\n",
      "49000. Accuracy: 0.7317073170731707 Loss: 0.483044231916393\n",
      "49000. Accuracy: 0.975609756097561 Loss: 0.22372382401466262\n",
      "49000. Accuracy: 0.8536585365853658 Loss: 0.2978045431919665\n",
      "49000. Accuracy: 0.8536585365853658 Loss: 0.39243276333085064\n",
      "49000. Accuracy: 0.7804878048780488 Loss: 0.4487992970362582\n",
      "49500. Accuracy: 0.8780487804878049 Loss: 0.2705902181796144\n",
      "49500. Accuracy: 0.7317073170731707 Loss: 0.4821607045758489\n",
      "49500. Accuracy: 0.975609756097561 Loss: 0.22201728301804582\n",
      "49500. Accuracy: 0.8536585365853658 Loss: 0.2980878209292264\n",
      "49500. Accuracy: 0.8536585365853658 Loss: 0.3902305726693467\n",
      "49500. Accuracy: 0.7804878048780488 Loss: 0.44868959979695117\n"
     ]
    }
   ],
   "source": [
    "train = Train(network2c, learning_rate, batch_size, epochs, loss_function)\n",
    "cost, accuracies = train.train(inputs_train, outputs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "13469057-7054-4666-acae-b246178911b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAGdCAYAAADJ6dNTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAAArEUlEQVR4nO3dfXhU5Z3/8c/kaQiSmQQhD0BCg8EgzxB5CFbBNYopa2HrT5F6NdRVulrYnyxWa9xWq726cUut+rMUcK1md1saHyrQIkoxGFAJVigRAhoFgfCQBAQykwQIIbl/f1CmjiQhExLmTub9uq5zXc45933Od24nno9nzrnHYYwxAgAAsERYsAsAAAD4MsIJAACwCuEEAABYhXACAACsQjgBAABWIZwAAACrEE4AAIBVCCcAAMAqEcEuoC2ampp06NAhxcTEyOFwBLscAADQBsYY1dTUqF+/fgoLa/v1kC4RTg4dOqTk5ORglwEAANph//79GjBgQJvbBxROFi9erMWLF2vv3r2SpGHDhunRRx9VdnZ2s+3z8/N11113+a1zOp06depUIIdVTEyMpLNvzuVyBdQXAAAEh9frVXJysu883lYBhZMBAwboySef1ODBg2WM0X//939r+vTp2rp1q4YNG9ZsH5fLpbKyMt/r9nwtc66Py+UinAAA0MUEeu4PKJzccsstfq9/9rOfafHixdq0aVOL4cThcCgxMTGgogAAQOhq99M6jY2NKigoUF1dnTIzM1tsV1tbq4EDByo5OVnTp0/Xjh07Lrjv+vp6eb1evwUAAISGgMPJ9u3b1atXLzmdTt17771avny5hg4d2mzb9PR0vfjii1q5cqV++9vfqqmpSZMmTdKBAwdaPUZeXp7cbrdv4WZYAABCh8MYYwLpcPr0aZWXl8vj8ei1117TCy+8oPXr17cYUL6soaFBV111lWbNmqWf/vSnLbarr69XfX297/W5G2o8Hg/3nAAA0EV4vV653e6Az98BP0ocFRWltLQ0SVJGRoY+/PBDPfvss1q6dOkF+0ZGRmrMmDHatWtXq+2cTqecTmegpQEAgG7gomeIbWpq8rvK0ZrGxkZt375dSUlJF3tYAADQTQV05SQ3N1fZ2dlKSUlRTU2Nli1bpqKiIq1Zs0aSlJOTo/79+ysvL0+S9MQTT2jixIlKS0tTdXW1Fi5cqH379umee+7p+HcCAAC6hYDCyeHDh5WTk6OKigq53W6NHDlSa9as0Y033ihJKi8v95ue9vjx45ozZ44qKysVFxenjIwMbdy4sU33pwAAgNAU8A2xwdDeG2oAAEDwtPf8za8SAwAAqxBOAACAVQgnAADAKgHPc9Kd/Oa9PTpw/IRmjkvWkETuZQEAwAYhfeXkjW2H9NL7e1V+9ESwSwEAAH8T0uEEAADYh3ACAACsQjgBAABWIZwAAACrEE4AAIBVCCcAAMAqhBMAAGAVwgkAALAK4USS9T/LDABACAnpcOJwOIJdAgAA+IqQDicAAMA+hBMAAGAVwgkAALAK4QQAAFiFcAIAAKxCOAEAAFYhnAAAAKsQTgAAgFUIJ5IMU8QCAGANwgkAALBKSIcTJq8HAMA+IR1OAACAfQgnAADAKoQTAABgFcIJAACwCuEEAABYhXACAACsQjgBAABWIZxIkpgiFgAAWxBOAACAVUI6nDiYIhYAAOuEdDgBAAD2IZwAAACrEE4AAIBVCCcAAMAqhBMAAGAVwgkAALBKQOFk8eLFGjlypFwul1wulzIzM/Xmm2+22ufVV1/VkCFD1KNHD40YMUKrV6++qIIBAED3FlA4GTBggJ588klt2bJFmzdv1j/8wz9o+vTp2rFjR7PtN27cqFmzZunuu+/W1q1bNWPGDM2YMUOlpaUdUnxHMUwQCwCANRzGXNypuXfv3lq4cKHuvvvu87bNnDlTdXV1WrVqlW/dxIkTNXr0aC1ZsqTNx/B6vXK73fJ4PHK5XBdTrp/blmzUh3uPa/GdY5U9IqnD9gsAANp//m73PSeNjY0qKChQXV2dMjMzm21TXFysrKwsv3VTp05VcXFxq/uur6+X1+v1WwAAQGgIOJxs375dvXr1ktPp1L333qvly5dr6NChzbatrKxUQkKC37qEhARVVla2eoy8vDy53W7fkpycHGiZbeIQ89cDAGCbgMNJenq6SkpK9MEHH+i+++7T7NmztXPnzg4tKjc3Vx6Px7fs37+/Q/cPAADsFRFoh6ioKKWlpUmSMjIy9OGHH+rZZ5/V0qVLz2ubmJioqqoqv3VVVVVKTExs9RhOp1NOpzPQ0gAAQDdw0fOcNDU1qb6+vtltmZmZKiws9Fu3du3aFu9RAQAACOjKSW5urrKzs5WSkqKamhotW7ZMRUVFWrNmjSQpJydH/fv3V15eniTp/vvv1+TJk/XUU09p2rRpKigo0ObNm/X88893/DsBAADdQkDh5PDhw8rJyVFFRYXcbrdGjhypNWvW6MYbb5QklZeXKyzs7xdjJk2apGXLlulHP/qRHnnkEQ0ePFgrVqzQ8OHDO/ZdAACAbiOgcPKb3/ym1e1FRUXnrbvtttt02223BVQUAAAIXfy2jiQmiAUAwB6EEwAAYBXCCQAAsEpohxMmiAUAwDqhHU4AAIB1CCcAAMAqhBMAAGAVwgkAALAK4QQAAFiFcAIAAKxCOJFkmCIWAABrEE4AAIBVCCcAAMAqhBMAAGCVkA4nzF4PAIB9QjqcAAAA+xBOAACAVQgnAADAKoQTAABgFcIJAACwCuFEkhFTxAIAYAvCCQAAsArhBAAAWIVwAgAArBLS4cTBFLEAAFgnpMMJAACwD+EEAABYhXACAACsQjgBAABWIZwAAACrEE4kGSaIBQDAGoQTAABgFcIJAACwCuEEAABYJaTDiUNMEQsAgG1COpwAAAD7EE4AAIBVCCcAAMAqhBMAAGAVwgkAALAK4QQAAFiFcCKJ2esBALBHQOEkLy9P48aNU0xMjOLj4zVjxgyVlZW12ic/P18Oh8Nv6dGjx0UVDQAAuq+Awsn69es1d+5cbdq0SWvXrlVDQ4Nuuukm1dXVtdrP5XKpoqLCt+zbt++iigYAAN1XRCCN33rrLb/X+fn5io+P15YtW3Tddde12M/hcCgxMbF9FQIAgJByUfeceDweSVLv3r1bbVdbW6uBAwcqOTlZ06dP144dO1ptX19fL6/X67d0Bgez1wMAYJ12h5OmpibNnz9f11xzjYYPH95iu/T0dL344otauXKlfvvb36qpqUmTJk3SgQMHWuyTl5cnt9vtW5KTk9tbJgAA6GLaHU7mzp2r0tJSFRQUtNouMzNTOTk5Gj16tCZPnqzXX39dffv21dKlS1vsk5ubK4/H41v279/f3jIBAEAXE9A9J+fMmzdPq1at0oYNGzRgwICA+kZGRmrMmDHatWtXi22cTqecTmd7SgMAAF1cQFdOjDGaN2+eli9frnXr1ik1NTXgAzY2Nmr79u1KSkoKuC8AAOj+ArpyMnfuXC1btkwrV65UTEyMKisrJUlut1vR0dGSpJycHPXv3195eXmSpCeeeEITJ05UWlqaqqurtXDhQu3bt0/33HNPB78VAADQHQQUThYvXixJmjJlit/6l156Sd/97nclSeXl5QoL+/sFmePHj2vOnDmqrKxUXFycMjIytHHjRg0dOvTiKu9AxjBHLAAAtggonLTlJF5UVOT3+umnn9bTTz8dUFEAACB08ds6AADAKoQTAABglZAOJ8wQCwCAfUI6nAAAAPsQTgAAgFUIJwAAwCqEEwAAYBXCCQAAsArhBAAAWIVwAgAArEI4AQAAViGcAAAAqxBOAACAVUI6nDjE/PUAANgmpMMJAACwD+EEAABYhXACAACsQjgBAABWIZxIMibYFQAAgHMIJwAAwCqEEwAAYBXCCQAAsArhBAAAWCWkw4mDCWIBALBOSIcTAABgH8IJAACwCuEEAABYhXACAACsQjiRZMQUsQAA2IJwAgAArEI4AQAAViGcAAAAqxBOAACAVQgnAADAKoQTAABgFcIJAACwCuEEAABYhXACAACsQjiRZJggFgAAaxBOAACAVQgnAADAKoQTAABglYDCSV5ensaNG6eYmBjFx8drxowZKisru2C/V199VUOGDFGPHj00YsQIrV69ut0FAwCA7i2gcLJ+/XrNnTtXmzZt0tq1a9XQ0KCbbrpJdXV1LfbZuHGjZs2apbvvvltbt27VjBkzNGPGDJWWll508QAAoPtxGNP+Z1WOHDmi+Ph4rV+/Xtddd12zbWbOnKm6ujqtWrXKt27ixIkaPXq0lixZ0qbjeL1eud1ueTweuVyu9pZ7npwX/6INnx7RL28fpW+NHdBh+wUAAO0/f1/UPScej0eS1Lt37xbbFBcXKysry2/d1KlTVVxc3GKf+vp6eb1evwUAAISGdoeTpqYmzZ8/X9dcc42GDx/eYrvKykolJCT4rUtISFBlZWWLffLy8uR2u31LcnJye8sEAABdTLvDydy5c1VaWqqCgoKOrEeSlJubK4/H41v279/f4ccAAAB2imhPp3nz5mnVqlXasGGDBgxo/V6NxMREVVVV+a2rqqpSYmJii32cTqecTmd7SmsXZogFAMAeAV05McZo3rx5Wr58udatW6fU1NQL9snMzFRhYaHfurVr1yozMzOwSgEAQEgI6MrJ3LlztWzZMq1cuVIxMTG++0bcbreio6MlSTk5Oerfv7/y8vIkSffff78mT56sp556StOmTVNBQYE2b96s559/voPfCgAA6A4CunKyePFieTweTZkyRUlJSb7l5Zdf9rUpLy9XRUWF7/WkSZO0bNkyPf/88xo1apRee+01rVixotWbaAEAQOgK6MpJW6ZEKSoqOm/dbbfdpttuuy2QQwEAgBDFb+sAAACrEE4AAIBVQjqcOIJdAAAAOE9IhxMAAGAfwgkAALAK4UQSE8QCAGAPwgkAALAK4QQAAFiFcAIAAKxCOAEAAFYhnAAAAKsQTgAAgFVCOpw4mCIWAADrhHQ4AQAA9iGcAAAAqxBOJBnDHLEAANiCcAIAAKxCOAEAAFYhnAAAAKsQTgAAgFUIJwAAwCqEEwAAYJWQDidMEAsAgH1COpwAAAD7EE4AAIBVCCeSmB8WAAB7EE4AAIBVCCcAAMAqhBMAAGAVwgkAALAK4QQAAFiFcAIAAKxCOAEAAFYJ6XDicDCBPQAAtgnpcAIAAOxDOJGYIhYAAIsQTgAAgFUIJwAAwCqEEwAAYBXCCQAAsArhBAAAWIVwAgAArBJwONmwYYNuueUW9evXTw6HQytWrGi1fVFRkRwOx3lLZWVle2sGAADdWMDhpK6uTqNGjdKiRYsC6ldWVqaKigrfEh8fH+ihOxzzwwIAYJ+IQDtkZ2crOzs74APFx8crNjY24H4AACC0XLJ7TkaPHq2kpCTdeOONev/991ttW19fL6/X67d0JsMUsQAAWKPTw0lSUpKWLFmiP/zhD/rDH/6g5ORkTZkyRX/9619b7JOXlye32+1bkpOTO7tMAABgiYC/1glUenq60tPTfa8nTZqk3bt36+mnn9b//u//NtsnNzdXCxYs8L32er0EFAAAQkSnh5PmjB8/Xu+9916L251Op5xO5yWsCAAA2CIo85yUlJQoKSkpGIcGAACWC/jKSW1trXbt2uV7vWfPHpWUlKh3795KSUlRbm6uDh48qP/5n/+RJD3zzDNKTU3VsGHDdOrUKb3wwgtat26d/vznP3fcuwAAAN1GwOFk8+bNuv76632vz90bMnv2bOXn56uiokLl5eW+7adPn9YDDzyggwcPqmfPnho5cqTefvttv30AAACc4zDGWP8crdfrldvtlsfjkcvl6rD93p3/oQo/Oaz/vHWEZo5L6bD9AgCA9p+/+W0dAABglZAOJw7mrwcAwDohHU7Osf+LLQAAQgfhBAAAWIVwAgAArEI4AQAAViGcAAAAqxBOAACAVQgnAADAKoQTAABgFcIJAACwSoiHE6aIBQDANiEeTs5iglgAAOxBOAEAAFYhnAAAAKsQTgAAgFUIJwAAwCqEEwAAYBXCCQAAsArhBAAAWIVwAgAArEI4AQAAVgnpcOL42+z1hiliAQCwRkiHEwAAYB/CCQAAsArhBAAAWIVwAgAArEI4AQAAViGcAAAAqxBOAACAVQgnAADAKoQTAABglZAOJ45gFwAAAM4T0uHkHCPmrwcAwBaEEwAAYBXCCQAAsArhBAAAWIVwAgAArEI4AQAAViGcAAAAqxBOAACAVQgnAADAKgGHkw0bNuiWW25Rv3795HA4tGLFigv2KSoq0tixY+V0OpWWlqb8/Px2lNrxHEwRCwCAdQIOJ3V1dRo1apQWLVrUpvZ79uzRtGnTdP3116ukpETz58/XPffcozVr1gRcbGcxTBALAIA1IgLtkJ2drezs7Da3X7JkiVJTU/XUU09Jkq666iq99957evrppzV16tRADw8AALq5Tr/npLi4WFlZWX7rpk6dquLi4hb71NfXy+v1+i0AACA0dHo4qaysVEJCgt+6hIQEeb1enTx5stk+eXl5crvdviU5ObmzywQAAJaw8mmd3NxceTwe37J///5glwQAAC6RgO85CVRiYqKqqqr81lVVVcnlcik6OrrZPk6nU06ns7NLAwAAFur0KyeZmZkqLCz0W7d27VplZmZ29qEBAEAXFHA4qa2tVUlJiUpKSiSdfVS4pKRE5eXlks5+JZOTk+Nrf++99+rzzz/XQw89pE8++US//vWv9corr+jf/u3fOuYdAACAbiXgcLJ582aNGTNGY8aMkSQtWLBAY8aM0aOPPipJqqio8AUVSUpNTdUbb7yhtWvXatSoUXrqqaf0wgsv8BgxAABoVsD3nEyZMkWmlVnLmpv9dcqUKdq6dWughwIAACHIyqd1LhWHzs5fzwSxAADYI6TDCQAAsA/hBAAAWIVwAgAArEI4AQAAViGcAAAAqxBOAACAVQgnAADAKoQTAABglZAOJ2/tqJQkbd57LMiVAACAc0I6nJyzsuRQsEsAAAB/QzgBAABWIZwAAACrEE4AAIBVCCcAAMAqhBMAAGAVwgkAALAK4QQAAFiFcAIAAKxCOAEAAFYhnPzNqYbGYJcAAABEOPH5tKom2CUAAAARTnyeffuzYJcAAABEOPEp/ORwsEsAAAAinAAAAMsQTr5k+GNrgl0CAAAhj3DyJbX1Z9TYZIJdBgAAIY1w8hVXPLJaJ0/zWDEAAMFCOGnGVY++pdKDnmCXAQBASIoIdgG2+sfn3pMkXRYVrrcfmKwkd3SQKwIAIDQQTi6g7nSjMvPWtdrmT/O+rqH9XAoPc1yiqgAA6L4IJx3gll+9d8E2d4xL1o//caguczLkAAC0JqTPlFcm9NKnVbWX5FgFH+5XwYf7W9z+2C1DddvVyepFeAEAhLiQPhMOSXRdsnByIY//aace/9POVtskuXvo2TvGKGNgHF8hAQC6rZAOJ98a219//OhQsMtoswrPKd2+tLjN7a8eGKf/e8NgZQyM4+skAECXEdJnrKjw7v0k9eZ9x5Xz4l8C6jMmJVYPTR2isQNj5YwI76TKAABoWUiHkzEpccEuwTpby6s16782BdzvhiHxuuGqBI0c4NagvpcpOjJcDgdfPQEAAhfS4cQZ0b2vnFxKhZ8c7vRfdr52cB99a2x/jU2JU//YaEV08ytfABCqQjqc8D/2Xcu7n32hdz/7okP2lZ4Qo3uuTdWktD5KcvVQGDcYA4A1QjyccEIKVWVVNXrwtW0dtr+oiDDNzhyorKsSNCTJpRhnBIEHANoppMMJ0FFOn2nSf727R//17p5O2f+QxBjdODRB1w+J1xV9eimmB+EHQPdFOAG6gE8qa/RJZY2eW7erw/c9qM9lujVjgCYOulyDE3opxhnBVUUAQdWucLJo0SItXLhQlZWVGjVqlJ577jmNHz++2bb5+fm66667/NY5nU6dOnWqPYcG0ME+/6JOC9eUddj+ekSG6Y5xKZqc3ldXJsQoPsapSG5eBhCAgMPJyy+/rAULFmjJkiWaMGGCnnnmGU2dOlVlZWWKj49vto/L5VJZ2d//48f/lQHd16mGJuVv3Kv8jXsv6XH79IrShNTLNajvZboyIUapfS6Tq0ekLnOGq2dUhKIiwhTm4L8/QFfgMMaYQDpMmDBB48aN069+9StJUlNTk5KTk/Wv//qvevjhh89rn5+fr/nz56u6urrdRXq9Xrndbnk8HrlcrnbvpznbD3ja9MN9ANAVDepzmQYn9FJ8TA8N6nuZ+sVGK65nlC7vFaUYZ4ScEeGKjHAoKjxMYQ6H7ylGQhw6QnvP3wFdOTl9+rS2bNmi3Nxc37qwsDBlZWWpuLjladVra2s1cOBANTU1aezYsfqP//gPDRs2rMX29fX1qq+v9732er2BlBmQEQPcnbZvAAi2z7+o0+df1AW7jG7vW2P7a+Kgy5WeEKOv9bmMJ/YuUkDh5IsvvlBjY6MSEhL81ickJOiTTz5ptk96erpefPFFjRw5Uh6PR7/4xS80adIk7dixQwMGDGi2T15enh5//PFASgMAIGhe/+tBvf7Xg8Euo90W/p+Ruu3q5GCX4dPpd6llZmYqJydHo0eP1uTJk/X666+rb9++Wrp0aYt9cnNz5fF4fMv+/fs7tcY9ed/o1P0DAGCzB1/bpvd3dcwklx0hoHDSp08fhYeHq6qqym99VVWVEhMT27SPyMhIjRkzRrt2tfxIpNPplMvl8ls6k8Ph0N4np3XqMQAAsNn8l0uCXYJPQF/rREVFKSMjQ4WFhZoxY4akszfEFhYWat68eW3aR2Njo7Zv365vfMO+qxVfDSjGGB2tO63blxTznS0AoFuz6RaZgB8lXrBggWbPnq2rr75a48eP1zPPPKO6ujrfXCY5OTnq37+/8vLyJElPPPGEJk6cqLS0NFVXV2vhwoXat2+f7rnnno59J53A4XCoTy+n1v1gSottPqn06uZn3r10RQEA0AnCLXpCK+BwMnPmTB05ckSPPvqoKisrNXr0aL311lu+m2TLy8sVFvb3b4uOHz+uOXPmqLKyUnFxccrIyNDGjRs1dOjQjnsXQTQk0dXqV0Kekw3KfX2bVm+vvIRVAQAQGJseHw94npNg6Mx5TmzgOdGgp9/+9JJPWgUAwDmZgy7X7783sUP3eUnmOUHncPeM1E++OUw/+WbLc78cra3XxLxCNTRanyUBAF1QvMsZ7BJ8CCddxOW9nPrsZy3fROw52aCn13L1BQDQPl36nhPYyR194asvklRXf0b5G/d26A+9AQC6PpvuOSGchJjLnBGae32a5l6fdsG2x+tOa0XJQT3+p52XoDIAQDB16UeJETriLovSXdek6q5rUtvU3hijA8dP6tUtB/T/Cj/r5OoAAB0pjCsn6I4cDoeSe/fUghuv1IIbrwy4vzFG3lNntGZHpR56bVsnVAgAaIlNP1RIOIE1HA6H3NGRuv3qZN3exh+gamoyKjlQrZ+u2qmt5dWdWyAAdGPhnf5re21HOEGXFhbm0NiUOC3//jVt7tPUZFThPaXfbdqnXxft7sTqAKDr4GsdIIjCwhzqHxuth24eooduHtJqW2OMyo+d0E9X7dTbHx++RBUCwKVHOAG6CIfDoYGXX6YXZo+7YNumJqNdR2r1bOFnemNbxSWoDgA6jkXZhHACdJSwMIeuTIjRom+P1aJvX7i9MUaekw0q/PiwHl1ZqrrTjZ1fJAC0gCsnAORwOBTbM0q3ZgzQrRkDAup7qqFRH1d49fKH+1Xw4f5OqhBAKAnnaR0AF6NHZLjGpMRpTEqcnrx1ZJv7GWN0pLZe6z4+rMf/tFMnG7haA+Asiy6cEE6AUOJwOBQf00N3jE/RHeNT2tzPGKNDnlNasfUgP30AdFN8rQOgS3E4zj7h1NafPpDOfvVUVlmjZ97+VO+UHenkCgFcLH74D0C31yMyXKOSY/XSXeMD6uc52aAPPj+qn68p067DtZ1UHYCvYoZYAGiBOzpSNw1L1E3DEgPua4xR/ZkmlR87oeLdR7Wy5KD+yszBQJtYlE0IJwC6D4fDoR6R4boyIUZXJsRo9qSvdch+G5uMak+d0d6jdfroQLXW7qzSu5990SH7BmwRHRke7BJ8CCcAcAHhYQ65e0ZqVM9YjUqOVU7m1zp0/2cam+Q52aDdR+pUVlWjTbuPav2nR1Rbf6ZDjwO0JsKiH9chnABAkEWEh+nyXk5d3sup8am99Z2JAzv1eMYYNTQa1daf0aHqk9p39IR2Vni07YCHK0IhzKJvdQgnABBqHA6HoiIc6h0Rpd6XRWl4f7emjUy6JMduajp7X5DnZIMqPCdVfuyE5r9cImMuyeHRCiZhAwCEpLAwh6KjwhUdFa5Edw+NSYnT9NH9L8mxjTFqbDKqq29U9cnTqvSc0sHqk6r0ntKuw7U6cOyk/rL32CWpxUYWPUlMOAEAhAaHw6GIcIfcPcPk7hmpgZdfdsmO3dhkdKSmXh8dqNYfSw5p0+dHdbTu9CU7flsMTXIFuwQfwgkAAJ0sPMyhRHcPJboTNbUdj8l/1bnH5hsamxQVEabIsDA5HGdD0LETp1V+9IT+sveYVm49pLKqmjbt8+qv9b7oujqKwxj7v+nzer1yu93yeDxyuexJdgAAoGXtPX/b89wQAACACCcAAMAyhBMAAGAVwgkAALAK4QQAAFiFcAIAAKxCOAEAAFYhnAAAAKsQTgAAgFUIJwAAwCqEEwAAYBXCCQAAsArhBAAAWCUi2AW0xbkfTvZ6vUGuBAAAtNW58/a583hbdYlwUlNTI0lKTk4OciUAACBQNTU1crvdbW7vMIHGmSBoamrSoUOHFBMTI4fD0WH79Xq9Sk5O1v79++VyuTpsv90RYxUYxqvtGKu2Y6zajrFqu84cK2OMampq1K9fP4WFtf1Oki5x5SQsLEwDBgzotP27XC4+vG3EWAWG8Wo7xqrtGKu2Y6zarrPGKpArJudwQywAALAK4QQAAFglpMOJ0+nUY489JqfTGexSrMdYBYbxajvGqu0Yq7ZjrNrOxrHqEjfEAgCA0BHSV04AAIB9CCcAAMAqhBMAAGAVwgkAALAK4QQAAFglpMPJokWL9LWvfU09evTQhAkT9Je//CXYJXWon/zkJ3I4HH7LkCFDfNtPnTqluXPn6vLLL1evXr106623qqqqym8f5eXlmjZtmnr27Kn4+Hg9+OCDOnPmjF+boqIijR07Vk6nU2lpacrPzz+vFtvGesOGDbrlllvUr18/ORwOrVixwm+7MUaPPvqokpKSFB0draysLH322Wd+bY4dO6Y777xTLpdLsbGxuvvuu1VbW+vXZtu2bbr22mvVo0cPJScn6+c///l5tbz66qsaMmSIevTooREjRmj16tUB19KZLjRW3/3ud8/7nN18881+bUJlrPLy8jRu3DjFxMQoPj5eM2bMUFlZmV8bm/7u2lJLZ2nLWE2ZMuW8z9a9997r1yYUxmrx4sUaOXKkbwbXzMxMvfnmmwHV1uXGyYSogoICExUVZV588UWzY8cOM2fOHBMbG2uqqqqCXVqHeeyxx8ywYcNMRUWFbzly5Ihv+7333muSk5NNYWGh2bx5s5k4caKZNGmSb/uZM2fM8OHDTVZWltm6datZvXq16dOnj8nNzfW1+fzzz03Pnj3NggULzM6dO81zzz1nwsPDzVtvveVrY+NYr1692vz7v/+7ef31140ks3z5cr/tTz75pHG73WbFihXmo48+Mt/85jdNamqqOXnypK/NzTffbEaNGmU2bdpk3n33XZOWlmZmzZrl2+7xeExCQoK58847TWlpqfn9739voqOjzdKlS31t3n//fRMeHm5+/vOfm507d5of/ehHJjIy0mzfvj2gWjrThcZq9uzZ5uabb/b7nB07dsyvTaiM1dSpU81LL71kSktLTUlJifnGN75hUlJSTG1tra+NTX93F6qlM7VlrCZPnmzmzJnj99nyeDy+7aEyVn/84x/NG2+8YT799FNTVlZmHnnkERMZGWlKS0vbVFtXHKeQDSfjx483c+fO9b1ubGw0/fr1M3l5eUGsqmM99thjZtSoUc1uq66uNpGRkebVV1/1rfv444+NJFNcXGyMOXtSCgsLM5WVlb42ixcvNi6Xy9TX1xtjjHnooYfMsGHD/PY9c+ZMM3XqVN9r28f6qyfcpqYmk5iYaBYuXOhbV11dbZxOp/n9739vjDFm586dRpL58MMPfW3efPNN43A4zMGDB40xxvz61782cXFxvrEyxpgf/vCHJj093ff69ttvN9OmTfOrZ8KECeZf/uVf2lzLpdRSOJk+fXqLfUJ1rIwx5vDhw0aSWb9+va8eW/7u2lLLpfTVsTLmbDi5//77W+wTqmNljDFxcXHmhRde6LafqZD8Wuf06dPasmWLsrKyfOvCwsKUlZWl4uLiIFbW8T777DP169dPgwYN0p133qny8nJJ0pYtW9TQ0OA3BkOGDFFKSopvDIqLizVixAglJCT42kydOlVer1c7duzwtfnyPs61ObePrjjWe/bsUWVlpV/NbrdbEyZM8Bub2NhYXX311b42WVlZCgsL0wcffOBrc9111ykqKsrXZurUqSorK9Px48d9bVobv7bUYoOioiLFx8crPT1d9913n44ePerbFspj5fF4JEm9e/eWZNffXVtquZS+Olbn/O53v1OfPn00fPhw5ebm6sSJE75toThWjY2NKigoUF1dnTIzM7vtZ6pL/CpxR/viiy/U2Njo9y9KkhISEvTJJ58EqaqON2HCBOXn5ys9PV0VFRV6/PHHde2116q0tFSVlZWKiopSbGysX5+EhARVVlZKkiorK5sdo3PbWmvj9Xp18uRJHT9+vMuN9bn31lzNX37f8fHxftsjIiLUu3dvvzapqann7ePctri4uBbH78v7uFAtwXbzzTfrW9/6llJTU7V792498sgjys7OVnFxscLDw0N2rJqamjR//nxdc801Gj58uK9GW/7u2lLLpdLcWEnSt7/9bQ0cOFD9+vXTtm3b9MMf/lBlZWV6/fXXJYXWWG3fvl2ZmZk6deqUevXqpeXLl2vo0KEqKSnplp+pkAwnoSI7O9v3zyNHjtSECRM0cOBAvfLKK4qOjg5iZehO7rjjDt8/jxgxQiNHjtQVV1yhoqIi3XDDDUGsLLjmzp2r0tJSvffee8EuxXotjdX3vvc93z+PGDFCSUlJuuGGG7R7925dccUVl7rMoEpPT1dJSYk8Ho9ee+01zZ49W+vXrw92WZ0mJL/W6dOnj8LDw8+7g7iqqkqJiYlBqqrzxcbG6sorr9SuXbuUmJio06dPq7q62q/Nl8cgMTGx2TE6t621Ni6XS9HR0V1yrM/V1VrNiYmJOnz4sN/2M2fO6NixYx0yfl/efqFabDNo0CD16dNHu3btkhSaYzVv3jytWrVK77zzjgYMGOBbb9PfXVtquRRaGqvmTJgwQZL8PluhMlZRUVFKS0tTRkaG8vLyNGrUKD377LPd9jMVkuEkKipKGRkZKiws9K1rampSYWGhMjMzg1hZ56qtrdXu3buVlJSkjIwMRUZG+o1BWVmZysvLfWOQmZmp7du3+51Y1q5dK5fLpaFDh/rafHkf59qc20dXHOvU1FQlJib61ez1evXBBx/4jU11dbW2bNnia7Nu3To1NTX5/gOamZmpDRs2qKGhwddm7dq1Sk9PV1xcnK9Na+PXllpsc+DAAR09elRJSUmSQmusjDGaN2+eli9frnXr1p33VZVNf3dtqaUzXWismlNSUiJJfp+tUBir5jQ1Nam+vr77fqYCun22GykoKDBOp9Pk5+ebnTt3mu9973smNjbW727mru6BBx4wRUVFZs+ePeb99983WVlZpk+fPubw4cPGmLOPfKWkpJh169aZzZs3m8zMTJOZmenrf+7xs5tuusmUlJSYt956y/Tt27fZx88efPBB8/HHH5tFixY1+/iZbWNdU1Njtm7darZu3WokmV/+8pdm69atZt++fcaYs4+kxsbGmpUrV5pt27aZ6dOnN/so8ZgxY8wHH3xg3nvvPTN48GC/x2Orq6tNQkKC+c53vmNKS0tNQUGB6dmz53mPx0ZERJhf/OIX5uOPPzaPPfZYs4/HXqiWztTaWNXU1Jgf/OAHpri42OzZs8e8/fbbZuzYsWbw4MHm1KlTITdW9913n3G73aaoqMjv8dcTJ0742tj0d3ehWjrThcZq165d5oknnjCbN282e/bsMStXrjSDBg0y1113nW8foTJWDz/8sFm/fr3Zs2eP2bZtm3n44YeNw+Ewf/7zn9tUW1ccp5ANJ8YY89xzz5mUlBQTFRVlxo8fbzZt2hTskjrUzJkzTVJSkomKijL9+/c3M2fONLt27fJtP3nypPn+979v4uLiTM+ePc0//dM/mYqKCr997N2712RnZ5vo6GjTp08f88ADD5iGhga/Nu+8844ZPXq0iYqKMoMGDTIvvfTSebXYNtbvvPOOkXTeMnv2bGPM2cdSf/zjH5uEhATjdDrNDTfcYMrKyvz2cfToUTNr1izTq1cv43K5zF133WVqamr82nz00Ufm61//unE6naZ///7mySefPK+WV155xVx55ZUmKirKDBs2zLzxxht+29tSS2dqbaxOnDhhbrrpJtO3b18TGRlpBg4caObMmXNe8AyVsWpunCT5/U3Y9HfXllo6y4XGqry83Fx33XWmd+/exul0mrS0NPPggw/6zXNiTGiM1T//8z+bgQMHmqioKNO3b19zww03+IJJW2vrauPkMMaYwK61AAAAdJ6QvOcEAADYi3ACAACsQjgBAABWIZwAAACrEE4AAIBVCCcAAMAqhBMAAGAVwgkAALAK4QQAAFiFcAIAAKxCOAEAAFb5/3QVP8KUa1XQAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([a for a in range(len(cost))],cost)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a4cbfa-fb8c-42b3-a80b-9a4273be36fb",
   "metadata": {},
   "source": [
    "### d) increase learning rate to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0a015645-4b74-460a-8f64-5867909bfbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "network2d = NeuralNetwork(input_dim,\n",
    "                        hidden_dim,\n",
    "                        output_dim,\n",
    "                        num_of_hidden_layers,\n",
    "                        activation,\n",
    "                        activation_output,\n",
    "                        initialization,\n",
    "                        output_initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "774bf4d3-4114-404d-98a2-5a40129ce095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Accuracy: 0.6341463414634146 Loss: 0.6987044129911617\n",
      "0. Accuracy: 0.6097560975609756 Loss: 0.7680438332644374\n",
      "0. Accuracy: 0.2926829268292683 Loss: 1.2161717346284378\n",
      "0. Accuracy: 0.6829268292682927 Loss: 1.1662571364668322\n",
      "0. Accuracy: 0.6829268292682927 Loss: 0.6761970053814754\n",
      "0. Accuracy: 0.4634146341463415 Loss: 0.8459934309175717\n",
      "500. Accuracy: 0.7804878048780488 Loss: 0.4606543025855208\n",
      "500. Accuracy: 0.7317073170731707 Loss: 0.5969606519160693\n",
      "500. Accuracy: 0.8292682926829268 Loss: 0.4592304106757282\n",
      "500. Accuracy: 0.7317073170731707 Loss: 0.517217318510966\n",
      "500. Accuracy: 0.6829268292682927 Loss: 0.5885382707576904\n",
      "500. Accuracy: 0.7073170731707317 Loss: 0.5728488308904568\n",
      "1000. Accuracy: 0.7804878048780488 Loss: 0.43581125606961646\n",
      "1000. Accuracy: 0.7560975609756098 Loss: 0.5744240262885517\n",
      "1000. Accuracy: 0.8780487804878049 Loss: 0.4468191634681277\n",
      "1000. Accuracy: 0.7560975609756098 Loss: 0.4931111450742857\n",
      "1000. Accuracy: 0.6829268292682927 Loss: 0.5707247979781346\n",
      "1000. Accuracy: 0.7317073170731707 Loss: 0.5409145153434677\n",
      "1500. Accuracy: 0.8536585365853658 Loss: 0.40600646971343096\n",
      "1500. Accuracy: 0.7560975609756098 Loss: 0.5504873652996025\n",
      "1500. Accuracy: 0.8780487804878049 Loss: 0.43992117553699767\n",
      "1500. Accuracy: 0.7560975609756098 Loss: 0.47260795712321063\n",
      "1500. Accuracy: 0.7073170731707317 Loss: 0.5558153027590572\n",
      "1500. Accuracy: 0.7317073170731707 Loss: 0.5237419682528036\n",
      "2000. Accuracy: 0.8536585365853658 Loss: 0.38907368436163237\n",
      "2000. Accuracy: 0.7560975609756098 Loss: 0.533332401857836\n",
      "2000. Accuracy: 0.8536585365853658 Loss: 0.42217314638100695\n",
      "2000. Accuracy: 0.7560975609756098 Loss: 0.4546105306845599\n",
      "2000. Accuracy: 0.7317073170731707 Loss: 0.5406629127539709\n",
      "2000. Accuracy: 0.7560975609756098 Loss: 0.5021270581391105\n",
      "2500. Accuracy: 0.8536585365853658 Loss: 0.3670974885922314\n",
      "2500. Accuracy: 0.7073170731707317 Loss: 0.5196488085214934\n",
      "2500. Accuracy: 0.8536585365853658 Loss: 0.41352220689826624\n",
      "2500. Accuracy: 0.7560975609756098 Loss: 0.4472225354662054\n",
      "2500. Accuracy: 0.7560975609756098 Loss: 0.5257020418864534\n",
      "2500. Accuracy: 0.8292682926829268 Loss: 0.4848534856914875\n",
      "3000. Accuracy: 0.8536585365853658 Loss: 0.3442306032227615\n",
      "3000. Accuracy: 0.7317073170731707 Loss: 0.5081919858043384\n",
      "3000. Accuracy: 0.8536585365853658 Loss: 0.39981211423025365\n",
      "3000. Accuracy: 0.7560975609756098 Loss: 0.452288642268989\n",
      "3000. Accuracy: 0.7560975609756098 Loss: 0.5104347562597092\n",
      "3000. Accuracy: 0.8292682926829268 Loss: 0.47330401470657146\n",
      "3500. Accuracy: 0.8780487804878049 Loss: 0.3304254798739861\n",
      "3500. Accuracy: 0.7317073170731707 Loss: 0.5038105618386803\n",
      "3500. Accuracy: 0.8292682926829268 Loss: 0.4053538579532139\n",
      "3500. Accuracy: 0.7560975609756098 Loss: 0.45200809392607666\n",
      "3500. Accuracy: 0.7560975609756098 Loss: 0.5009477000627687\n",
      "3500. Accuracy: 0.8292682926829268 Loss: 0.45325021089872064\n",
      "4000. Accuracy: 0.9024390243902439 Loss: 0.31622809185806006\n",
      "4000. Accuracy: 0.7560975609756098 Loss: 0.49723110186875263\n",
      "4000. Accuracy: 0.8536585365853658 Loss: 0.3886437982433055\n",
      "4000. Accuracy: 0.7560975609756098 Loss: 0.4461785710768928\n",
      "4000. Accuracy: 0.7560975609756098 Loss: 0.4893986376441629\n",
      "4000. Accuracy: 0.8292682926829268 Loss: 0.4474531512774713\n",
      "4500. Accuracy: 0.8780487804878049 Loss: 0.33474484318768594\n",
      "4500. Accuracy: 0.7317073170731707 Loss: 0.49673711801063225\n",
      "4500. Accuracy: 0.8780487804878049 Loss: 0.36392248415782674\n",
      "4500. Accuracy: 0.7560975609756098 Loss: 0.4276779889509266\n",
      "4500. Accuracy: 0.7804878048780488 Loss: 0.47360637079172696\n",
      "4500. Accuracy: 0.8536585365853658 Loss: 0.4578797075151645\n",
      "5000. Accuracy: 0.8292682926829268 Loss: 0.3501784458287128\n",
      "5000. Accuracy: 0.7560975609756098 Loss: 0.47250168911306106\n",
      "5000. Accuracy: 0.8780487804878049 Loss: 0.3570867690612451\n",
      "5000. Accuracy: 0.7560975609756098 Loss: 0.4141265623999145\n",
      "5000. Accuracy: 0.8048780487804879 Loss: 0.46659768817242747\n",
      "5000. Accuracy: 0.8048780487804879 Loss: 0.4770101604500061\n",
      "5500. Accuracy: 0.8780487804878049 Loss: 0.3135794002342507\n",
      "5500. Accuracy: 0.7317073170731707 Loss: 0.4811235295842918\n",
      "5500. Accuracy: 0.9024390243902439 Loss: 0.3582156352355103\n",
      "5500. Accuracy: 0.7560975609756098 Loss: 0.4162906274316486\n",
      "5500. Accuracy: 0.8048780487804879 Loss: 0.46046924491655744\n",
      "5500. Accuracy: 0.8292682926829268 Loss: 0.4628388274423773\n",
      "6000. Accuracy: 0.7804878048780488 Loss: 0.378545498266915\n",
      "6000. Accuracy: 0.7317073170731707 Loss: 0.5149633823280334\n",
      "6000. Accuracy: 0.926829268292683 Loss: 0.26208419195448074\n",
      "6000. Accuracy: 0.7560975609756098 Loss: 0.3861576567657661\n",
      "6000. Accuracy: 0.8048780487804879 Loss: 0.4529818638022814\n",
      "6000. Accuracy: 0.7804878048780488 Loss: 0.454898807957369\n",
      "6500. Accuracy: 0.9024390243902439 Loss: 0.30644814237506535\n",
      "6500. Accuracy: 0.7560975609756098 Loss: 0.4628148312439779\n",
      "6500. Accuracy: 0.8780487804878049 Loss: 0.3481625419378597\n",
      "6500. Accuracy: 0.7560975609756098 Loss: 0.42249795607625895\n",
      "6500. Accuracy: 0.8292682926829268 Loss: 0.45129479425451285\n",
      "6500. Accuracy: 0.8292682926829268 Loss: 0.4319412361613495\n",
      "7000. Accuracy: 0.926829268292683 Loss: 0.28833372758139997\n",
      "7000. Accuracy: 0.7560975609756098 Loss: 0.48438675790628904\n",
      "7000. Accuracy: 0.8536585365853658 Loss: 0.39082955067865327\n",
      "7000. Accuracy: 0.7560975609756098 Loss: 0.4152216513328927\n",
      "7000. Accuracy: 0.7804878048780488 Loss: 0.476663934553982\n",
      "7000. Accuracy: 0.8292682926829268 Loss: 0.44477644095585406\n",
      "7500. Accuracy: 0.926829268292683 Loss: 0.2830863543882029\n",
      "7500. Accuracy: 0.7560975609756098 Loss: 0.4781278731886611\n",
      "7500. Accuracy: 0.8536585365853658 Loss: 0.37270149375991457\n",
      "7500. Accuracy: 0.7560975609756098 Loss: 0.40619342946621945\n",
      "7500. Accuracy: 0.8048780487804879 Loss: 0.4545226957509526\n",
      "7500. Accuracy: 0.8292682926829268 Loss: 0.4310601896884301\n",
      "8000. Accuracy: 0.926829268292683 Loss: 0.26697177467169114\n",
      "8000. Accuracy: 0.7560975609756098 Loss: 0.4877199609663843\n",
      "8000. Accuracy: 0.8292682926829268 Loss: 0.4027561708155396\n",
      "8000. Accuracy: 0.7560975609756098 Loss: 0.40590127866072834\n",
      "8000. Accuracy: 0.8292682926829268 Loss: 0.44245046793083476\n",
      "8000. Accuracy: 0.8536585365853658 Loss: 0.4040331562338876\n",
      "8500. Accuracy: 0.8780487804878049 Loss: 0.2693235631298815\n",
      "8500. Accuracy: 0.7804878048780488 Loss: 0.4418913915250843\n",
      "8500. Accuracy: 0.926829268292683 Loss: 0.28655526783944824\n",
      "8500. Accuracy: 0.7560975609756098 Loss: 0.337620450213062\n",
      "8500. Accuracy: 0.8292682926829268 Loss: 0.4279548642724068\n",
      "8500. Accuracy: 0.8536585365853658 Loss: 0.40186946151064273\n",
      "9000. Accuracy: 0.8780487804878049 Loss: 0.2584859479365071\n",
      "9000. Accuracy: 0.8292682926829268 Loss: 0.42323213496094336\n",
      "9000. Accuracy: 0.926829268292683 Loss: 0.2894194678845948\n",
      "9000. Accuracy: 0.7560975609756098 Loss: 0.3239942041493553\n",
      "9000. Accuracy: 0.8292682926829268 Loss: 0.42295653868056127\n",
      "9000. Accuracy: 0.8292682926829268 Loss: 0.4038502770429879\n",
      "9500. Accuracy: 0.9024390243902439 Loss: 0.25644124620743297\n",
      "9500. Accuracy: 0.8048780487804879 Loss: 0.42432008004495975\n",
      "9500. Accuracy: 0.8536585365853658 Loss: 0.33486268147378706\n",
      "9500. Accuracy: 0.7560975609756098 Loss: 0.3346481005471879\n",
      "9500. Accuracy: 0.8536585365853658 Loss: 0.4012747422695014\n",
      "9500. Accuracy: 0.8536585365853658 Loss: 0.4057860095312742\n",
      "10000. Accuracy: 0.9024390243902439 Loss: 0.25408473499743267\n",
      "10000. Accuracy: 0.8048780487804879 Loss: 0.4232794160514388\n",
      "10000. Accuracy: 0.8780487804878049 Loss: 0.3270311567342362\n",
      "10000. Accuracy: 0.8048780487804879 Loss: 0.3209317435189762\n",
      "10000. Accuracy: 0.8536585365853658 Loss: 0.3922911449342579\n",
      "10000. Accuracy: 0.7804878048780488 Loss: 0.3950747602021812\n",
      "10500. Accuracy: 0.9024390243902439 Loss: 0.2456860376053004\n",
      "10500. Accuracy: 0.8048780487804879 Loss: 0.419020273822183\n",
      "10500. Accuracy: 0.8536585365853658 Loss: 0.311847232589436\n",
      "10500. Accuracy: 0.8048780487804879 Loss: 0.3204034457615839\n",
      "10500. Accuracy: 0.8536585365853658 Loss: 0.3926443082036791\n",
      "10500. Accuracy: 0.8292682926829268 Loss: 0.3936545448110164\n",
      "11000. Accuracy: 0.9512195121951219 Loss: 0.23394447546666663\n",
      "11000. Accuracy: 0.8048780487804879 Loss: 0.440891994518978\n",
      "11000. Accuracy: 0.8048780487804879 Loss: 0.37119585734175814\n",
      "11000. Accuracy: 0.7804878048780488 Loss: 0.33008752052646867\n",
      "11000. Accuracy: 0.8048780487804879 Loss: 0.3996806303252691\n",
      "11000. Accuracy: 0.8292682926829268 Loss: 0.3953755392130698\n",
      "11500. Accuracy: 0.9024390243902439 Loss: 0.22842084701178306\n",
      "11500. Accuracy: 0.8048780487804879 Loss: 0.4048798658610086\n",
      "11500. Accuracy: 0.8536585365853658 Loss: 0.32282145449701016\n",
      "11500. Accuracy: 0.7804878048780488 Loss: 0.32237553002545216\n",
      "11500. Accuracy: 0.7804878048780488 Loss: 0.4002114094680407\n",
      "11500. Accuracy: 0.8536585365853658 Loss: 0.40574661189216055\n",
      "12000. Accuracy: 0.8780487804878049 Loss: 0.2423320552846615\n",
      "12000. Accuracy: 0.8048780487804879 Loss: 0.41963911448064933\n",
      "12000. Accuracy: 0.8536585365853658 Loss: 0.3350555510443113\n",
      "12000. Accuracy: 0.7804878048780488 Loss: 0.3223899126315745\n",
      "12000. Accuracy: 0.8292682926829268 Loss: 0.38324301665812593\n",
      "12000. Accuracy: 0.8536585365853658 Loss: 0.39133357961854043\n",
      "12500. Accuracy: 0.8292682926829268 Loss: 0.3480477801123061\n",
      "12500. Accuracy: 0.8292682926829268 Loss: 0.38231168717143915\n",
      "12500. Accuracy: 0.975609756097561 Loss: 0.15106148880328957\n",
      "12500. Accuracy: 0.8780487804878049 Loss: 0.25726543050649064\n",
      "12500. Accuracy: 0.8292682926829268 Loss: 0.38467641646779904\n",
      "12500. Accuracy: 0.7804878048780488 Loss: 0.4466780912593179\n",
      "13000. Accuracy: 0.9024390243902439 Loss: 0.2654864652707669\n",
      "13000. Accuracy: 0.7317073170731707 Loss: 0.5594601625944943\n",
      "13000. Accuracy: 0.7317073170731707 Loss: 0.539360692550986\n",
      "13000. Accuracy: 0.7560975609756098 Loss: 0.4832861200901365\n",
      "13000. Accuracy: 0.7560975609756098 Loss: 0.4056643825963863\n",
      "13000. Accuracy: 0.8048780487804879 Loss: 0.4229059299182037\n",
      "13500. Accuracy: 0.8292682926829268 Loss: 0.2783255965081588\n",
      "13500. Accuracy: 0.7317073170731707 Loss: 0.5857346905066552\n",
      "13500. Accuracy: 0.7317073170731707 Loss: 0.5533897687919439\n",
      "13500. Accuracy: 0.7560975609756098 Loss: 0.47137404113551057\n",
      "13500. Accuracy: 0.7804878048780488 Loss: 0.40336379026752683\n",
      "13500. Accuracy: 0.7804878048780488 Loss: 0.4322348146810861\n",
      "14000. Accuracy: 0.8536585365853658 Loss: 0.2666940292765146\n",
      "14000. Accuracy: 0.7560975609756098 Loss: 0.5454137088861967\n",
      "14000. Accuracy: 0.7560975609756098 Loss: 0.48476096508166233\n",
      "14000. Accuracy: 0.7804878048780488 Loss: 0.3911828999909806\n",
      "14000. Accuracy: 0.8048780487804879 Loss: 0.3830322805146739\n",
      "14000. Accuracy: 0.7804878048780488 Loss: 0.41465830297595857\n",
      "14500. Accuracy: 0.8780487804878049 Loss: 0.25347331633369685\n",
      "14500. Accuracy: 0.7804878048780488 Loss: 0.5053562572492316\n",
      "14500. Accuracy: 0.7804878048780488 Loss: 0.4742952326552681\n",
      "14500. Accuracy: 0.7560975609756098 Loss: 0.3862151733134108\n",
      "14500. Accuracy: 0.8292682926829268 Loss: 0.386895717881924\n",
      "14500. Accuracy: 0.8292682926829268 Loss: 0.43973626999521326\n",
      "15000. Accuracy: 0.8536585365853658 Loss: 0.28756856105028566\n",
      "15000. Accuracy: 0.7560975609756098 Loss: 0.607998360017059\n",
      "15000. Accuracy: 0.7317073170731707 Loss: 0.5903750767157299\n",
      "15000. Accuracy: 0.7560975609756098 Loss: 0.4494146125413324\n",
      "15000. Accuracy: 0.8048780487804879 Loss: 0.401980146315223\n",
      "15000. Accuracy: 0.8048780487804879 Loss: 0.45457190979527495\n",
      "15500. Accuracy: 0.9024390243902439 Loss: 0.2770023912373732\n",
      "15500. Accuracy: 0.7317073170731707 Loss: 0.5854212109720187\n",
      "15500. Accuracy: 0.7317073170731707 Loss: 0.55727858915257\n",
      "15500. Accuracy: 0.7804878048780488 Loss: 0.403340103761557\n",
      "15500. Accuracy: 0.8048780487804879 Loss: 0.4233076087665481\n",
      "15500. Accuracy: 0.8292682926829268 Loss: 0.38310903785832245\n",
      "16000. Accuracy: 0.7804878048780488 Loss: 0.43824233469541923\n",
      "16000. Accuracy: 0.8536585365853658 Loss: 0.43982820394321925\n",
      "16000. Accuracy: 0.9024390243902439 Loss: 0.1884295868823929\n",
      "16000. Accuracy: 0.9024390243902439 Loss: 0.2584416462884154\n",
      "16000. Accuracy: 0.8292682926829268 Loss: 0.39053407167101456\n",
      "16000. Accuracy: 0.7560975609756098 Loss: 0.4940481289814624\n",
      "16500. Accuracy: 0.7560975609756098 Loss: 0.4717638999762366\n",
      "16500. Accuracy: 0.8292682926829268 Loss: 0.41472985621416986\n",
      "16500. Accuracy: 0.9024390243902439 Loss: 0.1849126146659072\n",
      "16500. Accuracy: 0.9024390243902439 Loss: 0.2559682247983509\n",
      "16500. Accuracy: 0.8536585365853658 Loss: 0.38157114857452107\n",
      "16500. Accuracy: 0.7317073170731707 Loss: 0.48752891132836323\n",
      "17000. Accuracy: 0.9024390243902439 Loss: 0.24886767776987764\n",
      "17000. Accuracy: 0.7560975609756098 Loss: 0.49530393935915834\n",
      "17000. Accuracy: 0.7804878048780488 Loss: 0.456377878631178\n",
      "17000. Accuracy: 0.7804878048780488 Loss: 0.3926061918162555\n",
      "17000. Accuracy: 0.7804878048780488 Loss: 0.40849659291044355\n",
      "17000. Accuracy: 0.8292682926829268 Loss: 0.37028338295568675\n",
      "17500. Accuracy: 0.8780487804878049 Loss: 0.2673284510755874\n",
      "17500. Accuracy: 0.7560975609756098 Loss: 0.5544559308270463\n",
      "17500. Accuracy: 0.7560975609756098 Loss: 0.5203928179571509\n",
      "17500. Accuracy: 0.7804878048780488 Loss: 0.4526340431073991\n",
      "17500. Accuracy: 0.7804878048780488 Loss: 0.4303988611922313\n",
      "17500. Accuracy: 0.8292682926829268 Loss: 0.3745654044652309\n",
      "18000. Accuracy: 0.926829268292683 Loss: 0.2688192199061288\n",
      "18000. Accuracy: 0.7560975609756098 Loss: 0.5585668117486519\n",
      "18000. Accuracy: 0.6585365853658537 Loss: 0.5743957124087263\n",
      "18000. Accuracy: 0.7560975609756098 Loss: 0.544231592454432\n",
      "18000. Accuracy: 0.7560975609756098 Loss: 0.480199387675287\n",
      "18000. Accuracy: 0.8536585365853658 Loss: 0.33157522922953875\n",
      "18500. Accuracy: 0.926829268292683 Loss: 0.2458585010460796\n",
      "18500. Accuracy: 0.7560975609756098 Loss: 0.46545146510346874\n",
      "18500. Accuracy: 0.7804878048780488 Loss: 0.49127438615555585\n",
      "18500. Accuracy: 0.7560975609756098 Loss: 0.49641667473932294\n",
      "18500. Accuracy: 0.8048780487804879 Loss: 0.4154179475720702\n",
      "18500. Accuracy: 0.8780487804878049 Loss: 0.3072352064814706\n",
      "19000. Accuracy: 0.8536585365853658 Loss: 0.3262296783661697\n",
      "19000. Accuracy: 0.7317073170731707 Loss: 0.5508334543187968\n",
      "19000. Accuracy: 0.7560975609756098 Loss: 0.46530246572110506\n",
      "19000. Accuracy: 0.7560975609756098 Loss: 0.43296032077363605\n",
      "19000. Accuracy: 0.8536585365853658 Loss: 0.4051385482957659\n",
      "19000. Accuracy: 0.8536585365853658 Loss: 0.31731880797452\n",
      "19500. Accuracy: 0.9024390243902439 Loss: 0.2791030903166245\n",
      "19500. Accuracy: 0.7560975609756098 Loss: 0.4464676138287902\n",
      "19500. Accuracy: 0.8536585365853658 Loss: 0.38325086170142314\n",
      "19500. Accuracy: 0.7560975609756098 Loss: 0.38793907762731467\n",
      "19500. Accuracy: 0.8292682926829268 Loss: 0.37607819068870274\n",
      "19500. Accuracy: 0.8536585365853658 Loss: 0.30347348425855863\n",
      "20000. Accuracy: 0.7073170731707317 Loss: 0.6092927518210313\n",
      "20000. Accuracy: 0.6585365853658537 Loss: 0.8190878964025989\n",
      "20000. Accuracy: 0.5853658536585366 Loss: 0.5923832765088403\n",
      "20000. Accuracy: 0.7317073170731707 Loss: 0.6582681940335\n",
      "20000. Accuracy: 0.7804878048780488 Loss: 0.44311320076992833\n",
      "20000. Accuracy: 0.7317073170731707 Loss: 0.4339824097187853\n",
      "20500. Accuracy: 0.9024390243902439 Loss: 0.2658200218312719\n",
      "20500. Accuracy: 0.7560975609756098 Loss: 0.4014576577225141\n",
      "20500. Accuracy: 0.8292682926829268 Loss: 0.3837945198580272\n",
      "20500. Accuracy: 0.7560975609756098 Loss: 0.42394102167333025\n",
      "20500. Accuracy: 0.8292682926829268 Loss: 0.37694654802261085\n",
      "20500. Accuracy: 0.8780487804878049 Loss: 0.320717579641701\n",
      "21000. Accuracy: 0.8292682926829268 Loss: 0.3023054135285617\n",
      "21000. Accuracy: 0.7560975609756098 Loss: 0.4655891357602954\n",
      "21000. Accuracy: 0.8048780487804879 Loss: 0.407296357641767\n",
      "21000. Accuracy: 0.7560975609756098 Loss: 0.4415754725821759\n",
      "21000. Accuracy: 0.8048780487804879 Loss: 0.3943722518592352\n",
      "21000. Accuracy: 0.8292682926829268 Loss: 0.3844065392315442\n",
      "21500. Accuracy: 0.7804878048780488 Loss: 0.6926177786660528\n",
      "21500. Accuracy: 0.8780487804878049 Loss: 0.37584401909410325\n",
      "21500. Accuracy: 0.9024390243902439 Loss: 0.19013657560592853\n",
      "21500. Accuracy: 0.8780487804878049 Loss: 0.2825539317537656\n",
      "21500. Accuracy: 0.7317073170731707 Loss: 0.4193532931572724\n",
      "21500. Accuracy: 0.7073170731707317 Loss: 0.7278643313339044\n",
      "22000. Accuracy: 0.8048780487804879 Loss: 0.5016695026627993\n",
      "22000. Accuracy: 0.8780487804878049 Loss: 0.36806060558876913\n",
      "22000. Accuracy: 0.9024390243902439 Loss: 0.19707668379245075\n",
      "22000. Accuracy: 0.8780487804878049 Loss: 0.25635934756428386\n",
      "22000. Accuracy: 0.8292682926829268 Loss: 0.35401122786901507\n",
      "22000. Accuracy: 0.7560975609756098 Loss: 0.4963883358053744\n",
      "22500. Accuracy: 0.8048780487804879 Loss: 0.4716982434755963\n",
      "22500. Accuracy: 0.8780487804878049 Loss: 0.3310748658015745\n",
      "22500. Accuracy: 0.926829268292683 Loss: 0.15253479014110813\n",
      "22500. Accuracy: 0.8780487804878049 Loss: 0.2643082258216627\n",
      "22500. Accuracy: 0.8048780487804879 Loss: 0.3557761992154513\n",
      "22500. Accuracy: 0.8292682926829268 Loss: 0.4776630635008543\n",
      "23000. Accuracy: 0.8292682926829268 Loss: 0.47258909765059354\n",
      "23000. Accuracy: 0.8780487804878049 Loss: 0.29672223124447206\n",
      "23000. Accuracy: 0.926829268292683 Loss: 0.1568299430129934\n",
      "23000. Accuracy: 0.8780487804878049 Loss: 0.2557974958025164\n",
      "23000. Accuracy: 0.8292682926829268 Loss: 0.34314671829546517\n",
      "23000. Accuracy: 0.8536585365853658 Loss: 0.41203008419226006\n",
      "23500. Accuracy: 0.8292682926829268 Loss: 0.4465068526763787\n",
      "23500. Accuracy: 0.8780487804878049 Loss: 0.3173672156298829\n",
      "23500. Accuracy: 0.926829268292683 Loss: 0.16352635944163085\n",
      "23500. Accuracy: 0.9024390243902439 Loss: 0.2484945282097092\n",
      "23500. Accuracy: 0.8048780487804879 Loss: 0.34019470523503764\n",
      "23500. Accuracy: 0.8292682926829268 Loss: 0.42227017305664866\n",
      "24000. Accuracy: 0.8292682926829268 Loss: 0.4004692946990101\n",
      "24000. Accuracy: 0.8780487804878049 Loss: 0.2967627398268451\n",
      "24000. Accuracy: 0.9024390243902439 Loss: 0.17195275359310178\n",
      "24000. Accuracy: 0.8780487804878049 Loss: 0.25848674211265266\n",
      "24000. Accuracy: 0.7804878048780488 Loss: 0.3767202493468559\n",
      "24000. Accuracy: 0.6829268292682927 Loss: 0.579880866139598\n",
      "24500. Accuracy: 0.9024390243902439 Loss: 0.25618620184390833\n",
      "24500. Accuracy: 0.8780487804878049 Loss: 0.29803958615836423\n",
      "24500. Accuracy: 0.9512195121951219 Loss: 0.2128114731945095\n",
      "24500. Accuracy: 0.8536585365853658 Loss: 0.27284185975483266\n",
      "24500. Accuracy: 0.8536585365853658 Loss: 0.3319491853022798\n",
      "24500. Accuracy: 0.8780487804878049 Loss: 0.2898376342893313\n",
      "25000. Accuracy: 0.8292682926829268 Loss: 0.4241961238803209\n",
      "25000. Accuracy: 0.9024390243902439 Loss: 0.2971179318011046\n",
      "25000. Accuracy: 0.9024390243902439 Loss: 0.16248745533184228\n",
      "25000. Accuracy: 0.8780487804878049 Loss: 0.2548764660431941\n",
      "25000. Accuracy: 0.7804878048780488 Loss: 0.3577706245064802\n",
      "25000. Accuracy: 0.8292682926829268 Loss: 0.4172905734611398\n",
      "25500. Accuracy: 0.7560975609756098 Loss: 0.6361354771049555\n",
      "25500. Accuracy: 0.8536585365853658 Loss: 0.43235031046014893\n",
      "25500. Accuracy: 0.8536585365853658 Loss: 0.2303926326091459\n",
      "25500. Accuracy: 0.8536585365853658 Loss: 0.28890773303455564\n",
      "25500. Accuracy: 0.7804878048780488 Loss: 0.38513254206753883\n",
      "25500. Accuracy: 0.7804878048780488 Loss: 0.4643599396957655\n",
      "26000. Accuracy: 0.8780487804878049 Loss: 0.30963698853882665\n",
      "26000. Accuracy: 0.8780487804878049 Loss: 0.26940711303361387\n",
      "26000. Accuracy: 0.975609756097561 Loss: 0.15441530875356121\n",
      "26000. Accuracy: 0.8780487804878049 Loss: 0.24723062041991484\n",
      "26000. Accuracy: 0.8536585365853658 Loss: 0.33989137936958846\n",
      "26000. Accuracy: 0.8536585365853658 Loss: 0.30134063769435515\n",
      "26500. Accuracy: 0.8536585365853658 Loss: 0.26432938874630696\n",
      "26500. Accuracy: 0.8048780487804879 Loss: 0.3780334633512519\n",
      "26500. Accuracy: 0.8536585365853658 Loss: 0.33609294740774454\n",
      "26500. Accuracy: 0.7804878048780488 Loss: 0.3800437962753239\n",
      "26500. Accuracy: 0.8048780487804879 Loss: 0.39335223938940533\n",
      "26500. Accuracy: 0.8536585365853658 Loss: 0.31184472264089075\n",
      "27000. Accuracy: 0.8536585365853658 Loss: 0.2638547666100138\n",
      "27000. Accuracy: 0.8048780487804879 Loss: 0.33834804170622607\n",
      "27000. Accuracy: 0.8780487804878049 Loss: 0.30624832617453973\n",
      "27000. Accuracy: 0.8048780487804879 Loss: 0.3408394133129076\n",
      "27000. Accuracy: 0.7804878048780488 Loss: 0.3730934594431315\n",
      "27000. Accuracy: 0.9024390243902439 Loss: 0.28642819274428377\n",
      "27500. Accuracy: 0.8536585365853658 Loss: 0.3769815562361035\n",
      "27500. Accuracy: 0.8780487804878049 Loss: 0.3118459127329209\n",
      "27500. Accuracy: 0.9024390243902439 Loss: 0.17855537087024784\n",
      "27500. Accuracy: 0.8780487804878049 Loss: 0.26490138298508453\n",
      "27500. Accuracy: 0.8048780487804879 Loss: 0.35762863924220323\n",
      "27500. Accuracy: 0.8292682926829268 Loss: 0.3878015826996296\n",
      "28000. Accuracy: 0.8292682926829268 Loss: 0.42424364915151896\n",
      "28000. Accuracy: 0.8780487804878049 Loss: 0.3356557327705337\n",
      "28000. Accuracy: 0.9024390243902439 Loss: 0.17951737005346713\n",
      "28000. Accuracy: 0.8780487804878049 Loss: 0.26946470700556957\n",
      "28000. Accuracy: 0.8048780487804879 Loss: 0.3559381350291836\n",
      "28000. Accuracy: 0.8536585365853658 Loss: 0.36497185096800877\n",
      "28500. Accuracy: 0.6829268292682927 Loss: 0.48958469649886605\n",
      "28500. Accuracy: 0.7073170731707317 Loss: 0.8269957290394218\n",
      "28500. Accuracy: 0.5365853658536586 Loss: 0.7135777732258569\n",
      "28500. Accuracy: 0.7073170731707317 Loss: 0.7903419923350337\n",
      "28500. Accuracy: 0.7560975609756098 Loss: 0.6474315585660696\n",
      "28500. Accuracy: 0.7317073170731707 Loss: 0.550919717092725\n",
      "29000. Accuracy: 0.8780487804878049 Loss: 0.35463466172350394\n",
      "29000. Accuracy: 0.9024390243902439 Loss: 0.2882853753102872\n",
      "29000. Accuracy: 0.975609756097561 Loss: 0.15287577522971077\n",
      "29000. Accuracy: 0.8780487804878049 Loss: 0.24790583445516307\n",
      "29000. Accuracy: 0.8048780487804879 Loss: 0.36018966976347294\n",
      "29000. Accuracy: 0.8292682926829268 Loss: 0.39168140824249464\n",
      "29500. Accuracy: 0.8780487804878049 Loss: 0.30769800531537533\n",
      "29500. Accuracy: 0.926829268292683 Loss: 0.2571150926878135\n",
      "29500. Accuracy: 0.975609756097561 Loss: 0.14278831190845528\n",
      "29500. Accuracy: 0.8780487804878049 Loss: 0.23953957461980233\n",
      "29500. Accuracy: 0.8536585365853658 Loss: 0.3533911928826081\n",
      "29500. Accuracy: 0.8536585365853658 Loss: 0.3371703578712632\n",
      "30000. Accuracy: 0.8536585365853658 Loss: 0.3790201491443102\n",
      "30000. Accuracy: 0.9024390243902439 Loss: 0.30782640643966386\n",
      "30000. Accuracy: 0.9512195121951219 Loss: 0.15747366268169122\n",
      "30000. Accuracy: 0.8780487804878049 Loss: 0.25976285212666733\n",
      "30000. Accuracy: 0.8048780487804879 Loss: 0.37018620614036013\n",
      "30000. Accuracy: 0.8292682926829268 Loss: 0.4150364729213992\n",
      "30500. Accuracy: 0.8292682926829268 Loss: 0.4262076027123028\n",
      "30500. Accuracy: 0.8780487804878049 Loss: 0.34868827273694664\n",
      "30500. Accuracy: 0.975609756097561 Loss: 0.1587164831201154\n",
      "30500. Accuracy: 0.8536585365853658 Loss: 0.2655036177002282\n",
      "30500. Accuracy: 0.8048780487804879 Loss: 0.367637152179934\n",
      "30500. Accuracy: 0.8048780487804879 Loss: 0.36120756263114356\n",
      "31000. Accuracy: 0.7804878048780488 Loss: 0.4084114833788101\n",
      "31000. Accuracy: 0.7560975609756098 Loss: 0.6969947603157357\n",
      "31000. Accuracy: 0.6097560975609756 Loss: 0.5097054407830983\n",
      "31000. Accuracy: 0.7560975609756098 Loss: 0.5878087112258825\n",
      "31000. Accuracy: 0.8292682926829268 Loss: 0.49387250289395185\n",
      "31000. Accuracy: 0.9024390243902439 Loss: 0.3190558461026272\n",
      "31500. Accuracy: 0.8048780487804879 Loss: 0.3545574380723104\n",
      "31500. Accuracy: 0.7560975609756098 Loss: 0.581713947113441\n",
      "31500. Accuracy: 0.5853658536585366 Loss: 0.6923264269361636\n",
      "31500. Accuracy: 0.7073170731707317 Loss: 0.9033493594969827\n",
      "31500. Accuracy: 0.7317073170731707 Loss: 0.5685195442396985\n",
      "31500. Accuracy: 0.7073170731707317 Loss: 0.6583855446335272\n",
      "32000. Accuracy: 0.9024390243902439 Loss: 0.2726141345579653\n",
      "32000. Accuracy: 0.9512195121951219 Loss: 0.2454170418330939\n",
      "32000. Accuracy: 1.0 Loss: 0.13944266849389253\n",
      "32000. Accuracy: 0.926829268292683 Loss: 0.21410411180613254\n",
      "32000. Accuracy: 0.8048780487804879 Loss: 0.33144678501149405\n",
      "32000. Accuracy: 0.8780487804878049 Loss: 0.2925933343961587\n",
      "32500. Accuracy: 0.8536585365853658 Loss: 0.3361895647072843\n",
      "32500. Accuracy: 0.9024390243902439 Loss: 0.3035461809317412\n",
      "32500. Accuracy: 0.975609756097561 Loss: 0.1505968380377323\n",
      "32500. Accuracy: 0.8536585365853658 Loss: 0.24847665806165523\n",
      "32500. Accuracy: 0.8292682926829268 Loss: 0.35891261666777263\n",
      "32500. Accuracy: 0.8292682926829268 Loss: 0.39297748767059826\n",
      "33000. Accuracy: 0.8292682926829268 Loss: 0.5753630731890961\n",
      "33000. Accuracy: 0.8292682926829268 Loss: 0.4765375210184556\n",
      "33000. Accuracy: 0.8292682926829268 Loss: 0.2577798702476118\n",
      "33000. Accuracy: 0.8780487804878049 Loss: 0.3159009695570625\n",
      "33000. Accuracy: 0.8048780487804879 Loss: 0.37134915692890186\n",
      "33000. Accuracy: 0.8048780487804879 Loss: 0.34229723702983555\n",
      "33500. Accuracy: 0.8536585365853658 Loss: 0.3253295582810162\n",
      "33500. Accuracy: 0.8780487804878049 Loss: 0.2913859068079413\n",
      "33500. Accuracy: 0.975609756097561 Loss: 0.13280515977878146\n",
      "33500. Accuracy: 0.8536585365853658 Loss: 0.22937090241229943\n",
      "33500. Accuracy: 0.8292682926829268 Loss: 0.3357729480334663\n",
      "33500. Accuracy: 0.8536585365853658 Loss: 0.35351094186272525\n",
      "34000. Accuracy: 0.8536585365853658 Loss: 0.3372212505292978\n",
      "34000. Accuracy: 0.8780487804878049 Loss: 0.2966098535589584\n",
      "34000. Accuracy: 0.975609756097561 Loss: 0.12958043424209378\n",
      "34000. Accuracy: 0.8536585365853658 Loss: 0.2230067378604526\n",
      "34000. Accuracy: 0.8048780487804879 Loss: 0.36622552357071886\n",
      "34000. Accuracy: 0.8292682926829268 Loss: 0.3525934674250036\n",
      "34500. Accuracy: 0.8292682926829268 Loss: 0.2753452218348617\n",
      "34500. Accuracy: 0.8292682926829268 Loss: 0.35823481867263723\n",
      "34500. Accuracy: 0.7317073170731707 Loss: 0.45515811981930493\n",
      "34500. Accuracy: 0.7560975609756098 Loss: 0.6142490993620966\n",
      "34500. Accuracy: 0.7804878048780488 Loss: 0.5704702331308535\n",
      "34500. Accuracy: 0.7073170731707317 Loss: 0.7150811768615497\n",
      "35000. Accuracy: 0.8780487804878049 Loss: 0.2883921264360116\n",
      "35000. Accuracy: 0.8048780487804879 Loss: 0.5560748948825741\n",
      "35000. Accuracy: 0.7317073170731707 Loss: 0.44698464445926533\n",
      "35000. Accuracy: 0.7804878048780488 Loss: 0.5063058738591237\n",
      "35000. Accuracy: 0.8780487804878049 Loss: 0.3709433052942712\n",
      "35000. Accuracy: 0.9024390243902439 Loss: 0.28060226416946626\n",
      "35500. Accuracy: 0.8780487804878049 Loss: 0.30696425440140146\n",
      "35500. Accuracy: 0.8780487804878049 Loss: 0.2670969158956196\n",
      "35500. Accuracy: 0.975609756097561 Loss: 0.12973714794288868\n",
      "35500. Accuracy: 0.9024390243902439 Loss: 0.21725453911718695\n",
      "35500. Accuracy: 0.9024390243902439 Loss: 0.3022933740653091\n",
      "35500. Accuracy: 0.9024390243902439 Loss: 0.2915607640618554\n",
      "36000. Accuracy: 0.6829268292682927 Loss: 0.519471947723566\n",
      "36000. Accuracy: 0.7317073170731707 Loss: 0.6247317642777321\n",
      "36000. Accuracy: 0.6341463414634146 Loss: 0.5980869538699015\n",
      "36000. Accuracy: 0.7560975609756098 Loss: 0.6377454983587142\n",
      "36000. Accuracy: 0.8048780487804879 Loss: 0.42547426495060336\n",
      "36000. Accuracy: 0.8292682926829268 Loss: 0.3959302455263984\n",
      "36500. Accuracy: 0.926829268292683 Loss: 0.23466043854517452\n",
      "36500. Accuracy: 0.8780487804878049 Loss: 0.2605302742272516\n",
      "36500. Accuracy: 0.9024390243902439 Loss: 0.2261976237327049\n",
      "36500. Accuracy: 0.8048780487804879 Loss: 0.27313206764867487\n",
      "36500. Accuracy: 0.8536585365853658 Loss: 0.3291564425783139\n",
      "36500. Accuracy: 0.926829268292683 Loss: 0.2413103843699633\n",
      "37000. Accuracy: 0.8780487804878049 Loss: 0.2616251014618593\n",
      "37000. Accuracy: 0.8780487804878049 Loss: 0.2558857618612365\n",
      "37000. Accuracy: 1.0 Loss: 0.16436943246046445\n",
      "37000. Accuracy: 0.8780487804878049 Loss: 0.24169255794662897\n",
      "37000. Accuracy: 0.8048780487804879 Loss: 0.32279041944444936\n",
      "37000. Accuracy: 0.8780487804878049 Loss: 0.2553964881241552\n",
      "37500. Accuracy: 0.8292682926829268 Loss: 0.3992028807426604\n",
      "37500. Accuracy: 0.9024390243902439 Loss: 0.3394652880912708\n",
      "37500. Accuracy: 0.975609756097561 Loss: 0.1355221770486093\n",
      "37500. Accuracy: 0.8292682926829268 Loss: 0.26695511419702034\n",
      "37500. Accuracy: 0.7317073170731707 Loss: 0.46883697343108555\n",
      "37500. Accuracy: 0.6585365853658537 Loss: 0.6612152787858678\n",
      "38000. Accuracy: 0.9024390243902439 Loss: 0.2630613798835898\n",
      "38000. Accuracy: 0.9512195121951219 Loss: 0.24955911419418347\n",
      "38000. Accuracy: 1.0 Loss: 0.14509966160079538\n",
      "38000. Accuracy: 0.9024390243902439 Loss: 0.24189950627100495\n",
      "38000. Accuracy: 0.8780487804878049 Loss: 0.31936442716623126\n",
      "38000. Accuracy: 0.8536585365853658 Loss: 0.27924715010812856\n",
      "38500. Accuracy: 0.9024390243902439 Loss: 0.2512747727533224\n",
      "38500. Accuracy: 0.8536585365853658 Loss: 0.30211943334752844\n",
      "38500. Accuracy: 0.8536585365853658 Loss: 0.33574670689468084\n",
      "38500. Accuracy: 0.7560975609756098 Loss: 0.45581925693238334\n",
      "38500. Accuracy: 0.8048780487804879 Loss: 0.4790186708522728\n",
      "38500. Accuracy: 0.7073170731707317 Loss: 0.60206200851953\n",
      "39000. Accuracy: 0.9024390243902439 Loss: 0.2710031059816079\n",
      "39000. Accuracy: 0.9512195121951219 Loss: 0.24248562112521577\n",
      "39000. Accuracy: 1.0 Loss: 0.14630090882788932\n",
      "39000. Accuracy: 0.9024390243902439 Loss: 0.23870051108027512\n",
      "39000. Accuracy: 0.8780487804878049 Loss: 0.32065172905773115\n",
      "39000. Accuracy: 0.8780487804878049 Loss: 0.2818887378264609\n",
      "39500. Accuracy: 0.9024390243902439 Loss: 0.24036835779289797\n",
      "39500. Accuracy: 0.8048780487804879 Loss: 0.3894757410588949\n",
      "39500. Accuracy: 0.7560975609756098 Loss: 0.41251244303990486\n",
      "39500. Accuracy: 0.7560975609756098 Loss: 0.4926451196148054\n",
      "39500. Accuracy: 0.7804878048780488 Loss: 0.45263148622248944\n",
      "39500. Accuracy: 0.7560975609756098 Loss: 0.3988577513158957\n",
      "40000. Accuracy: 0.926829268292683 Loss: 0.23387289138702905\n",
      "40000. Accuracy: 0.8780487804878049 Loss: 0.28779516501607944\n",
      "40000. Accuracy: 0.8780487804878049 Loss: 0.264106044966274\n",
      "40000. Accuracy: 0.8292682926829268 Loss: 0.3058224696799663\n",
      "40000. Accuracy: 0.8536585365853658 Loss: 0.32327393303093166\n",
      "40000. Accuracy: 0.9024390243902439 Loss: 0.2660097274822132\n",
      "40500. Accuracy: 0.8780487804878049 Loss: 0.24633096020013603\n",
      "40500. Accuracy: 0.8048780487804879 Loss: 0.40265510898788126\n",
      "40500. Accuracy: 0.7317073170731707 Loss: 0.463359181280165\n",
      "40500. Accuracy: 0.7560975609756098 Loss: 0.5759168458500061\n",
      "40500. Accuracy: 0.8292682926829268 Loss: 0.4501346156975553\n",
      "40500. Accuracy: 0.7317073170731707 Loss: 0.45206651633674955\n",
      "41000. Accuracy: 0.8780487804878049 Loss: 0.28309274217713853\n",
      "41000. Accuracy: 0.9024390243902439 Loss: 0.25625033021475024\n",
      "41000. Accuracy: 0.975609756097561 Loss: 0.12390293120651459\n",
      "41000. Accuracy: 0.9024390243902439 Loss: 0.21887098115700068\n",
      "41000. Accuracy: 0.8292682926829268 Loss: 0.3033885278051742\n",
      "41000. Accuracy: 0.8536585365853658 Loss: 0.3242816050544856\n",
      "41500. Accuracy: 0.8292682926829268 Loss: 0.366373068261959\n",
      "41500. Accuracy: 0.7560975609756098 Loss: 0.4868297202926427\n",
      "41500. Accuracy: 0.7317073170731707 Loss: 0.4672027182668709\n",
      "41500. Accuracy: 0.7560975609756098 Loss: 0.5741140855645275\n",
      "41500. Accuracy: 0.8048780487804879 Loss: 0.4333210834210393\n",
      "41500. Accuracy: 0.926829268292683 Loss: 0.3059670024634801\n",
      "42000. Accuracy: 0.8780487804878049 Loss: 0.2654802633171104\n",
      "42000. Accuracy: 0.926829268292683 Loss: 0.24463878087680344\n",
      "42000. Accuracy: 0.975609756097561 Loss: 0.13050716950548327\n",
      "42000. Accuracy: 0.8780487804878049 Loss: 0.21408133385108064\n",
      "42000. Accuracy: 0.8536585365853658 Loss: 0.3185116735742615\n",
      "42000. Accuracy: 0.8536585365853658 Loss: 0.3345122993516083\n",
      "42500. Accuracy: 0.9512195121951219 Loss: 0.2336209654018282\n",
      "42500. Accuracy: 0.8048780487804879 Loss: 0.2995473479667286\n",
      "42500. Accuracy: 0.7804878048780488 Loss: 0.3804759522759557\n",
      "42500. Accuracy: 0.7560975609756098 Loss: 0.4584486811427389\n",
      "42500. Accuracy: 0.7560975609756098 Loss: 0.47101663601253413\n",
      "42500. Accuracy: 0.7317073170731707 Loss: 0.5014560726167334\n",
      "43000. Accuracy: 0.9024390243902439 Loss: 0.27967922516757127\n",
      "43000. Accuracy: 0.926829268292683 Loss: 0.22404087119636573\n",
      "43000. Accuracy: 1.0 Loss: 0.14153198598559824\n",
      "43000. Accuracy: 0.9024390243902439 Loss: 0.21375821887002808\n",
      "43000. Accuracy: 0.8780487804878049 Loss: 0.3099946274163011\n",
      "43000. Accuracy: 0.8780487804878049 Loss: 0.2669836913403185\n",
      "43500. Accuracy: 0.926829268292683 Loss: 0.234649754892487\n",
      "43500. Accuracy: 0.9024390243902439 Loss: 0.2079144328145894\n",
      "43500. Accuracy: 0.926829268292683 Loss: 0.17780414892896046\n",
      "43500. Accuracy: 0.8536585365853658 Loss: 0.2385551657118987\n",
      "43500. Accuracy: 0.8292682926829268 Loss: 0.34776322805550475\n",
      "43500. Accuracy: 0.8536585365853658 Loss: 0.2820701943930046\n",
      "44000. Accuracy: 0.8536585365853658 Loss: 0.3712939518462616\n",
      "44000. Accuracy: 0.9024390243902439 Loss: 0.3114391738435347\n",
      "44000. Accuracy: 0.9512195121951219 Loss: 0.14533437115567066\n",
      "44000. Accuracy: 0.8780487804878049 Loss: 0.24066080825174418\n",
      "44000. Accuracy: 0.8292682926829268 Loss: 0.3141800022056562\n",
      "44000. Accuracy: 0.7804878048780488 Loss: 0.32677147880696983\n",
      "44500. Accuracy: 0.9024390243902439 Loss: 0.24855331778089818\n",
      "44500. Accuracy: 0.926829268292683 Loss: 0.21554182329480584\n",
      "44500. Accuracy: 1.0 Loss: 0.1349315075229269\n",
      "44500. Accuracy: 0.9024390243902439 Loss: 0.2042411643181894\n",
      "44500. Accuracy: 0.8780487804878049 Loss: 0.29905488979523104\n",
      "44500. Accuracy: 0.9024390243902439 Loss: 0.2559460291059624\n",
      "45000. Accuracy: 0.8536585365853658 Loss: 0.42633509103105016\n",
      "45000. Accuracy: 0.9024390243902439 Loss: 0.3626470014227426\n",
      "45000. Accuracy: 0.9512195121951219 Loss: 0.15110707168376658\n",
      "45000. Accuracy: 0.8780487804878049 Loss: 0.24683234541165094\n",
      "45000. Accuracy: 0.8292682926829268 Loss: 0.31520123883157114\n",
      "45000. Accuracy: 0.8292682926829268 Loss: 0.3383236976693113\n",
      "45500. Accuracy: 0.9512195121951219 Loss: 0.21381392504328592\n",
      "45500. Accuracy: 0.8780487804878049 Loss: 0.25365619674348683\n",
      "45500. Accuracy: 0.926829268292683 Loss: 0.18158947636660844\n",
      "45500. Accuracy: 0.8780487804878049 Loss: 0.22471376752233982\n",
      "45500. Accuracy: 0.9024390243902439 Loss: 0.2782362166023747\n",
      "45500. Accuracy: 0.9024390243902439 Loss: 0.2619185850646352\n",
      "46000. Accuracy: 0.9024390243902439 Loss: 0.25158697063603597\n",
      "46000. Accuracy: 0.7804878048780488 Loss: 0.5639595385853935\n",
      "46000. Accuracy: 0.6097560975609756 Loss: 0.6000065943136048\n",
      "46000. Accuracy: 0.7317073170731707 Loss: 0.7351830677080518\n",
      "46000. Accuracy: 0.7804878048780488 Loss: 0.5213304829279191\n",
      "46000. Accuracy: 0.8048780487804879 Loss: 0.3833528353921709\n",
      "46500. Accuracy: 0.8780487804878049 Loss: 0.2512011631026424\n",
      "46500. Accuracy: 0.975609756097561 Loss: 0.21284460594107235\n",
      "46500. Accuracy: 0.926829268292683 Loss: 0.1570370153571981\n",
      "46500. Accuracy: 0.8780487804878049 Loss: 0.23516973138996816\n",
      "46500. Accuracy: 0.8780487804878049 Loss: 0.3082951225510453\n",
      "46500. Accuracy: 0.8780487804878049 Loss: 0.2785076685886802\n",
      "47000. Accuracy: 0.6829268292682927 Loss: 0.6522399127678278\n",
      "47000. Accuracy: 0.8048780487804879 Loss: 0.4689337576147867\n",
      "47000. Accuracy: 0.8048780487804879 Loss: 0.43945888032926006\n",
      "47000. Accuracy: 0.7804878048780488 Loss: 0.46602341573571054\n",
      "47000. Accuracy: 0.8536585365853658 Loss: 0.3652827223989575\n",
      "47000. Accuracy: 0.9024390243902439 Loss: 0.24271335536736693\n",
      "47500. Accuracy: 0.8780487804878049 Loss: 0.2764934818238577\n",
      "47500. Accuracy: 0.9024390243902439 Loss: 0.24999705582346837\n",
      "47500. Accuracy: 1.0 Loss: 0.12545343945479615\n",
      "47500. Accuracy: 0.8780487804878049 Loss: 0.22159957875663053\n",
      "47500. Accuracy: 0.8780487804878049 Loss: 0.2914001540350097\n",
      "47500. Accuracy: 0.8292682926829268 Loss: 0.27632989149829523\n",
      "48000. Accuracy: 0.8780487804878049 Loss: 0.2723619916491858\n",
      "48000. Accuracy: 0.926829268292683 Loss: 0.2205826982353677\n",
      "48000. Accuracy: 1.0 Loss: 0.11953116777980999\n",
      "48000. Accuracy: 0.9024390243902439 Loss: 0.21338881709592797\n",
      "48000. Accuracy: 0.9024390243902439 Loss: 0.2829638838641395\n",
      "48000. Accuracy: 0.8536585365853658 Loss: 0.28822084120838054\n",
      "48500. Accuracy: 0.926829268292683 Loss: 0.2166116423323238\n",
      "48500. Accuracy: 0.926829268292683 Loss: 0.19507671084536066\n",
      "48500. Accuracy: 0.926829268292683 Loss: 0.15603133936425576\n",
      "48500. Accuracy: 0.9024390243902439 Loss: 0.22779132148544892\n",
      "48500. Accuracy: 0.9024390243902439 Loss: 0.2952261053929475\n",
      "48500. Accuracy: 0.9024390243902439 Loss: 0.2436811211961079\n",
      "49000. Accuracy: 0.8780487804878049 Loss: 0.2828776603538743\n",
      "49000. Accuracy: 0.926829268292683 Loss: 0.22555317016854204\n",
      "49000. Accuracy: 1.0 Loss: 0.11159474793331253\n",
      "49000. Accuracy: 0.9024390243902439 Loss: 0.20900707565666427\n",
      "49000. Accuracy: 0.9024390243902439 Loss: 0.27565786703394385\n",
      "49000. Accuracy: 0.8536585365853658 Loss: 0.2815764702865532\n",
      "49500. Accuracy: 0.8292682926829268 Loss: 0.3816997324311273\n",
      "49500. Accuracy: 0.8780487804878049 Loss: 0.2896660683962918\n",
      "49500. Accuracy: 0.975609756097561 Loss: 0.11623756283709524\n",
      "49500. Accuracy: 0.8536585365853658 Loss: 0.23027527006406834\n",
      "49500. Accuracy: 0.8536585365853658 Loss: 0.2887802802379215\n",
      "49500. Accuracy: 0.8536585365853658 Loss: 0.2780294589534635\n"
     ]
    }
   ],
   "source": [
    "train = Train(network2d, learning_rate, batch_size, epochs, loss_function)\n",
    "cost, accuracies = train.train(inputs_train, outputs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "84aeaac7-3438-4b42-aca2-048f3fc7d197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAGdCAYAAADJ6dNTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAABDZUlEQVR4nO3deVxU9f4/8NeAApqAepVFxS1Lyz0zw8rsSqn5rezeW93qtmfXrt5fZjcTsyzrht+srG9ZVl6lzdxy6bojirjgAoqKCsomoAybMMM6LPP5/YGMjMzA7Oecmdfz8ZjHQ2bO8uYIw2s+57OohBACRERERDLhJXUBRERERM0xnBAREZGsMJwQERGRrDCcEBERkawwnBAREZGsMJwQERGRrDCcEBERkawwnBAREZGstJO6AEvo9XpcvnwZ/v7+UKlUUpdDREREFhBCoLy8HD169ICXl+XtIYoIJ5cvX0ZYWJjUZRAREZENcnNz0atXL4u3V0Q48ff3B9D4zQUEBEhcDREREVlCq9UiLCzM8HfcUooIJ023cgICAhhOiIiIFMbaLhnsEEtERESywnBCREREssJwQkRERLLCcEJERESywnBCREREssJwQkRERLLCcEJERESywnBCREREssJwQkRERLLCcEJERESywnBCREREssJwQkRERLLCcEJEROREq4/m4HBmidRlKIoiViUmIiJSoqSLpZi74TQAIHvRFImrUQ62nBARETlJXmmV1CUoEsMJERERyQrDCREREckKwwkRERHJCsMJERERyQrDCREREckKwwkRERHJCsMJERERyQrDCREREckKwwkRERHJCsMJERERyQrDCREREckKwwkRERHJCsMJERERyQrDCRERkZOoVCqpS1AkhhMiIiKSFYYTIiIikhWGEyIiIpIVhhMiIiKSFYYTIiIikhWGEyIiIpIVhhMiIiKSFYYTIiIiJ+EsJ7ZhOCEiIiJZYTghIiIiWWE4ISIiIllhOCEiIiJZYTghIiIiWWE4ISIichIuSmwbhhMiIiKSFYYTIiIikhWGEyIiIpIVhhMiIiKSFYYTIiIiJ1FxAnubMJwQERGRrDCcEBERkawwnBAREZGsMJwQERGRrDCcEBERkaxYFU6ioqIwevRo+Pv7IygoCFOnTkVaWlqr+0RHR0OlUhk9/Pz87CqaiIiI3JdV4WTfvn2YMWMGDh8+jJiYGNTV1eGBBx5AZWVlq/sFBAQgPz/f8Lh48aJdRRMREZH7amfNxjt27DD6Ojo6GkFBQUhKSsK4cePM7qdSqRASEmJbhURERArFhf9sY1efE41GAwDo2rVrq9tVVFSgT58+CAsLwyOPPIIzZ860ur1Op4NWqzV6EBERkWewOZzo9XrMmjULd911F4YMGWJ2u4EDB2LFihXYvHkzfv75Z+j1eowdOxZ5eXlm94mKikJgYKDhERYWZmuZREREpDAqIYSwZcdXX30V27dvx4EDB9CrVy+L96urq8Mtt9yCJ598Eh988IHJbXQ6HXQ6neFrrVaLsLAwaDQaBAQE2FIuERGRy20/nY9XfzkOAMheNEXialxPq9UiMDDQ6r/fVvU5aTJz5kxs2bIF8fHxVgUTAGjfvj1GjhyJ9PR0s9v4+vrC19fXltKIiIhI4ay6rSOEwMyZM7Fx40bs2bMH/fr1s/qEDQ0NOH36NEJDQ63el4iIiNyfVS0nM2bMwKpVq7B582b4+/tDrVYDAAIDA9GhQwcAwLPPPouePXsiKioKALBw4ULceeedGDBgAMrKyrB48WJcvHgRL7/8soO/FSIiInIHVoWTb775BgAwfvx4o+dXrlyJ559/HgCQk5MDL69rDTKlpaWYNm0a1Go1unTpglGjRuHQoUO49dZb7auciIiI3JJV4cSSvrNxcXFGXy9ZsgRLliyxqigiIiLyXFxbh4iIiGSF4YSIiIhkheGEiIiIZIXhhIiIiGSF4YSIiMhJuPCfbRhOiIiInIbpxBYMJ0RERCQrDCdEREQkKwwnREREJCsMJ0RERCQrDCdEREQkKwwnREREJCsMJ0RERCQrDCdEREQkKwwnREREJCsMJ0RERE7C6ettw3BCREREssJwQkRERLLCcEJERESywnBCRETkJOxyYhuGEyIiIpIVhhMiIiKSFYYTIiIikhWGEyIiIpIVhhMiIiKSFYYTIiIikhWGEyIiIidRcf56mzCcEBERkawwnBAREZGsMJwQERGRrDCcEJHb+eXIRXyw5SyEEFKXQkQ2aCd1AUREjvb2xhQAwKQhIRjdt6vE1RCRtdhyQkRuq6KmXuoSiMgGDCdEREROwoHEtmE4ISIiIllhOCEiIiJZYTghIiIiWWE4ISIichLOXm8bhhMicltL96ZLXQIR2YDhhIjcVuLFUqlLICIbMJwQERGRrDCcEBERkawwnBAREZGsMJwQERGRrDCcEBERkawwnBAREZGsMJwQkUcQQkhdAnkgTsJmG4YTInILReU6FGprTL62N60Qo/8di7i0QhdXRUS2YDghIsVr0AuM/vdu3PFRLGrqGlq8/sLKYyiu0OH5lcckqI48mQpsOrEFwwkRKZ6u/logmb022ei1X4/muLgaIrKXVeEkKioKo0ePhr+/P4KCgjB16lSkpaW1ud+6deswaNAg+Pn5YejQodi2bZvNBRMRtWbbabXR15EbTktUCRHZyqpwsm/fPsyYMQOHDx9GTEwM6urq8MADD6CystLsPocOHcKTTz6Jl156CSdOnMDUqVMxdepUpKSk2F08ERERuZ921my8Y8cOo6+jo6MRFBSEpKQkjBs3zuQ+X3zxBSZNmoQ333wTAPDBBx8gJiYGX331FZYtW2Zj2UREROSu7OpzotFoAABdu3Y1u01CQgIiIiKMnps4cSISEhLM7qPT6aDVao0eRERE5BlsDid6vR6zZs3CXXfdhSFDhpjdTq1WIzg42Oi54OBgqNVqM3s09m0JDAw0PMLCwmwtk4iIiBTG5nAyY8YMpKSkYPXq1Y6sBwAQGRkJjUZjeOTm5jr8HETkHip19eD8akTuxao+J01mzpyJLVu2ID4+Hr169Wp125CQEBQUFBg9V1BQgJCQELP7+Pr6wtfX15bSiMiDZBRVYMKn+3D3gG5Sl0JEDmRVy4kQAjNnzsTGjRuxZ88e9OvXr819wsPDERsba/RcTEwMwsPDrauUiOg6PyVcBAAcSC+WuBIiciSrWk5mzJiBVatWYfPmzfD39zf0GwkMDESHDh0AAM8++yx69uyJqKgoAMBrr72Ge++9F59++immTJmC1atXIzExEd99952DvxUiIiJyB1a1nHzzzTfQaDQYP348QkNDDY81a9YYtsnJyUF+fr7h67Fjx2LVqlX47rvvMHz4cKxfvx6bNm1qtRMtEZGznMgpxbf7MtCgZ0cVcgHOXm8Tq1pOLFnVMy4ursVzjz32GB577DFrTkVE5BSPfn0IANClow8eH82RgORczCa24do6ROSR0osqpC6BiMxgOCEiIiJZYTghIo9UW6/HxRLz64IRkXQYTojII0Ufysa9i+MQl1YodSlEdB2GEyLyaGuOcQZqUrYKXT1+PnwRReU6qUtxGIYTIlKExOwrWLo3nUOAia7z9sbTmL8pBU8vPyx1KQ5j0/T1RESu9pdljSuZBwf44S+jWl82g8iT7DzTOCHq+QL3GYHGlhMiUpRMDgEmcnsMJ0RERCQrDCdEREROolJxjlhbMJwQERGRrDCcEJEiVerqpS6BiJyEo3WISHF2pKgx/eckqcsgIidhywkRKc68jaelLoHIIuxxYhuGEyJSFE7BRuT+GE6IiIg8UEJGCQ6lF0tdhkkMJ0QkW7lXqvDW+lM4X1AudSlEbqWmrgFPfn8YTy0/ggoZdi5nh1gikq1pPyYiVV2O309edto5tqeosSe1AH8cFOy0cxDJja5Ob/h3pa4enXzlFQfYckJEspWqbmwxqa5rcOp5XoxOdOrxicg6DCdEREQkKwwnRERETsLZ623DcEJERESywnBCRJIor6nDjFXHsfOM2qr9BCc6IXKoy2XVUpfQAsMJEUniqz3p2HoqH3//KQkZRRVSl0OkWPYG9nkbUxxTiAMxnBCRJIrKdYZ/z1l/SsJKiDxbcYWu7Y1cjOGEiCRX4+ShwkSkLAwnREREHkbIfJUqhhMiIiInUblgXWJbYkbkBnmv7M1wQkREJLHl+zMxf9NpCBcNR9ueYt0oOVeT12T6REREHujDrecAAI+O7IVRfbpIXI302HJCRIoi93vlRPaoqjW/QrCrWlXkgOGEiCTHKb7JXTnqZ/tIZglu+yDGqhW69XqBk7ll0NUrbzQcwwkRKU6D3nM+QRIBwIvRx1BaVYf/9+sJi/dZFp+BR5YexD3/u9eJlTkHwwkRyZa5T52a6jrXFkIkMVvi+IoDWQCAwnIdDqYXm91OjmGf4YSIpMFbOUQusze10OxrVyprXViJZRhOiIiISFY4lJiIZCnlkoYrEBO1oqauAXmlVVKX4RQMJ0QkO6fyyvDwVwelLoNI1h756iDSCsqt3i+ruNIJ1TgWb+sQkcMJIVCgrWl1m+bTel8/xffB9JJWDm5XaURuw5ZgAgA7ZD47LMBwQkRO8MmuNIz5KBb/uTpawJG+jc90+DGJ5Kq6tgHfx2eiqlZ5c5XYg+GEiBxu6d4MAMAHW85KXAmRtOwdlPb57vP497ZzDqlFSRhOiMipMosqpC6BSDp2ppOj2VccU4fCMJwQkVP98dN9UpdARArDcEJEkuB6OkRtO5FTZvO+Sh6Kz3BCRJJjUCGi5hhOiIiI3JzSGlEYTojIZX4/eRkzfjmOqtp6qUshIhnjDLFE5DJNy70PCvGXuBLHq2/Qo503P++RPAghUCLDBf0sxd8kImrVD4eysfZYrkOPqeQ3TVMKtTUY9v4uzP3tFJIuXsHC/55FpY6tQyQdJcwC2xq2nBCRWYXlNVjw+xkAwJ9u68mWATN+TLiIqtoGrD6Wi9VXg5yXCpj/P7dKXBl5qn3ni8y+poQO6Fa/08THx+Ohhx5Cjx49oFKpsGnTpla3j4uLg0qlavFQq5Wd6og8QZXu2pTZejt61DXYs7NCZSpgcTWSH2cP/9XVNyCjUP4TI1odTiorKzF8+HAsXbrUqv3S0tKQn59veAQFBVl7aiJSqDEfxUJc966rMvNvInKep78/gnVJeVKX0Sarb+tMnjwZkydPtvpEQUFB6Ny5s9X7EZHyFVfosDetUOoyiFzu+hW3XaGmrsFwe/F6iRdLXVyNbVx2A3nEiBEIDQ3F/fffj4MHD7a6rU6ng1arNXoQkbI1n+ky+lC2ZHUQubvPYs5LXYLdnB5OQkNDsWzZMvz222/47bffEBYWhvHjx+P48eNm94mKikJgYKDhERYW5uwyicjFYs4VSF0CkdNJ0fn0cGaJ60/qYE4frTNw4EAMHDjQ8PXYsWORkZGBJUuW4KeffjK5T2RkJGbPnm34WqvVMqAQuZmyqjqpS3CYAm2N1CUQuRVJhhLfcccdOHDggNnXfX194evr68KKiIhss+nEJUV0MCRlUMIwX1eQZNKC5ORkhIaGSnFqItnYkaLG3N9OobZeL3Up0lPwO/KnMWlSl0DUJqWtUGx1y0lFRQXS09MNX2dlZSE5ORldu3ZF7969ERkZiUuXLuHHH38EAHz++efo168fBg8ejJqaGixfvhx79uzBrl27HPddECnQ9J+TAAADQ/zxwl39JK6GiEg+rA4niYmJuO+++wxfN/UNee655xAdHY38/Hzk5OQYXq+trcUbb7yBS5cuoWPHjhg2bBh2795tdAwiT1ZYrpO6BCJyAb1e4LmVR9EjsAP+9y/DpC5H1qwOJ+PHj28xmVJz0dHRRl/PmTMHc+bMsbowInIvSmtWJnK0lMsa7L9QDAAMJ23gQhlEREQuIOdlHNJlNqU9wwkRWUTAdW+sSuofyxYhkhtbfiYjPtvn+ELswHBCRETkJArK2bLCcEJEZrmqBYNv4ETUHMMJERGRC5RU1EpdgmIwnBAREbnA/E0pUpegGAwnROQSruxQ60rsEEuWUlu4BtOpvDKoNbat17Q3rRDn8rU27SsnkqytQ0TX8I8bkftSWdlxK01djg+3ngMAZC+aYvX5Xlh5zOp95IgtJ0RERDJxPKfUKcdVWsslwwkRERHJCm/rEElMSROOOUtybhmEEPj5SA46+XpLXQ4RSYzhhIhkYf+FYrxzdTTDW5MGSVwNkTTYB60Rb+sQkSyUVl2bA8IdWpNaWyCVyBxn/thsPJHnvIM7GMMJETmU3sziZioFzwNbUqGDprrOqn0amE0I8grar685KXUJFmM4ISKLWPKJTgiByV/sN/2awkYLNKnU1WPUh7sx/P1dVu0Xf77IpvOV19Th31vP4mRumU37k/ubuvQg1h7LlboMp2I4ISKH0VTXIa2gXOoyHCqvtNql5/tkZxq+35+FR5YedOl5STmSc8sw57dTUpfhVAwnREQykqp2r3BHZAuGEyIyy5X9RJTaf5QdX8mRlHr709EYTogkxr9tyrH/gm39SIjIOgwnREQWeuY/R3Eks0TqMojcHsMJEZEVkpy09kkTNqSRMyithZbhhMjDncorQ1xaoUOOZc8bIO+1kzuS0TQnisJwQiQxqSdpevirg3h+5THklFTZtH9eaRXWHstFbb2+1e3aCi5K+2RnieIKndQlECkSwwkRAQDyymwLJ/d9Eoc5v53C9/szoXfHhNGG1r7jV35MdFkd5B5O5WmkLkEWuPAfEdml7uo87YcyitGlo4/E1dgn5ZIGvbp0QOdWvg9r8tfxnDL7iyJFs7ZlNF9TY/h3WbP1pjwNW06IyGEcdRtDijtdSRev4H++PIA7o2IlOHszntf4RGZEbUuVugTJeHQ4Ka+pw6m8Mk6iRCQDUv8axqU1zmFSU2fcd0bqPkHkudYkuvf6Oa3x6HDywJJ4PPzVQexJdcxIBSKyHT8ikDtKuujcoeeWij6ULXUJVvHocNJ0b297ilriSsiTSd1i4Eju9L0QOcJHZm7N5F6xrQO6p/DocEJEjtXaXCXumlsYyMgW93y8F8edPKGfkjGcEBHJVIOeyced/ffkZalLMFKhq5e6BAOGE/CTD5Gj2DVDLH8RARi3Pq04kCVhJeRp6htan0jRlRhOiMgsV45UUUo0ceWn3fVJeS47F5GcMJwQkSzUNygjnqSqy6UugcjtMZyAC46RtNxpHo3skkqzr7X1bc7beNqxxbgI3z+IHI/hhIgcZnOyvDr4EcmZSmZrFsup2xfDCRERzLfsuPrPh5z+QBBJheGEiByirU+B/JtLZKyk0jFrUbkjhhOA75pEROQQQgj8a91JfLsvo81teRvUvHZSF0Dk6diMT+aws62ylFToMGtNMvZfKAYA/P3eGyWuSLkYTogIgAW3Zfh30iReF2ryj1+O40jWFanLsJmcfpR5Wwfy+g8hIs/G9yPlUnIwkRuGEyIiIpIVhhMiIgDFlbVSlwC9XiDlkkbqMshJ3GnCRWdjOCEii9jbOVPufTNWHcmR9PxCCPzfngvQ1ctn8bXWqDU12JGiht4DVk4WQqBORoviOYucFt9kOIG8/kOIACBNXY6Ptp1DWZX0n+apdY5693hu5TF8vvuCg47mfPd8vAfTf07C+uPuvzjhC9HHcNsHMSivqZO6FI/BcEIkQxM/j8d38Zl4Z/MZqUvxeK5qio8/X9TiOTl/bqq7ulBj07BZdxaXVoTymnrsSS10+LH5AcQ0hhMiibX2x8+d+h9Yc1soanuqEyshe6SqtcgoqpC6DKc6nlOKOetPoqTC/AyuQgjka6rtPteMVcftPoY74jwn4NA9Ikeo17d+T/6/CpoN81j2FYzu21XqMmSnvKYOkz7fL3UZTvenrw8BACprG7D0qdtMbrNk9wX8X+wFzJ08CNPtmGztYHqJzfu6M7acEFnhfEE5+s7dislf7EdNXYPU5TiUvR1eD2e2PsfDZU2NXcd3paJyrnliSnGFfG9BCCEc/juZVVRp9rX/i23sH7TIilY+uQ/WkdMHdavDSXx8PB566CH06NEDKpUKmzZtanOfuLg43HbbbfD19cWAAQMQHR1tQ6lE0pv+UxIA4Fy+Ft/FZzrkmG31K3DVaIinvj+C5Nwyl5yL3Md/T17G57vPO+345TV1+M+BLFwua/0WyutrkjHonR3IKaly2LnP5mux145+JuxPYjurw0llZSWGDx+OpUuXWrR9VlYWpkyZgvvuuw/JycmYNWsWXn75ZezcudPqYomkVtrszSbTBffds4orMeS9nTiVV+b0cwHAjF94/xuwriOqnDutuoozRxm99/tZfLDlLKYuPdjqdpuu3jb86XC2Q8//QvQxm/cdsTDGgZV4Fqv7nEyePBmTJ0+2ePtly5ahX79++PTTTwEAt9xyCw4cOIAlS5Zg4sSJ1p7eKfjmQnJQU9eATScu4b5BQUbPV9U2YM76U9gxa5xElRFZr7Zej5r6Bvj7toPKjiFP8RcaRzEV8labR3F6h9iEhAREREQYPTdx4kTMmjXL7D46nQ463bUfRK1W66zyiKzizBz78Y40rDiYheAAXyeexXamQnyautz1hXgQuX1uOn6x1OJtb/8wBtqaegBA7Bv34sbunaw+nxDCrfr/eMB8dQ7j9A6xarUawcHBRs8FBwdDq9Wiutr0PcSoqCgEBgYaHmFhYc4uk0hy21PyAQAFWue9GW86cQnrkxw3adYrPyU67FhyYm/nYHf1xrqTFm/bFEwA4B8/23a78PeTyhnhZY9amcwKLKe7CLIcrRMZGQmNRmN45ObmOvV8Mvr/IAWp0NVDCAGtA2aN/DouHfmtjGa5VFZt90zGNXUNmLUmGf9adxKaKsfMdHlFxqM3nOlETinu/2yfyYnTqKW0gnJcsWHtou2n1U6oRn5unr9d6hJkx+nhJCQkBAUFBUbPFRQUICAgAB06dDC5j6+vLwICAoweRNZKuaTBo18fxOFMx80j0Dwf7D5XiH6R2zDsvV1IsqK525SPd6S1+np5TT0W72x9m7bUNlsbpNrNhkE7V8v+En9bfgQXCivw7Iqj4Mcby6Sq3ef2/KU2Rg6R/ZweTsLDwxEbG2v0XExMDMLDw519avJwz604ihM5Zfjrd4edfq5v4jJs3rfewgXFvrbjHGSdthqpKmsZ7qylra7D7R/uRt+5WxU/w+zsNclSl+D2rA4nFRUVSE5ORnJyMoDGocLJycnIyWlc0TMyMhLPPvusYfvp06cjMzMTc+bMQWpqKr7++musXbsWr7/+umO+AyIzSpo1I8/97ZRsV09dfiBL6hJaEELguRVH8c9fT0hdiuT0croRr2Df789C8dXp4JtmYHXWeZzdh+OyA6atp9ZZHU4SExMxcuRIjBw5EgAwe/ZsjBw5Eu+++y4AID8/3xBUAKBfv37YunUrYmJiMHz4cHz66adYvny5bIYRA1yV2BOsPpaLhVvOWrRtYXkNqmrr295Qwdrq8JlVXIl954vanJTNE35zlsQ4b4IxJTieU2pTf5HrNb/1qal27uq+PyZkO/X47kpOHcGtHko8fvz4Vv+Ym5r9dfz48Thxgp/ASFrRh7Lx3sODW92mQFuDMR/FoqOPN84unNTidSUHWWtmmpBpI5PLCAC6+gb4tvPG9hTP6JRpysH0Yjy9/Aj82nsh9QPL57eSWlax+WnnSRlkOVqHyBFsmffpaFbj+jBV7FPQpqJyHSp07tnC9E1cBgbO34EDF4oddsxKXb3VtxalDsNNU7fX1LV9myRVrYUQAvM3ncbXcekOOb8dc7c5zYmcUuRe4W0dZ2M4gWc0TZNzyfFNtDWO+Jv3+LcJ9h9Eps7lN44seXvT6Ta3teRa5pVWYfCCnXhmxRF7S5Ot135NxpnLWvx8OKfN0WdSyCyqwPjFe7E20fapKc7ma/GoE/vL0DUMJ0RWUHKQtWcKcVPYdG65TScuAQAOpjtuWLsrbEq+ZPG2aQXlOJjuuJYmR5u74TSyS6owZ/2pVrdLuaQx+1pTyyo5H8MJuS2FNWaQB4o/X4T7P9uH4zmm58lxdKC0RtLFUhRbOcle1PZUJ1VjP52FI3jySj34lo2MPn0xnJDbsuSNvVJXj58SsqFuZXZWOamqrUcNJ1BzGWdEg6Z+HADw7IqjuFBYgb8tN327p6FZH5WNJ/Jw7+K9uFDgmvWMlNwyprTbrNQSwwkgq7RIrvXh1nN4Z/MZw3Lsbb6pSfyzcuu7OzFkwU6U2jm005Zvg78mtmveL+WrvS07i5rrgN08ILy+5iQullQZ1rep1NVjb2ohdPX2h9WMogqkFxqHnga9PNZ7sYWzRpudyClzzoGpBYYTcluWfHiKS2v8FKvW2tdyYupc725OwaNfH0SdhTPAWqpeLzDygxjsSS1oe+NmLLke/MRpLLukqs1tnB3aNp7IM+p83DTB2PSfk/BC9DFEbbPvVkpdgx4TPt2HiM/iUX01JL33+xm89VvbnYGdzdafx1VHcmSzmB7ZhuGE3JbUf2h/TLiIEzlliEtzzuJwi3d69uRgSmIqwFRaOAz79TUnW3TETMgowf6rw5xXH8sxtZvFmq+z1DQ5WvSh7Bbb5ZW2HdTk5Ob525FjQbgkebJ6EjZ3JKdZ8ci5mibWMscZ00rIcfpzqefP8CTpheX4zMQssyMXxth8zCe/v7ZelMpFXb9fjD7mkvM40nv/PYPeXTtK/kFFKeT0rsCWEzjnDxLJ09sbU+zaX8k/KnyDlkbEZ/EtnrtQUG60SrQ97P1/bf7+t/JQForKdSa3O18gz8X6auv1eOXHRJOvFZbXIPpQNlYezIbWiVPmv/f7GaSpXdNR2VOw5QTw6Omp3VnjJ0rjOLE+KQ8je3dGz84dMH5gkNWfOd11RlRynYsllbh/ScvAYitLZzMuqdCh6w0+rY5i+3ZfJr7dl+mo0lxi44k87Dpruv9V8/zXcF0vWSEESipr0a2Tr9HztoS96EPZ+IHr+TgUW07IfZl5k3l7YwqeX2m6idoRrQullbXYdjrf/gO1oWkWU1IWa+cOsdXlsmrD7btD6cUY9eFuzHTDVabLa2z7wPDG2pO4/cPdiD1nXcdyc9gC71gMJ0QOkl1ciS92X8ADn8fjH78cd8k5bR0J1PYbKd9pLeXq/jumWj6OZBrPPLs+KQ9jF+0xzIb6zb4MAMDWU42hedcZNQ5lXJ3NVcb/1fb2p2ktwG+4OmuvqaHdJD2GE1KkpXvT0XfuVvyWlGd2G1d2sdh1tgCTvojHkt3nzd6zdwZrvkdL3ujZL8V6pVXO68tgiqk/uE98d9jo6yVXO+CuM/H7UaCtwSs/JeGp7913nR9TOPChbXJq/WE4IUVavLNxYbGmCankwJKVWx1tf7O1TLKKK/HgF/sNn46vxzdnz1BVW49LZeanYG8enoUQOJrN9WJIfhhOSPHSC6+NIvg+PhNL96ajQldv0Voarli7xJlneGHlMcN09v9adxJn87WYsartW0rmvu3cK9V4bNkhJGabXuuF5E1X32DVatGrjuZgmpmRLkqwfH8mPtx6zqJtm7ccbm62oKEQgKaqDisOZKGwXBnLWHgCjtYhxbn+Hn/EZ/sQ8/o4hHXtiH9va3yjampZscarPychV2ETTQGN/U782nuj4rqOgbX1erT3VpkMYK013x7LLsUxhhPFSS8sNzlsuTXLrvZFUSpLgwlgPNLutdXJRq/NXpuM2NRCrE3Mxev33+yo8sgObDkhxRk4f0eL555afgT1di6osT1FjZRLjh8BI8XKsmnqctw8fzv6RW7DusTcxjrsbMPhxG3yZi6Y/PHTOMNssgBw5rLG8O/cK9KtwFtW5ZpRS02utLIeVezVxRhTOVeJbDCckOKYmryqqFyHOgevpaG0OU2aZ6CJn1/7Q/Xm1REb5Jkyi4xXF5bDmjkA8Mmutls3t7pgSP71kfvwdSOfPImc+qUxnJDbePEHx06vrXHijJKOJEXLDJG91JoarE3MhVpjup9HTZ39qy3bYuXBbEnOS8bY54TchqcuZ94UTdoKU8wwJCe7zxVi97lCdOvkg8T597d4fYmJ9YicQW/n7WByDoYTIjOU8rc8s6gSl8qqkG/mEyjQuAKut5dSviPyJOZmzN133jmreV/v9CVN2xuRy/G2DimKxoUTXlm6ZklbnB0JHvrqQJujFpbvz3JyFUREjsNwQory1PLDbW9khdZudexIcX5nPFcpqzb+dMqBNyRXdQ16xKUV2rxmDtlOTu8LvK1DinLmsmOH+uaVmh9K6cXbIEQu99WedHwRe8Hka0IIdgD3EGw5IY/1VhtDbFsLLnIjp088RNZqvoDl+lbWyzqcyan2PQXDyVW2ru5KrlHfoDeactoR1lydnMycVUdyHHo+Z2ptLRVT5DSfAdHN87fjUwvmPVHa3ENkO4aTqxhO5O3nwxdbTDmtFHJohTbVsnK+oFyyuSSImhMC+HJPutRleDw5fWRhOLnK3qnPyXkqdfV4779npS7DrcScLcADS+Lx528OWbzP6TwOuSTna22+nvMF5VxGwUMwnFz18JcHpC6BzPjtuPl70M6mq7e/ZcFUy0maxGt4rEtsvKbWdDBWyoy5pGyt3bpZvDMNPx++6MJqSCoMJ1dllyhvNVpP0SBhq9baRMcHo5IKndHaN1JgnxNSqu85Z49HYDghWdPW1OF9CW/pqDXV2HLqMraectycJ1nFlW1v5GS8i0lEcsZ5TqgFIQTeWHsS3fx9Me/BWySt5fv4TEnPfyijBEv3ZgAA7h7wgN3Hq6lrwF+WJdh9HHulF1ZIXQKRTZpa/So5csfh5NSfh+GEDFLVWpRW1qHLDe2x4UTjsF2pw0mlTtrRJBXNZql8Pvqo3cc7mqXceRrkMOqI3Js1fxwHL9jpxEpIarytQwaTPt+PJ78/jGwZ3HYAGod3/37ysqQ1XGjWwuCIVY9P5dl/DCnllFThr98l4GB6sdSlkBtqa40oANDV6bG2jTmKSPnYckItXJRJ5+Avdl9AcYVO6jIc6pNdrlkG3hT7W2xVGLd4LwDgcOYRu+shut5/DrTd2bWwXIc5bczuTMrHlpNmSitNL93tCTZIOFzXnK/2usekTCqnr0tMROReGE6aGflBjNQlSEIIgdlrT0pdhvu6mk32nS+Stg47XSiQdm4WInIuGfWHZTi5niMm3VKag+klRl9bMltug17gp8MXkXKJs4Za6rkV9neotZUjeuH/elQ5aw0RkfXk1Omd4eQ6A+fvkLoEl8u5YtzHZPHOawtwpanLUVXbcsje4p1peGdTCv7nywOSTpKmFB9uUf70+5c1NVKXQEQeguHEhNhzBVKXYJN8TTW0NdZPMd7abKETP4/HlP9rObX/sn0Zhn87ctHEXWfUWO1mn9AX/vcsllvQ0Y+IiBoxnJjw0g+J0FQpax2RjKIKhEftwbD3dkFvZUvG2xtTWn3dlTOavvJTEuZuOI30Qvfp3yCHGWGJiJSE4cSM4Qt3IeliqdRlWOwvzVaXdfUKy0Pfc/xkSN/Hs6WBiMiV5NQhlvOctKL5cvLZi6ZIWEnbSp3c0lNbr4dPO9NZtq5BYE9qAf44KNiucyRdvDZ7alm15w7rJiLydGw5sVDfuVvRd+5W/JYkv/lArueMFWfnrG99qPGL0Yl2n+PP31xbc6akguHEkWT0gYiIZIqjdRTsjXUn0XfuVqnLcJjl+y1bWG9T8mX8fvIyNidfQnWt6eHWF0va7luhranDofRiwwifVUdyTE6FnqigW2pK4G4z7RKRe2M4sVHfuVuNRqxIKfe6ocDX3zesb2U0jSVrWTT5f7+ewGurk/HqL0kmX399TXKbx3h8WQKeWn4EPxzKxq4zaszbeBpPL+dU6M627bRa6hKIiCzGPid2WLQ9FYu2pwIATr/3APz92ktSR26p+bVw/v5TInaeKcD21+7BLaEBDjlfXJrpmU6LLbgVk6puHIWz0A3m/SAicidy6hDLlhMHGfreLkO/FEfMxmmP5pOi7TzTOGfL5C/2O/289vR1OXOZM80SEVEjhhMn6Be5DX3nbkV4VCxq6x03QZmlRn4Qg/0XilrM1bL6aI5T68m9Um3zvqYmeiMiIs9kUzhZunQp+vbtCz8/P4wZMwZHj5pfMyQ6Ohoqlcro4efnZ3PBSpKvqcHN87ej79yt2JGSb/NxtDV1mLr0oNl1bHR1xoGjtl6PZ/5zFMMX7jJ6fu6G0/jewg6w5H4Kyzn9PBEpg9V9TtasWYPZs2dj2bJlGDNmDD7//HNMnDgRaWlpCAoKMrlPQEAA0tKurdeiktN4JReZ/vNxw7+fC++DF+/uh+AAP/i1925z32HvNYaM//nygMn5Vqzpv5GQUYJ/jL8RC34/g5uD/S3ez1ZCCFTVNuAGX3Zvktq9i+OkLoGIZExOf5qt/ovx2WefYdq0aXjhhRcAAMuWLcPWrVuxYsUKzJ071+Q+KpUKISEh9lXqRn5IuIgfEi4avk7/92R8FnMex3NK8dnjIxAS4AcvL9M/JUKIFuHOmunRBQR2nlHjx2bnd6b7PolDdkkVfns1HKP6dHXJOYmIyHpy6hBrVTipra1FUlISIiMjDc95eXkhIiICCQkJZverqKhAnz59oNfrcdttt+Gjjz7C4MGDzW6v0+mg012bl0Gr1VpTpuIMeHu74d9jF+1pddu3fjuFj/8y3OZzCQEsiblg8/6W0OsFTuaV4ZbQAGSXNI4k+vM3CbKfZZeIiOTBqnBSXFyMhoYGBAcbT1MeHByM1NRUk/sMHDgQK1aswLBhw6DRaPDJJ59g7NixOHPmDHr16mVyn6ioKLz//vvWlOYx1ibmIepPwzDh0zjDH35rHMoocUJV1+xNLcQb607iSmUtxt3c3annIiIi9+T00Trh4eF49tlnMWLECNx7773YsGEDunfvjm+//dbsPpGRkdBoNIZHbm6us8tUlBvnbbMpmLjCC9HHcKWycb6T+PPG86FoqpW10jMREUnDqpaTbt26wdvbGwUFBUbPFxQUWNynpH379hg5ciTS09PNbuPr6wtfX19rSiMFuKuNW1ZERESAlS0nPj4+GDVqFGJjYw3P6fV6xMbGIjw83KJjNDQ04PTp0wgNDbWuUlK8Cl291CUQEZECWH1bZ/bs2fj+++/xww8/4Ny5c3j11VdRWVlpGL3z7LPPGnWYXbhwIXbt2oXMzEwcP34cf/vb33Dx4kW8/PLLjvsubHTs7QipSyAiIqLrWD2U+IknnkBRURHeffddqNVqjBgxAjt27DB0ks3JyYGX17XMU1paimnTpkGtVqNLly4YNWoUDh06hFtvvdVx34WNuvvz1hEREZHcqITUC8FYQKvVIjAwEBqNBgEBjlm8rrm80irUNQjc90mcw49NRESkBPvn3Iewrh0dekxb/35z2k4Avbo0/mc0zcPRd+5WKcshIiLyaFz4z4TsRVM4YRgREZFEGE5akb1oCuZOHiR1GURERB6F4aQN0++9EbPvv1nqMoiIiDwGw4kF/t+EmzB/yi1Sl0FEROQR2CHWQi/f0x8v39MfdQ163NRsoT4iIiJyLLacWKm9txeyF03Bb69aNiMuERERWYfhxEaj+nRF9qIp2D/nPqlLISIicisMJ3YK69oR2YumYNJgyxY+JCIiotYxnDjIsmdGcW4UIiIiB2A4cbDsRVNw/J37pS6DiIhIsRhOnKDrDT7IXjQF//vnoVKXQkREpDgMJ070xOjeyF40BWNv/IPUpRARESkGw4kLrJp2J1I/mCR1GURERIrAcOIifu29kb1oClLenyh1KURERLLGGWJdrJNvO6NRPQ16gRvnbTO7/coXRuPW0ACM+SjW8FyfP3TExZIqp9ZJRESepUEvpC7BgC0nEvP2UiF70RRkRT1o9Pz66eHIXjQF9w0MQnCAH47Mm4DbenfGyudHY/q9N0pULRERuavY1EKpSzBgy4lMqFSqVudJCQ7ww4Z/3AWgMd1GbjjtqtKIiMgD6OobpC7BgC0nCuTtpcLRtydIXQYREbkRFVRSl2DAcKJQQf5+iJw8CD07d5C6FCIiIodiOFGwv997Iw7O/aPUZZCC/fvRIVKXQETUAsOJB2pqbXng1mCJKyEp7Z49Do+NCpO6DCKSidxS+YwCZTjxMLf36YKNM8bivYduxeLHhktdDknk95l3YUCQP3za8S2AiBpdqaiVugQDvjN5GC+VCkH+fnj+rn4I7NBe6nIUIzjAV+oSHKoH+yoR0XVU8ukPy3DiDq6fIyX53fuRvWgKshdNwR8HBRm9Nn5Qd1eWpmgJkdf68yx4aDAW/2WYhNUQETmXnMIJ5zlxA63NkbLi+dEQQuBo1hWotTV4cGioi6tTrpAAPwzrFYhLpdWYPCQEKpUKb64/Zfdx9/5rPO77JM7+Au0go/cgIpIJDiUml1KpVBjT/w94ZERPtPfmf7mlVCoVNs+4C4nzI6Cy8yNFzOvjEBLgh80z7kK/bje0aO0iIpKcfLIJW06IWmNvKAGANycOxE3B/jg879rEeY44LhGRI8npXYkfoz3c7tnjpC6BJMBwRETXk9P7AltOPNyAIH9kL5qC8po6tPPygl4IFGhr8P5/z2Lf+SKpyyMiIheRTzRhOKGr/P2uDSvu370TfnjxDqPX0wsrUFpVi5UHs3BzsD8+333B1SUSEZGHYDghiwwI6gQAGN23KwBgVsTNhtfWHstFcl4ZZk24CfvOF2HuhtNo0AtJ6iTLyOkTEhHR9RhOyG6Pjw7D46Mbp0F/7PYwPHb7tSnRhRDQ1esRl1aEwT0CMP6TOEUHl5fu7of/HMiSugwiIoeTUZcTdogl51KpVPBr741JQ0IQ1rUjds5Sdgfc+VNukboEh5DTmxAR0fUYTsilBgR1QvaiKTgcOQHvPzxY6nKM3DewO757ZlSr2zRNePf9s7cDaAwrGR89iB+v66PT3N0Dujm0Tkc7/+Fkw79fb3a7jog8i5w+s6iEELJvY9dqtQgMDIRGo0FAQIDU5ZAT7UjJx/Sfj9t9nCfvCMOvR3Mxpl9X5F6pQjd/Xzx2exgaGvQ4lFGCXWcLDNv6eHth22v34MbuN9g9lK5QW4PPYy+guFxnOIe52XvnbzqNnw/n2HU+WyW/ez86d/QxfF3foEdWcSVuCvbH5bJqjF20R5K6iEg6U0f0wOd/HenQY9r695vhhGSptLIWIz+IsWqfV8b1xwt39UVooHIWtfsuPgMfbUvF5CEh+OZvo9Avcitc8RuZ8dGD8PZqPYg16AW8vVSoqWvAoHd2mNzmwFv3oWfnDrhUVo21iXkY2bszunfyRVVtA7r7+yK9sALRh7IwaUgo7r2pO/zaeyEowM+wf229HpnFFbhQUIGle9Px88tjUFyhw4dbzuH2vl2MRoX9aWRP9O9+A1IuabHjjBrzp9yCD7eeM6rHSwUsfGQI/nZnH+j1AufUWvTv1gmLd6Zh3M3d8IcbfOHb3gvbT6txY9ANuCU0ABM+3WfHlSRyHwwnVmI4IU9R36DHgLe3O/085lpzzMkrrcLd/7vX8PW5hZPQwcfb0WVJrq5Bj3ZXQ9sz/zmKA+nFEldE5DpyCiccrUMkI+28vZC9aArUmhrcGRULAEj9YBL82l8LAnq9QP952wAAz9zZBwsfGYxyXT02JOXhvf+edUpdvbp0tDrQKFHztad+fnlMi9c1VXW4rKnGi9HHkK+pwdCegfjbnb3x7uYz0NXr7Tr3jPtuxNK9GXYdg8gecpohli0nRB4g4rN9SC+sAABs/MdYjOzdReKKCGgcam/uD0JtvR7tvVVQqVSoa9DjwIVivBB9zPD6vAcH4aNtqWaPPSCoE7p18sH4gUE4mF6M/Rcc1wo0KMQfqepyw9dvTRqEr+PSUV5Tb3af2DfuxZ5zhaipa8CnMecdVospaR9Ogqa6DmuP5WLLqXyjWsm8R0f2xJInRjj0mLytQ0REslBeU4fs4ioM7hEArzb6NrVFCIF8TQ3aeavQvZMv6vUCx7Kv4IdD2UhTl6Osug5Ln7oNd/Tr2uaq63q9QEVtPSp19QgJ8IOuXg9vLxXae3tBCIF6vUDulSrkXKnC8yuPGe275Z9349bQANQ26LHh+CW091Yh/kIxCjQ10FTXYcYfByD2XAG63uCDV8b1R3JOGdTaGmQUVSBy8i3Yfa4Adw/ohnxNDYID/LDvfBEyiyrwdVwGwvv/AQmZJXZdJ0d476Fb8fxd/Rx6TIYTIiIiBavQ1eMGH2+j1rRD6cV4avkRAMDav4fj8W8TnHb+9H9PRrs2Ap61GE6IiIgIQGOLU2VtA0oqdCiuqMXNwZ3Qybcd6vUCQgDrk/IwrFcg2nmrkJhdir+M6mXUt81RGE6IiIhIVmz9+80ZYomIiEhWGE6IiIhIVhhOiIiISFYYToiIiEhWGE6IiIhIVhhOiIiISFZsCidLly5F37594efnhzFjxuDo0aOtbr9u3ToMGjQIfn5+GDp0KLZt22ZTsUREROT+rA4na9aswezZs7FgwQIcP34cw4cPx8SJE1FYWGhy+0OHDuHJJ5/ESy+9hBMnTmDq1KmYOnUqUlJS7C6eiIiI3I/Vk7CNGTMGo0ePxldffQUA0Ov1CAsLwz//+U/MnTu3xfZPPPEEKisrsWXLFsNzd955J0aMGIFly5ZZdE5OwkZERKQ8LpmErba2FklJSYiIiLh2AC8vREREICHB9Hz/CQkJRtsDwMSJE81uDwA6nQ5ardboQURERJ7BqnBSXFyMhoYGBAcHGz0fHBwMtVptch+1Wm3V9gAQFRWFwMBAwyMsLMyaMomIiEjBZDlaJzIyEhqNxvDIzc2VuiQiIiJykXbWbNytWzd4e3ujoKDA6PmCggKEhISY3CckJMSq7QHA19cXvr6+1pRGREREbsKqcOLj44NRo0YhNjYWU6dOBdDYITY2NhYzZ840uU94eDhiY2Mxa9Ysw3MxMTEIDw+3+LxNfXbZ94SIiEg5mv5uWzn2BhBWWr16tfD19RXR0dHi7Nmz4pVXXhGdO3cWarVaCCHEM888I+bOnWvY/uDBg6Jdu3bik08+EefOnRMLFiwQ7du3F6dPn7b4nLm5uQIAH3zwwQcffPChwEdubq5VWcOqlhOgcWhwUVER3n33XajVaowYMQI7duwwdHrNycmBl9e1rixjx47FqlWrMH/+fMybNw833XQTNm3ahCFDhlh8zh49eiA3Nxf+/v5QqVTWlmyWVqtFWFgYcnNzOUS5DbxW1uH1shyvleV4rSzHa2U5Z14rIQTKy8vRo0cPq/azep4Td8L5UyzHa2UdXi/L8VpZjtfKcrxWlpPjtZLlaB0iIiLyXAwnREREJCseHU58fX2xYMECDlu2AK+VdXi9LMdrZTleK8vxWllOjtfKo/ucEBERkfx4dMsJERERyQ/DCREREckKwwkRERHJCsMJERERyYpHh5OlS5eib9++8PPzw5gxY3D06FGpS3Ko9957DyqVyugxaNAgw+s1NTWYMWMG/vCHP6BTp07485//3GKRxpycHEyZMgUdO3ZEUFAQ3nzzTdTX1xttExcXh9tuuw2+vr4YMGAAoqOjW9Qit2sdHx+Phx56CD169IBKpcKmTZuMXhdC4N1330VoaCg6dOiAiIgIXLhwwWibK1eu4Omnn0ZAQAA6d+6Ml156CRUVFUbbnDp1Cvfccw/8/PwQFhaGjz/+uEUt69atw6BBg+Dn54ehQ4di27ZtVtfiTG1dq+eff77Fz9mkSZOMtvGUaxUVFYXRo0fD398fQUFBmDp1KtLS0oy2kdPvnSW1OIsl12r8+PEtframT59utI0nXKtvvvkGw4YNQ0BAAAICAhAeHo7t27dbVZvirpNVk927kdWrVwsfHx+xYsUKcebMGTFt2jTRuXNnUVBQIHVpDrNgwQIxePBgkZ+fb3gUFRUZXp8+fboICwsTsbGxIjExUdx5551i7Nixhtfr6+vFkCFDREREhDhx4oTYtm2b6Natm4iMjDRsk5mZKTp27Chmz54tzp49K7788kvh7e0tduzYYdhGjtd627Zt4u233xYbNmwQAMTGjRuNXl+0aJEIDAwUmzZtEidPnhQPP/yw6Nevn6iurjZsM2nSJDF8+HBx+PBhsX//fjFgwADx5JNPGl7XaDQiODhYPP300yIlJUX8+uuvokOHDuLbb781bHPw4EHh7e0tPv74Y3H27Fkxf/78FmtPWVKLM7V1rZ577jkxadIko5+zK1euGG3jKddq4sSJYuXKlSIlJUUkJyeLBx98UPTu3VtUVFQYtpHT711btTiTJdfq3nvvFdOmTTP62dJoNIbXPeVa/f7772Lr1q3i/PnzIi0tTcybN0+0b99epKSkWFSbEq+Tx4aTO+64Q8yYMcPwdUNDg+jRo4eIioqSsCrHWrBggRg+fLjJ18rKykT79u3FunXrDM+dO3dOABAJCQlCiMY/Sl5eXoZFHYUQ4ptvvhEBAQFCp9MJIYSYM2eOGDx4sNGxn3jiCTFx4kTD13K/1tf/wdXr9SIkJEQsXrzY8FxZWZnw9fUVv/76qxBCiLNnzwoA4tixY4Zttm/fLlQqlbh06ZIQQoivv/5adOnSxXCthBDirbfeEgMHDjR8/fjjj4spU6YY1TNmzBjx97//3eJaXMlcOHnkkUfM7uOp10oIIQoLCwUAsW/fPkM9cvm9s6QWV7r+WgnRGE5ee+01s/t46rUSQoguXbqI5cuXu+3PlEfe1qmtrUVSUhIiIiIMz3l5eSEiIgIJCQkSVuZ4Fy5cQI8ePdC/f388/fTTyMnJAQAkJSWhrq7O6BoMGjQIvXv3NlyDhIQEDB061LCoIwBMnDgRWq0WZ86cMWzT/BhN2zQdQ4nXOisrC2q12qjmwMBAjBkzxujadO7cGbfffrthm4iICHh5eeHIkSOGbcaNGwcfHx/DNhMnTkRaWhpKS0sN27R2/SypRQ7i4uIQFBSEgQMH4tVXX0VJSYnhNU++VhqNBgDQtWtXAPL6vbOkFle6/lo1+eWXX9CtWzcMGTIEkZGRqKqqMrzmideqoaEBq1evRmVlJcLDw932Z8rqVYndQXFxMRoaGoz+owAgODgYqampElXleGPGjEF0dDQGDhyI/Px8vP/++7jnnnuQkpICtVoNHx8fdO7c2Wif4OBgqNVqAIBarTZ5jZpea20brVaL6upqlJaWKu5aN31vpmpu/n0HBQUZvd6uXTt07drVaJt+/fq1OEbTa126dDF7/Zofo61apDZp0iT86U9/Qr9+/ZCRkYF58+Zh8uTJSEhIgLe3t8deK71ej1mzZuGuu+4yrMIup987S2pxFVPXCgCeeuop9OnTBz169MCpU6fw1ltvIS0tDRs2bADgWdfq9OnTCA8PR01NDTp16oSNGzfi1ltvRXJyslv+THlkOPEUkydPNvx72LBhGDNmDPr06YO1a9eiQ4cOElZG7uSvf/2r4d9Dhw7FsGHDcOONNyIuLg4TJkyQsDJpzZgxAykpKThw4IDUpcieuWv1yiuvGP49dOhQhIaGYsKECcjIyMCNN97o6jIlNXDgQCQnJ0Oj0WD9+vV47rnnsG/fPqnLchqPvK3TrVs3eHt7t+hBXFBQgJCQEImqcr7OnTvj5ptvRnp6OkJCQlBbW4uysjKjbZpfg5CQEJPXqOm11rYJCAhAhw4dFHmtm+pqreaQkBAUFhYavV5fX48rV6445Po1f72tWuSmf//+6NatG9LT0wF45rWaOXMmtmzZgr1796JXr16G5+X0e2dJLa5g7lqZMmbMGAAw+tnylGvl4+ODAQMGYNSoUYiKisLw4cPxxRdfuO3PlEeGEx8fH4waNQqxsbGG5/R6PWJjYxEeHi5hZc5VUVGBjIwMhIaGYtSoUWjfvr3RNUhLS0NOTo7hGoSHh+P06dNGf1hiYmIQEBCAW2+91bBN82M0bdN0DCVe6379+iEkJMSoZq1WiyNHjhhdm7KyMiQlJRm22bNnD/R6veENNDw8HPHx8airqzNsExMTg4EDB6JLly6GbVq7fpbUIjd5eXkoKSlBaGgoAM+6VkIIzJw5Exs3bsSePXta3KqS0++dJbU4U1vXypTk5GQAMPrZ8oRrZYper4dOp3Pfnymrus+6kdWrVwtfX18RHR0tzp49K1555RXRuXNno97MSvfGG2+IuLg4kZWVJQ4ePCgiIiJEt27dRGFhoRCicchX7969xZ49e0RiYqIIDw8X4eHhhv2bhp898MADIjk5WezYsUN0797d5PCzN998U5w7d04sXbrU5PAzuV3r8vJyceLECXHixAkBQHz22WfixIkT4uLFi0KIxiGpnTt3Fps3bxanTp0SjzzyiMmhxCNHjhRHjhwRBw4cEDfddJPR8NiysjIRHBwsnnnmGZGSkiJWr14tOnbs2GJ4bLt27cQnn3wizp07JxYsWGByeGxbtThTa9eqvLxc/Otf/xIJCQkiKytL7N69W9x2223ipptuEjU1NR53rV599VURGBgo4uLijIa/VlVVGbaR0+9dW7U4U1vXKj09XSxcuFAkJiaKrKwssXnzZtG/f38xbtw4wzE85VrNnTtX7Nu3T2RlZYlTp06JuXPnCpVKJXbt2mVRbUq8Th4bToQQ4ssvvxS9e/cWPj4+4o477hCHDx+WuiSHeuKJJ0RoaKjw8fERPXv2FE888YRIT083vF5dXS3+8Y9/iC5duoiOHTuKRx99VOTn5xsdIzs7W0yePFl06NBBdOvWTbzxxhuirq7OaJu9e/eKESNGCB8fH9G/f3+xcuXKFrXI7Vrv3btXAGjxeO6554QQjcNS33nnHREcHCx8fX3FhAkTRFpamtExSkpKxJNPPik6deokAgICxAsvvCDKy8uNtjl58qS4++67ha+vr+jZs6dYtGhRi1rWrl0rbr75ZuHj4yMGDx4stm7davS6JbU4U2vXqqqqSjzwwAOie/fuon379qJPnz5i2rRpLYKnp1wrU9cJgNHvhJx+7yypxVnaulY5OTli3LhxomvXrsLX11cMGDBAvPnmm0bznAjhGdfqxRdfFH369BE+Pj6ie/fuYsKECYZgYmltSrtOKiGEsK6thYiIiMh5PLLPCREREckXwwkRERHJCsMJERERyQrDCREREckKwwkRERHJCsMJERERyQrDCREREckKwwkRERHJCsMJERERyQrDCREREckKwwkRERHJCsMJERERycr/BxJ9YKsnW4sAAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([a for a in range(len(cost))],cost)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e3ffd7-bc22-4387-85ee-236053716954",
   "metadata": {},
   "source": [
    "### e) decrease learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5d2fc9cf-e6a8-459c-8ce2-a5a3a16a1bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.000001\n",
    "network2e = NeuralNetwork(input_dim,\n",
    "                        hidden_dim,\n",
    "                        output_dim,\n",
    "                        num_of_hidden_layers,\n",
    "                        activation,\n",
    "                        activation_output,\n",
    "                        initialization,\n",
    "                        output_initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c5a0c8c6-a62c-455f-a02d-8d8355aaa3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Accuracy: 0.5365853658536586 Loss: 3.9749432749859883\n",
      "0. Accuracy: 0.5609756097560976 Loss: 4.179943152903811\n",
      "0. Accuracy: 0.7073170731707317 Loss: 2.2953936703825923\n",
      "0. Accuracy: 0.6585365853658537 Loss: 2.5516603313132022\n",
      "0. Accuracy: 0.5853658536585366 Loss: 4.004703656758679\n",
      "0. Accuracy: 0.6585365853658537 Loss: 3.1505919547607157\n",
      "500. Accuracy: 0.7804878048780488 Loss: 0.5086688187577766\n",
      "500. Accuracy: 0.5853658536585366 Loss: 0.7179461938180268\n",
      "500. Accuracy: 0.7560975609756098 Loss: 0.5629977812069251\n",
      "500. Accuracy: 0.6585365853658537 Loss: 0.6262213513371023\n",
      "500. Accuracy: 0.6829268292682927 Loss: 0.601967382675834\n",
      "500. Accuracy: 0.6585365853658537 Loss: 0.6133825224093138\n",
      "1000. Accuracy: 0.7560975609756098 Loss: 0.49019830847912765\n",
      "1000. Accuracy: 0.5853658536585366 Loss: 0.7118824109174609\n",
      "1000. Accuracy: 0.7560975609756098 Loss: 0.5402814336347469\n",
      "1000. Accuracy: 0.6829268292682927 Loss: 0.6135184324350894\n",
      "1000. Accuracy: 0.6829268292682927 Loss: 0.6055105800803693\n",
      "1000. Accuracy: 0.6829268292682927 Loss: 0.6089377734810162\n",
      "1500. Accuracy: 0.7560975609756098 Loss: 0.4888669710432574\n",
      "1500. Accuracy: 0.5853658536585366 Loss: 0.7023690014059313\n",
      "1500. Accuracy: 0.7804878048780488 Loss: 0.5338515794515911\n",
      "1500. Accuracy: 0.7073170731707317 Loss: 0.6046195177710012\n",
      "1500. Accuracy: 0.6829268292682927 Loss: 0.6003947042967084\n",
      "1500. Accuracy: 0.6829268292682927 Loss: 0.6031655328618941\n",
      "2000. Accuracy: 0.7804878048780488 Loss: 0.4859182728445972\n",
      "2000. Accuracy: 0.6097560975609756 Loss: 0.6946552084634848\n",
      "2000. Accuracy: 0.8048780487804879 Loss: 0.5292061261202732\n",
      "2000. Accuracy: 0.7073170731707317 Loss: 0.5991135250341902\n",
      "2000. Accuracy: 0.7073170731707317 Loss: 0.6005759895041023\n",
      "2000. Accuracy: 0.6829268292682927 Loss: 0.5994048152958996\n",
      "2500. Accuracy: 0.7804878048780488 Loss: 0.48233047800376927\n",
      "2500. Accuracy: 0.6097560975609756 Loss: 0.6869269285459949\n",
      "2500. Accuracy: 0.7804878048780488 Loss: 0.5267543573979984\n",
      "2500. Accuracy: 0.7073170731707317 Loss: 0.592086764464395\n",
      "2500. Accuracy: 0.6829268292682927 Loss: 0.6013333193541538\n",
      "2500. Accuracy: 0.7073170731707317 Loss: 0.5964116087473749\n",
      "3000. Accuracy: 0.7560975609756098 Loss: 0.47903213525559285\n",
      "3000. Accuracy: 0.6097560975609756 Loss: 0.6812812500507381\n",
      "3000. Accuracy: 0.7804878048780488 Loss: 0.5253176153593253\n",
      "3000. Accuracy: 0.7073170731707317 Loss: 0.5864063645210952\n",
      "3000. Accuracy: 0.6829268292682927 Loss: 0.6031826150088341\n",
      "3000. Accuracy: 0.7073170731707317 Loss: 0.5941348136347576\n",
      "3500. Accuracy: 0.7560975609756098 Loss: 0.47605494245104585\n",
      "3500. Accuracy: 0.6097560975609756 Loss: 0.6767835258875766\n",
      "3500. Accuracy: 0.7804878048780488 Loss: 0.5230555191869829\n",
      "3500. Accuracy: 0.7073170731707317 Loss: 0.5820634903325234\n",
      "3500. Accuracy: 0.6829268292682927 Loss: 0.6044945890482325\n",
      "3500. Accuracy: 0.7317073170731707 Loss: 0.591734479185839\n",
      "4000. Accuracy: 0.7560975609756098 Loss: 0.47411663551027167\n",
      "4000. Accuracy: 0.6097560975609756 Loss: 0.6728433132251048\n",
      "4000. Accuracy: 0.7804878048780488 Loss: 0.521045547404878\n",
      "4000. Accuracy: 0.7073170731707317 Loss: 0.579188215927492\n",
      "4000. Accuracy: 0.6829268292682927 Loss: 0.6057989662484811\n",
      "4000. Accuracy: 0.7073170731707317 Loss: 0.5895642528998086\n",
      "4500. Accuracy: 0.7560975609756098 Loss: 0.4719117376379688\n",
      "4500. Accuracy: 0.6097560975609756 Loss: 0.6697036260194218\n",
      "4500. Accuracy: 0.7560975609756098 Loss: 0.5190543165042458\n",
      "4500. Accuracy: 0.7073170731707317 Loss: 0.576212758748214\n",
      "4500. Accuracy: 0.6829268292682927 Loss: 0.6071342397128175\n",
      "4500. Accuracy: 0.7073170731707317 Loss: 0.5875644197225381\n",
      "5000. Accuracy: 0.7560975609756098 Loss: 0.4694574406503091\n",
      "5000. Accuracy: 0.6097560975609756 Loss: 0.6671304148322467\n",
      "5000. Accuracy: 0.7560975609756098 Loss: 0.5176203471215803\n",
      "5000. Accuracy: 0.7073170731707317 Loss: 0.5734445072077432\n",
      "5000. Accuracy: 0.6829268292682927 Loss: 0.6082524687595802\n",
      "5000. Accuracy: 0.7073170731707317 Loss: 0.5858625452433496\n",
      "5500. Accuracy: 0.7560975609756098 Loss: 0.4666922553125689\n",
      "5500. Accuracy: 0.6097560975609756 Loss: 0.6649364958126589\n",
      "5500. Accuracy: 0.7560975609756098 Loss: 0.5166077782763489\n",
      "5500. Accuracy: 0.7073170731707317 Loss: 0.5710094981736671\n",
      "5500. Accuracy: 0.6829268292682927 Loss: 0.6092706482336231\n",
      "5500. Accuracy: 0.7073170731707317 Loss: 0.5839805130538394\n",
      "6000. Accuracy: 0.7560975609756098 Loss: 0.46353288653929825\n",
      "6000. Accuracy: 0.6097560975609756 Loss: 0.6631662747573915\n",
      "6000. Accuracy: 0.7560975609756098 Loss: 0.5149516568867807\n",
      "6000. Accuracy: 0.7073170731707317 Loss: 0.5685407728433466\n",
      "6000. Accuracy: 0.6829268292682927 Loss: 0.6106340202114977\n",
      "6000. Accuracy: 0.7073170731707317 Loss: 0.5806921998437201\n",
      "6500. Accuracy: 0.7560975609756098 Loss: 0.46328397275002003\n",
      "6500. Accuracy: 0.6097560975609756 Loss: 0.660979879292479\n",
      "6500. Accuracy: 0.7560975609756098 Loss: 0.514189939165087\n",
      "6500. Accuracy: 0.7073170731707317 Loss: 0.5665748007644352\n",
      "6500. Accuracy: 0.6829268292682927 Loss: 0.6103094826482024\n",
      "6500. Accuracy: 0.7073170731707317 Loss: 0.5791316970760436\n",
      "7000. Accuracy: 0.7560975609756098 Loss: 0.46313677630047306\n",
      "7000. Accuracy: 0.6097560975609756 Loss: 0.6588085677128074\n",
      "7000. Accuracy: 0.7560975609756098 Loss: 0.5133330673007022\n",
      "7000. Accuracy: 0.7073170731707317 Loss: 0.5647329154388692\n",
      "7000. Accuracy: 0.6829268292682927 Loss: 0.6100233505809975\n",
      "7000. Accuracy: 0.7073170731707317 Loss: 0.5778984396220178\n",
      "7500. Accuracy: 0.7560975609756098 Loss: 0.46272202478934005\n",
      "7500. Accuracy: 0.6097560975609756 Loss: 0.6569584875992986\n",
      "7500. Accuracy: 0.7560975609756098 Loss: 0.5123509871103921\n",
      "7500. Accuracy: 0.7073170731707317 Loss: 0.5629560773734765\n",
      "7500. Accuracy: 0.6829268292682927 Loss: 0.6099867337098299\n",
      "7500. Accuracy: 0.7073170731707317 Loss: 0.5768158448751808\n",
      "8000. Accuracy: 0.7804878048780488 Loss: 0.46225017291171255\n",
      "8000. Accuracy: 0.6097560975609756 Loss: 0.6552959922008604\n",
      "8000. Accuracy: 0.7560975609756098 Loss: 0.5112832347479424\n",
      "8000. Accuracy: 0.7073170731707317 Loss: 0.5613369770132554\n",
      "8000. Accuracy: 0.6829268292682927 Loss: 0.6100803129896656\n",
      "8000. Accuracy: 0.7073170731707317 Loss: 0.5757215281361545\n",
      "8500. Accuracy: 0.7804878048780488 Loss: 0.4606294566383874\n",
      "8500. Accuracy: 0.6097560975609756 Loss: 0.654079059552922\n",
      "8500. Accuracy: 0.7560975609756098 Loss: 0.5098687009883418\n",
      "8500. Accuracy: 0.7073170731707317 Loss: 0.5595564334824368\n",
      "8500. Accuracy: 0.6829268292682927 Loss: 0.6109495672541199\n",
      "8500. Accuracy: 0.7073170731707317 Loss: 0.5744820163481865\n",
      "9000. Accuracy: 0.7804878048780488 Loss: 0.4595512905106981\n",
      "9000. Accuracy: 0.6341463414634146 Loss: 0.6529040646488931\n",
      "9000. Accuracy: 0.7804878048780488 Loss: 0.5088179751253031\n",
      "9000. Accuracy: 0.7073170731707317 Loss: 0.5578058800670175\n",
      "9000. Accuracy: 0.6829268292682927 Loss: 0.611247647034102\n",
      "9000. Accuracy: 0.7073170731707317 Loss: 0.5732646972400031\n",
      "9500. Accuracy: 0.7804878048780488 Loss: 0.45839858691530727\n",
      "9500. Accuracy: 0.6341463414634146 Loss: 0.6520683826190249\n",
      "9500. Accuracy: 0.7804878048780488 Loss: 0.5077353833813673\n",
      "9500. Accuracy: 0.7073170731707317 Loss: 0.5560441417636522\n",
      "9500. Accuracy: 0.6829268292682927 Loss: 0.6111281553502964\n",
      "9500. Accuracy: 0.7073170731707317 Loss: 0.5720024916814058\n",
      "10000. Accuracy: 0.7804878048780488 Loss: 0.45928151060162403\n",
      "10000. Accuracy: 0.6341463414634146 Loss: 0.6514944308361428\n",
      "10000. Accuracy: 0.7804878048780488 Loss: 0.5073950076196809\n",
      "10000. Accuracy: 0.7073170731707317 Loss: 0.5542403973516082\n",
      "10000. Accuracy: 0.7073170731707317 Loss: 0.6090272561454438\n",
      "10000. Accuracy: 0.7073170731707317 Loss: 0.5705854995185257\n",
      "10500. Accuracy: 0.7804878048780488 Loss: 0.45938642335529667\n",
      "10500. Accuracy: 0.6341463414634146 Loss: 0.6502962508704339\n",
      "10500. Accuracy: 0.7804878048780488 Loss: 0.5067435363395488\n",
      "10500. Accuracy: 0.7073170731707317 Loss: 0.552871536074943\n",
      "10500. Accuracy: 0.7073170731707317 Loss: 0.608220974064121\n",
      "10500. Accuracy: 0.7073170731707317 Loss: 0.5697304886735263\n",
      "11000. Accuracy: 0.7804878048780488 Loss: 0.4591311890884999\n",
      "11000. Accuracy: 0.6341463414634146 Loss: 0.6494729746234945\n",
      "11000. Accuracy: 0.7804878048780488 Loss: 0.505844610797525\n",
      "11000. Accuracy: 0.7073170731707317 Loss: 0.551604927088295\n",
      "11000. Accuracy: 0.7073170731707317 Loss: 0.607714238544029\n",
      "11000. Accuracy: 0.7073170731707317 Loss: 0.5688545421084105\n",
      "11500. Accuracy: 0.7804878048780488 Loss: 0.45895421562673216\n",
      "11500. Accuracy: 0.6341463414634146 Loss: 0.6483910226139368\n",
      "11500. Accuracy: 0.7804878048780488 Loss: 0.5051450036652355\n",
      "11500. Accuracy: 0.7073170731707317 Loss: 0.5504069846235491\n",
      "11500. Accuracy: 0.7073170731707317 Loss: 0.6071474634769746\n",
      "11500. Accuracy: 0.7073170731707317 Loss: 0.5680701477430293\n",
      "12000. Accuracy: 0.7804878048780488 Loss: 0.4588853496087589\n",
      "12000. Accuracy: 0.6341463414634146 Loss: 0.6473286162738904\n",
      "12000. Accuracy: 0.7804878048780488 Loss: 0.504439596112587\n",
      "12000. Accuracy: 0.7073170731707317 Loss: 0.5492919522116781\n",
      "12000. Accuracy: 0.7073170731707317 Loss: 0.6065444483790847\n",
      "12000. Accuracy: 0.7073170731707317 Loss: 0.5673167855040647\n",
      "12500. Accuracy: 0.7804878048780488 Loss: 0.4588700943868548\n",
      "12500. Accuracy: 0.6341463414634146 Loss: 0.6463251319876782\n",
      "12500. Accuracy: 0.7804878048780488 Loss: 0.5037323035458132\n",
      "12500. Accuracy: 0.7073170731707317 Loss: 0.5481492313147485\n",
      "12500. Accuracy: 0.7073170731707317 Loss: 0.6059541088755991\n",
      "12500. Accuracy: 0.7073170731707317 Loss: 0.5665529792932888\n",
      "13000. Accuracy: 0.7804878048780488 Loss: 0.4587791811946471\n",
      "13000. Accuracy: 0.6341463414634146 Loss: 0.6453965139472525\n",
      "13000. Accuracy: 0.7804878048780488 Loss: 0.5029701900202531\n",
      "13000. Accuracy: 0.7073170731707317 Loss: 0.5470392200766578\n",
      "13000. Accuracy: 0.7073170731707317 Loss: 0.6054200711709574\n",
      "13000. Accuracy: 0.7073170731707317 Loss: 0.5658656496291162\n",
      "13500. Accuracy: 0.7804878048780488 Loss: 0.4586000584880937\n",
      "13500. Accuracy: 0.6341463414634146 Loss: 0.6445848465384265\n",
      "13500. Accuracy: 0.7804878048780488 Loss: 0.5021952932815787\n",
      "13500. Accuracy: 0.7073170731707317 Loss: 0.5459538039956772\n",
      "13500. Accuracy: 0.7073170731707317 Loss: 0.6049352107781972\n",
      "13500. Accuracy: 0.7073170731707317 Loss: 0.5652309007175169\n",
      "14000. Accuracy: 0.7804878048780488 Loss: 0.4584245439614977\n",
      "14000. Accuracy: 0.6585365853658537 Loss: 0.6437335025724454\n",
      "14000. Accuracy: 0.7804878048780488 Loss: 0.5014924567175789\n",
      "14000. Accuracy: 0.7073170731707317 Loss: 0.5449082165111306\n",
      "14000. Accuracy: 0.7073170731707317 Loss: 0.6044392762507022\n",
      "14000. Accuracy: 0.7073170731707317 Loss: 0.564594732343668\n",
      "14500. Accuracy: 0.7804878048780488 Loss: 0.4581816821362544\n",
      "14500. Accuracy: 0.6585365853658537 Loss: 0.6429862765432084\n",
      "14500. Accuracy: 0.7804878048780488 Loss: 0.5007323079982647\n",
      "14500. Accuracy: 0.7073170731707317 Loss: 0.5438780229484824\n",
      "14500. Accuracy: 0.7073170731707317 Loss: 0.6039990047484444\n",
      "14500. Accuracy: 0.7073170731707317 Loss: 0.5638122139965487\n",
      "15000. Accuracy: 0.7560975609756098 Loss: 0.45798633861644844\n",
      "15000. Accuracy: 0.6585365853658537 Loss: 0.6423119823586565\n",
      "15000. Accuracy: 0.7804878048780488 Loss: 0.5000514264997216\n",
      "15000. Accuracy: 0.7073170731707317 Loss: 0.5428618147937783\n",
      "15000. Accuracy: 0.7073170731707317 Loss: 0.603471642632839\n",
      "15000. Accuracy: 0.7073170731707317 Loss: 0.5630891780468426\n",
      "15500. Accuracy: 0.7560975609756098 Loss: 0.45777378969963073\n",
      "15500. Accuracy: 0.6585365853658537 Loss: 0.6414186470463523\n",
      "15500. Accuracy: 0.8048780487804879 Loss: 0.49937590059406495\n",
      "15500. Accuracy: 0.7073170731707317 Loss: 0.5418789029766351\n",
      "15500. Accuracy: 0.7073170731707317 Loss: 0.602952613883865\n",
      "15500. Accuracy: 0.7073170731707317 Loss: 0.5623690027324898\n",
      "16000. Accuracy: 0.7560975609756098 Loss: 0.45755748327905177\n",
      "16000. Accuracy: 0.6585365853658537 Loss: 0.6406460651943828\n",
      "16000. Accuracy: 0.8048780487804879 Loss: 0.49873839828513045\n",
      "16000. Accuracy: 0.7073170731707317 Loss: 0.540931046187377\n",
      "16000. Accuracy: 0.7073170731707317 Loss: 0.6024574923547971\n",
      "16000. Accuracy: 0.7073170731707317 Loss: 0.5618440405065407\n",
      "16500. Accuracy: 0.7560975609756098 Loss: 0.45733937755841936\n",
      "16500. Accuracy: 0.6585365853658537 Loss: 0.6399523188466435\n",
      "16500. Accuracy: 0.8048780487804879 Loss: 0.4980853346931268\n",
      "16500. Accuracy: 0.7073170731707317 Loss: 0.5400373453444839\n",
      "16500. Accuracy: 0.7073170731707317 Loss: 0.6020022225672164\n",
      "16500. Accuracy: 0.7073170731707317 Loss: 0.5613842453219977\n",
      "17000. Accuracy: 0.7560975609756098 Loss: 0.4570310738096951\n",
      "17000. Accuracy: 0.6585365853658537 Loss: 0.6393260804085916\n",
      "17000. Accuracy: 0.8048780487804879 Loss: 0.4974207686798659\n",
      "17000. Accuracy: 0.7073170731707317 Loss: 0.5391576114992259\n",
      "17000. Accuracy: 0.7073170731707317 Loss: 0.6015846607308363\n",
      "17000. Accuracy: 0.7073170731707317 Loss: 0.5609679043392728\n",
      "17500. Accuracy: 0.7560975609756098 Loss: 0.45664404181643753\n",
      "17500. Accuracy: 0.6585365853658537 Loss: 0.6386975978305998\n",
      "17500. Accuracy: 0.8048780487804879 Loss: 0.4967919207224465\n",
      "17500. Accuracy: 0.7073170731707317 Loss: 0.5383131997675032\n",
      "17500. Accuracy: 0.7073170731707317 Loss: 0.6011902927243045\n",
      "17500. Accuracy: 0.7073170731707317 Loss: 0.5605740899686642\n",
      "18000. Accuracy: 0.7560975609756098 Loss: 0.45618870345083323\n",
      "18000. Accuracy: 0.6585365853658537 Loss: 0.6381197796588763\n",
      "18000. Accuracy: 0.8048780487804879 Loss: 0.49598654093686284\n",
      "18000. Accuracy: 0.7073170731707317 Loss: 0.5374729621953059\n",
      "18000. Accuracy: 0.7073170731707317 Loss: 0.6008545442298885\n",
      "18000. Accuracy: 0.7073170731707317 Loss: 0.5602817158896259\n",
      "18500. Accuracy: 0.7560975609756098 Loss: 0.4558326793055284\n",
      "18500. Accuracy: 0.6585365853658537 Loss: 0.6375381827455701\n",
      "18500. Accuracy: 0.8048780487804879 Loss: 0.495435771986262\n",
      "18500. Accuracy: 0.7073170731707317 Loss: 0.5365894854973617\n",
      "18500. Accuracy: 0.7073170731707317 Loss: 0.6003948061658261\n",
      "18500. Accuracy: 0.7073170731707317 Loss: 0.559936877333928\n",
      "19000. Accuracy: 0.7560975609756098 Loss: 0.45554929828811996\n",
      "19000. Accuracy: 0.6585365853658537 Loss: 0.6369443773792068\n",
      "19000. Accuracy: 0.8048780487804879 Loss: 0.4948278247715035\n",
      "19000. Accuracy: 0.7073170731707317 Loss: 0.5357973321296846\n",
      "19000. Accuracy: 0.7073170731707317 Loss: 0.5999242794542107\n",
      "19000. Accuracy: 0.7073170731707317 Loss: 0.5595509740410217\n",
      "19500. Accuracy: 0.7560975609756098 Loss: 0.45535093465019005\n",
      "19500. Accuracy: 0.6585365853658537 Loss: 0.636319152564845\n",
      "19500. Accuracy: 0.8048780487804879 Loss: 0.4942549358861844\n",
      "19500. Accuracy: 0.7073170731707317 Loss: 0.5350373121551599\n",
      "19500. Accuracy: 0.7073170731707317 Loss: 0.5994263108325772\n",
      "19500. Accuracy: 0.7073170731707317 Loss: 0.5591629872890403\n",
      "20000. Accuracy: 0.7560975609756098 Loss: 0.4551766857856576\n",
      "20000. Accuracy: 0.6585365853658537 Loss: 0.6357435157050071\n",
      "20000. Accuracy: 0.8048780487804879 Loss: 0.49370444538722186\n",
      "20000. Accuracy: 0.7073170731707317 Loss: 0.5342418572891282\n",
      "20000. Accuracy: 0.7073170731707317 Loss: 0.5988767368364216\n",
      "20000. Accuracy: 0.7073170731707317 Loss: 0.5587593000833245\n",
      "20500. Accuracy: 0.7560975609756098 Loss: 0.45506056487644214\n",
      "20500. Accuracy: 0.6585365853658537 Loss: 0.6352428009621401\n",
      "20500. Accuracy: 0.8048780487804879 Loss: 0.49333260996877365\n",
      "20500. Accuracy: 0.7073170731707317 Loss: 0.5333075325557821\n",
      "20500. Accuracy: 0.7073170731707317 Loss: 0.5982764999971051\n",
      "20500. Accuracy: 0.7073170731707317 Loss: 0.5581803449101614\n",
      "21000. Accuracy: 0.7560975609756098 Loss: 0.4548161523813387\n",
      "21000. Accuracy: 0.6585365853658537 Loss: 0.634762336172995\n",
      "21000. Accuracy: 0.8048780487804879 Loss: 0.49286553999832994\n",
      "21000. Accuracy: 0.7073170731707317 Loss: 0.5324671127417764\n",
      "21000. Accuracy: 0.7073170731707317 Loss: 0.5977999305646546\n",
      "21000. Accuracy: 0.7073170731707317 Loss: 0.5576415780175259\n",
      "21500. Accuracy: 0.7560975609756098 Loss: 0.45452512291728\n",
      "21500. Accuracy: 0.6585365853658537 Loss: 0.6342749996869789\n",
      "21500. Accuracy: 0.8048780487804879 Loss: 0.4923767968076422\n",
      "21500. Accuracy: 0.7073170731707317 Loss: 0.5316531694025036\n",
      "21500. Accuracy: 0.7073170731707317 Loss: 0.597319042820694\n",
      "21500. Accuracy: 0.7073170731707317 Loss: 0.5571706960042506\n",
      "22000. Accuracy: 0.7560975609756098 Loss: 0.4541126142588705\n",
      "22000. Accuracy: 0.6585365853658537 Loss: 0.633848937002533\n",
      "22000. Accuracy: 0.8048780487804879 Loss: 0.4917362487216281\n",
      "22000. Accuracy: 0.7073170731707317 Loss: 0.5309242076457558\n",
      "22000. Accuracy: 0.7073170731707317 Loss: 0.5968769204551695\n",
      "22000. Accuracy: 0.7073170731707317 Loss: 0.5568306241909757\n",
      "22500. Accuracy: 0.7560975609756098 Loss: 0.453893615505356\n",
      "22500. Accuracy: 0.6585365853658537 Loss: 0.6333383917842502\n",
      "22500. Accuracy: 0.8048780487804879 Loss: 0.49125305282014586\n",
      "22500. Accuracy: 0.7073170731707317 Loss: 0.5300582758908234\n",
      "22500. Accuracy: 0.7073170731707317 Loss: 0.5963276903853831\n",
      "22500. Accuracy: 0.7073170731707317 Loss: 0.556419119860159\n",
      "23000. Accuracy: 0.7560975609756098 Loss: 0.4535531072384477\n",
      "23000. Accuracy: 0.6585365853658537 Loss: 0.6328420053262825\n",
      "23000. Accuracy: 0.8048780487804879 Loss: 0.4905908424409765\n",
      "23000. Accuracy: 0.7073170731707317 Loss: 0.5292870353948\n",
      "23000. Accuracy: 0.7073170731707317 Loss: 0.595829971876452\n",
      "23000. Accuracy: 0.7317073170731707 Loss: 0.5560478864748237\n",
      "23500. Accuracy: 0.7560975609756098 Loss: 0.45324693820894\n",
      "23500. Accuracy: 0.6585365853658537 Loss: 0.6323663754963323\n",
      "23500. Accuracy: 0.8048780487804879 Loss: 0.4898631494133227\n",
      "23500. Accuracy: 0.7073170731707317 Loss: 0.5285896403142043\n",
      "23500. Accuracy: 0.7073170731707317 Loss: 0.5953643080051245\n",
      "23500. Accuracy: 0.7317073170731707 Loss: 0.5556178171532462\n",
      "24000. Accuracy: 0.7560975609756098 Loss: 0.453080818574893\n",
      "24000. Accuracy: 0.6585365853658537 Loss: 0.6319268061396262\n",
      "24000. Accuracy: 0.8048780487804879 Loss: 0.4891977806104865\n",
      "24000. Accuracy: 0.7073170731707317 Loss: 0.527895130975129\n",
      "24000. Accuracy: 0.7073170731707317 Loss: 0.5948753229755317\n",
      "24000. Accuracy: 0.7317073170731707 Loss: 0.5552067207963286\n",
      "24500. Accuracy: 0.7560975609756098 Loss: 0.4529593675534292\n",
      "24500. Accuracy: 0.6585365853658537 Loss: 0.6314852032864748\n",
      "24500. Accuracy: 0.8048780487804879 Loss: 0.4884894591723701\n",
      "24500. Accuracy: 0.7073170731707317 Loss: 0.5271936281192805\n",
      "24500. Accuracy: 0.7073170731707317 Loss: 0.5943497163056415\n",
      "24500. Accuracy: 0.7317073170731707 Loss: 0.5548413938735677\n",
      "25000. Accuracy: 0.7560975609756098 Loss: 0.4527588314550071\n",
      "25000. Accuracy: 0.6585365853658537 Loss: 0.6311058372121697\n",
      "25000. Accuracy: 0.8048780487804879 Loss: 0.4878271879275984\n",
      "25000. Accuracy: 0.7073170731707317 Loss: 0.5264905495689324\n",
      "25000. Accuracy: 0.7073170731707317 Loss: 0.5938576723357297\n",
      "25000. Accuracy: 0.7560975609756098 Loss: 0.5545088395393668\n",
      "25500. Accuracy: 0.7560975609756098 Loss: 0.4525040649223193\n",
      "25500. Accuracy: 0.6585365853658537 Loss: 0.6307770891626918\n",
      "25500. Accuracy: 0.8048780487804879 Loss: 0.487160379689477\n",
      "25500. Accuracy: 0.7073170731707317 Loss: 0.5258157757926241\n",
      "25500. Accuracy: 0.7073170731707317 Loss: 0.5934277495329341\n",
      "25500. Accuracy: 0.7560975609756098 Loss: 0.5541821712047068\n",
      "26000. Accuracy: 0.7560975609756098 Loss: 0.45223143989\n",
      "26000. Accuracy: 0.6585365853658537 Loss: 0.6304549715037943\n",
      "26000. Accuracy: 0.8048780487804879 Loss: 0.48650613349418126\n",
      "26000. Accuracy: 0.7073170731707317 Loss: 0.5251651248319948\n",
      "26000. Accuracy: 0.7073170731707317 Loss: 0.5929936294359327\n",
      "26000. Accuracy: 0.7560975609756098 Loss: 0.5538771380925093\n",
      "26500. Accuracy: 0.7560975609756098 Loss: 0.4519696678921351\n",
      "26500. Accuracy: 0.6585365853658537 Loss: 0.6301655512705783\n",
      "26500. Accuracy: 0.8048780487804879 Loss: 0.4858549388729893\n",
      "26500. Accuracy: 0.7073170731707317 Loss: 0.5245015301379002\n",
      "26500. Accuracy: 0.7073170731707317 Loss: 0.5925469477672358\n",
      "26500. Accuracy: 0.7560975609756098 Loss: 0.5535665681674309\n",
      "27000. Accuracy: 0.7560975609756098 Loss: 0.4517109386329853\n",
      "27000. Accuracy: 0.6585365853658537 Loss: 0.6298892978189399\n",
      "27000. Accuracy: 0.8048780487804879 Loss: 0.4851983700099083\n",
      "27000. Accuracy: 0.7073170731707317 Loss: 0.5238633638511703\n",
      "27000. Accuracy: 0.7073170731707317 Loss: 0.5921086715663182\n",
      "27000. Accuracy: 0.7560975609756098 Loss: 0.553256648891763\n",
      "27500. Accuracy: 0.7560975609756098 Loss: 0.4515300150131062\n",
      "27500. Accuracy: 0.6585365853658537 Loss: 0.6294550534822531\n",
      "27500. Accuracy: 0.8048780487804879 Loss: 0.48460470259118654\n",
      "27500. Accuracy: 0.7073170731707317 Loss: 0.5232411184471502\n",
      "27500. Accuracy: 0.7073170731707317 Loss: 0.5916071339596898\n",
      "27500. Accuracy: 0.7560975609756098 Loss: 0.5529832559451859\n",
      "28000. Accuracy: 0.7804878048780488 Loss: 0.45134213780717414\n",
      "28000. Accuracy: 0.6585365853658537 Loss: 0.6290365113620183\n",
      "28000. Accuracy: 0.8048780487804879 Loss: 0.48396288731115544\n",
      "28000. Accuracy: 0.7073170731707317 Loss: 0.522661905688652\n",
      "28000. Accuracy: 0.7073170731707317 Loss: 0.5911377589400622\n",
      "28000. Accuracy: 0.7560975609756098 Loss: 0.5526973138789741\n",
      "28500. Accuracy: 0.7804878048780488 Loss: 0.4511956300231207\n",
      "28500. Accuracy: 0.6585365853658537 Loss: 0.6285868891017079\n",
      "28500. Accuracy: 0.8048780487804879 Loss: 0.4833115281481304\n",
      "28500. Accuracy: 0.7073170731707317 Loss: 0.5220973349304348\n",
      "28500. Accuracy: 0.7073170731707317 Loss: 0.5906136069878175\n",
      "28500. Accuracy: 0.7560975609756098 Loss: 0.5523802320312199\n",
      "29000. Accuracy: 0.7804878048780488 Loss: 0.4510615906607472\n",
      "29000. Accuracy: 0.6585365853658537 Loss: 0.6280910556546596\n",
      "29000. Accuracy: 0.8048780487804879 Loss: 0.48263272064204177\n",
      "29000. Accuracy: 0.7073170731707317 Loss: 0.5215560369453357\n",
      "29000. Accuracy: 0.7073170731707317 Loss: 0.5900960772376257\n",
      "29000. Accuracy: 0.7560975609756098 Loss: 0.5520817221319988\n",
      "29500. Accuracy: 0.7804878048780488 Loss: 0.4509342104385324\n",
      "29500. Accuracy: 0.6585365853658537 Loss: 0.6276202289353991\n",
      "29500. Accuracy: 0.8048780487804879 Loss: 0.4818999462194976\n",
      "29500. Accuracy: 0.7073170731707317 Loss: 0.5210206436059343\n",
      "29500. Accuracy: 0.7073170731707317 Loss: 0.5895680701684396\n",
      "29500. Accuracy: 0.7560975609756098 Loss: 0.5517760186725712\n",
      "30000. Accuracy: 0.7804878048780488 Loss: 0.45073991622564197\n",
      "30000. Accuracy: 0.6585365853658537 Loss: 0.6272175573239326\n",
      "30000. Accuracy: 0.8292682926829268 Loss: 0.4811772019671873\n",
      "30000. Accuracy: 0.7073170731707317 Loss: 0.5205034678940075\n",
      "30000. Accuracy: 0.7073170731707317 Loss: 0.5890987153163619\n",
      "30000. Accuracy: 0.7560975609756098 Loss: 0.5514924873311641\n",
      "30500. Accuracy: 0.7804878048780488 Loss: 0.45049475213933105\n",
      "30500. Accuracy: 0.6585365853658537 Loss: 0.6268235532951806\n",
      "30500. Accuracy: 0.8292682926829268 Loss: 0.48053594888621914\n",
      "30500. Accuracy: 0.7073170731707317 Loss: 0.5199900712355762\n",
      "30500. Accuracy: 0.7073170731707317 Loss: 0.588652654131358\n",
      "30500. Accuracy: 0.7560975609756098 Loss: 0.5512528475080982\n",
      "31000. Accuracy: 0.7804878048780488 Loss: 0.45024509892771497\n",
      "31000. Accuracy: 0.6585365853658537 Loss: 0.6264603629085376\n",
      "31000. Accuracy: 0.8292682926829268 Loss: 0.4798764476856413\n",
      "31000. Accuracy: 0.7073170731707317 Loss: 0.5194829546733256\n",
      "31000. Accuracy: 0.7073170731707317 Loss: 0.5882415694699517\n",
      "31000. Accuracy: 0.7560975609756098 Loss: 0.5510377742544262\n",
      "31500. Accuracy: 0.7804878048780488 Loss: 0.4500998083848294\n",
      "31500. Accuracy: 0.6585365853658537 Loss: 0.6260530933120695\n",
      "31500. Accuracy: 0.8292682926829268 Loss: 0.47924210524572897\n",
      "31500. Accuracy: 0.7073170731707317 Loss: 0.5189828612541043\n",
      "31500. Accuracy: 0.7073170731707317 Loss: 0.5877328140751483\n",
      "31500. Accuracy: 0.7560975609756098 Loss: 0.5508269161536686\n",
      "32000. Accuracy: 0.7804878048780488 Loss: 0.4498431576955394\n",
      "32000. Accuracy: 0.6585365853658537 Loss: 0.6257603179978851\n",
      "32000. Accuracy: 0.8292682926829268 Loss: 0.47862853423207113\n",
      "32000. Accuracy: 0.7073170731707317 Loss: 0.5184887797010018\n",
      "32000. Accuracy: 0.7073170731707317 Loss: 0.5872319842307048\n",
      "32000. Accuracy: 0.7560975609756098 Loss: 0.5506319544467333\n",
      "32500. Accuracy: 0.7804878048780488 Loss: 0.4495902790290855\n",
      "32500. Accuracy: 0.6585365853658537 Loss: 0.6254784182505725\n",
      "32500. Accuracy: 0.8292682926829268 Loss: 0.4780361834977249\n",
      "32500. Accuracy: 0.7073170731707317 Loss: 0.5179811430923494\n",
      "32500. Accuracy: 0.7073170731707317 Loss: 0.5867575655397745\n",
      "32500. Accuracy: 0.7560975609756098 Loss: 0.5504218428388018\n",
      "33000. Accuracy: 0.7804878048780488 Loss: 0.4493580339205983\n",
      "33000. Accuracy: 0.6585365853658537 Loss: 0.6251942887249479\n",
      "33000. Accuracy: 0.8292682926829268 Loss: 0.47746575768316074\n",
      "33000. Accuracy: 0.7073170731707317 Loss: 0.5174781519360038\n",
      "33000. Accuracy: 0.7073170731707317 Loss: 0.5862853172973465\n",
      "33000. Accuracy: 0.7560975609756098 Loss: 0.5501937718702209\n",
      "33500. Accuracy: 0.7804878048780488 Loss: 0.4490920760590843\n",
      "33500. Accuracy: 0.6829268292682927 Loss: 0.6248889864843712\n",
      "33500. Accuracy: 0.8292682926829268 Loss: 0.4768928319490845\n",
      "33500. Accuracy: 0.7073170731707317 Loss: 0.5169791562829994\n",
      "33500. Accuracy: 0.7073170731707317 Loss: 0.5858351312997\n",
      "33500. Accuracy: 0.7560975609756098 Loss: 0.549961148063443\n",
      "34000. Accuracy: 0.7804878048780488 Loss: 0.44887649389677414\n",
      "34000. Accuracy: 0.6829268292682927 Loss: 0.6246404452628872\n",
      "34000. Accuracy: 0.8292682926829268 Loss: 0.4763202681269558\n",
      "34000. Accuracy: 0.7073170731707317 Loss: 0.516466652436968\n",
      "34000. Accuracy: 0.7073170731707317 Loss: 0.5853387499212636\n",
      "34000. Accuracy: 0.7560975609756098 Loss: 0.5497181408917147\n",
      "34500. Accuracy: 0.7804878048780488 Loss: 0.4485316711450765\n",
      "34500. Accuracy: 0.6829268292682927 Loss: 0.6242353826297704\n",
      "34500. Accuracy: 0.8292682926829268 Loss: 0.4757228543041221\n",
      "34500. Accuracy: 0.7073170731707317 Loss: 0.5157838884761793\n",
      "34500. Accuracy: 0.7073170731707317 Loss: 0.5850446635953693\n",
      "34500. Accuracy: 0.7560975609756098 Loss: 0.5496112379231055\n",
      "35000. Accuracy: 0.7804878048780488 Loss: 0.4476166370973439\n",
      "35000. Accuracy: 0.6829268292682927 Loss: 0.6237754607124579\n",
      "35000. Accuracy: 0.8292682926829268 Loss: 0.47504589707274586\n",
      "35000. Accuracy: 0.7073170731707317 Loss: 0.5153557550247914\n",
      "35000. Accuracy: 0.7073170731707317 Loss: 0.584994663451949\n",
      "35000. Accuracy: 0.7560975609756098 Loss: 0.5495923348859103\n",
      "35500. Accuracy: 0.7804878048780488 Loss: 0.4461432826840467\n",
      "35500. Accuracy: 0.6829268292682927 Loss: 0.6233275779217177\n",
      "35500. Accuracy: 0.8292682926829268 Loss: 0.47424791978176417\n",
      "35500. Accuracy: 0.7073170731707317 Loss: 0.5152309136852028\n",
      "35500. Accuracy: 0.7073170731707317 Loss: 0.5851726701516737\n",
      "35500. Accuracy: 0.7560975609756098 Loss: 0.549410225359018\n",
      "36000. Accuracy: 0.7804878048780488 Loss: 0.4458099300856824\n",
      "36000. Accuracy: 0.6829268292682927 Loss: 0.6229938195170077\n",
      "36000. Accuracy: 0.8292682926829268 Loss: 0.4737536193981503\n",
      "36000. Accuracy: 0.7073170731707317 Loss: 0.5148198848989171\n",
      "36000. Accuracy: 0.7073170731707317 Loss: 0.5847470423807584\n",
      "36000. Accuracy: 0.7560975609756098 Loss: 0.5490273636936723\n",
      "36500. Accuracy: 0.7804878048780488 Loss: 0.44554109102894857\n",
      "36500. Accuracy: 0.6829268292682927 Loss: 0.6226174130191712\n",
      "36500. Accuracy: 0.8292682926829268 Loss: 0.47329588415130935\n",
      "36500. Accuracy: 0.7073170731707317 Loss: 0.5143259949792893\n",
      "36500. Accuracy: 0.7073170731707317 Loss: 0.5842671083755503\n",
      "36500. Accuracy: 0.7560975609756098 Loss: 0.5487483551386559\n",
      "37000. Accuracy: 0.7804878048780488 Loss: 0.4451899645242109\n",
      "37000. Accuracy: 0.6829268292682927 Loss: 0.6222948632023156\n",
      "37000. Accuracy: 0.8292682926829268 Loss: 0.4728258683013719\n",
      "37000. Accuracy: 0.7073170731707317 Loss: 0.5137979770235697\n",
      "37000. Accuracy: 0.7073170731707317 Loss: 0.5838914809194732\n",
      "37000. Accuracy: 0.7560975609756098 Loss: 0.548427841110846\n",
      "37500. Accuracy: 0.7804878048780488 Loss: 0.44498368102362373\n",
      "37500. Accuracy: 0.6829268292682927 Loss: 0.6219988055898154\n",
      "37500. Accuracy: 0.8292682926829268 Loss: 0.4722634058303323\n",
      "37500. Accuracy: 0.7073170731707317 Loss: 0.5133422380715007\n",
      "37500. Accuracy: 0.7073170731707317 Loss: 0.5834339954055507\n",
      "37500. Accuracy: 0.7560975609756098 Loss: 0.5480970195797266\n",
      "38000. Accuracy: 0.7804878048780488 Loss: 0.44503737156362655\n",
      "38000. Accuracy: 0.6829268292682927 Loss: 0.6217023725042035\n",
      "38000. Accuracy: 0.8292682926829268 Loss: 0.47175447249679997\n",
      "38000. Accuracy: 0.7073170731707317 Loss: 0.512838693160611\n",
      "38000. Accuracy: 0.7073170731707317 Loss: 0.5827150010433798\n",
      "38000. Accuracy: 0.7560975609756098 Loss: 0.5477923788061809\n",
      "38500. Accuracy: 0.7804878048780488 Loss: 0.44491016112973464\n",
      "38500. Accuracy: 0.6829268292682927 Loss: 0.6214897662705187\n",
      "38500. Accuracy: 0.8292682926829268 Loss: 0.4711192374897519\n",
      "38500. Accuracy: 0.7073170731707317 Loss: 0.5123450156844309\n",
      "38500. Accuracy: 0.7073170731707317 Loss: 0.5820641441423521\n",
      "38500. Accuracy: 0.7560975609756098 Loss: 0.5475797048369931\n",
      "39000. Accuracy: 0.7804878048780488 Loss: 0.44494819317391365\n",
      "39000. Accuracy: 0.6829268292682927 Loss: 0.6211537574043199\n",
      "39000. Accuracy: 0.8292682926829268 Loss: 0.4706576306713003\n",
      "39000. Accuracy: 0.7073170731707317 Loss: 0.5118304920253333\n",
      "39000. Accuracy: 0.7073170731707317 Loss: 0.5813500661613371\n",
      "39000. Accuracy: 0.7560975609756098 Loss: 0.5472567871855699\n",
      "39500. Accuracy: 0.7804878048780488 Loss: 0.4449049215099436\n",
      "39500. Accuracy: 0.6829268292682927 Loss: 0.6209282299518875\n",
      "39500. Accuracy: 0.8292682926829268 Loss: 0.47010535489647587\n",
      "39500. Accuracy: 0.7073170731707317 Loss: 0.5113286975512434\n",
      "39500. Accuracy: 0.7073170731707317 Loss: 0.5806923349060754\n",
      "39500. Accuracy: 0.7560975609756098 Loss: 0.5469803382278597\n",
      "40000. Accuracy: 0.7804878048780488 Loss: 0.4448986171803508\n",
      "40000. Accuracy: 0.6829268292682927 Loss: 0.6206834444398128\n",
      "40000. Accuracy: 0.8292682926829268 Loss: 0.46961207656057374\n",
      "40000. Accuracy: 0.7073170731707317 Loss: 0.5108263312576033\n",
      "40000. Accuracy: 0.7073170731707317 Loss: 0.5800412052931142\n",
      "40000. Accuracy: 0.7560975609756098 Loss: 0.5467083568408679\n",
      "40500. Accuracy: 0.7804878048780488 Loss: 0.4448921844588317\n",
      "40500. Accuracy: 0.6829268292682927 Loss: 0.6204414209997721\n",
      "40500. Accuracy: 0.8292682926829268 Loss: 0.4691336137229192\n",
      "40500. Accuracy: 0.7073170731707317 Loss: 0.510325977758369\n",
      "40500. Accuracy: 0.7073170731707317 Loss: 0.5794224247205095\n",
      "40500. Accuracy: 0.7560975609756098 Loss: 0.5464360229255799\n",
      "41000. Accuracy: 0.7804878048780488 Loss: 0.44490492719287966\n",
      "41000. Accuracy: 0.6829268292682927 Loss: 0.6201904730310536\n",
      "41000. Accuracy: 0.8292682926829268 Loss: 0.468664057294183\n",
      "41000. Accuracy: 0.7073170731707317 Loss: 0.5098304546195703\n",
      "41000. Accuracy: 0.7073170731707317 Loss: 0.5788223335279574\n",
      "41000. Accuracy: 0.7560975609756098 Loss: 0.546163755150947\n",
      "41500. Accuracy: 0.7804878048780488 Loss: 0.4448830217404196\n",
      "41500. Accuracy: 0.6829268292682927 Loss: 0.619922716132418\n",
      "41500. Accuracy: 0.8292682926829268 Loss: 0.46820804499929175\n",
      "41500. Accuracy: 0.7073170731707317 Loss: 0.5093400714282647\n",
      "41500. Accuracy: 0.7073170731707317 Loss: 0.5782267724535382\n",
      "41500. Accuracy: 0.7560975609756098 Loss: 0.545905101620028\n",
      "42000. Accuracy: 0.7804878048780488 Loss: 0.4448319470088471\n",
      "42000. Accuracy: 0.6829268292682927 Loss: 0.6196828068065696\n",
      "42000. Accuracy: 0.8292682926829268 Loss: 0.46771273056019547\n",
      "42000. Accuracy: 0.7073170731707317 Loss: 0.5088572562793926\n",
      "42000. Accuracy: 0.7073170731707317 Loss: 0.5776719785093957\n",
      "42000. Accuracy: 0.7560975609756098 Loss: 0.545677054416433\n",
      "42500. Accuracy: 0.7804878048780488 Loss: 0.44477016367335065\n",
      "42500. Accuracy: 0.6829268292682927 Loss: 0.6194348212458235\n",
      "42500. Accuracy: 0.8292682926829268 Loss: 0.4672192710880803\n",
      "42500. Accuracy: 0.7073170731707317 Loss: 0.5083789269520119\n",
      "42500. Accuracy: 0.7073170731707317 Loss: 0.5771299206221792\n",
      "42500. Accuracy: 0.7560975609756098 Loss: 0.5454444842676799\n",
      "43000. Accuracy: 0.7804878048780488 Loss: 0.44469677059421825\n",
      "43000. Accuracy: 0.6829268292682927 Loss: 0.6191945298735524\n",
      "43000. Accuracy: 0.8292682926829268 Loss: 0.46671902723550407\n",
      "43000. Accuracy: 0.7073170731707317 Loss: 0.5078977807630864\n",
      "43000. Accuracy: 0.7073170731707317 Loss: 0.5766061456552306\n",
      "43000. Accuracy: 0.7560975609756098 Loss: 0.5452336373925534\n",
      "43500. Accuracy: 0.7804878048780488 Loss: 0.44461306480298013\n",
      "43500. Accuracy: 0.6829268292682927 Loss: 0.6189582058327435\n",
      "43500. Accuracy: 0.8292682926829268 Loss: 0.4662303365223743\n",
      "43500. Accuracy: 0.7073170731707317 Loss: 0.5074138018364193\n",
      "43500. Accuracy: 0.7073170731707317 Loss: 0.5760930633347726\n",
      "43500. Accuracy: 0.7560975609756098 Loss: 0.5450441256176941\n",
      "44000. Accuracy: 0.7804878048780488 Loss: 0.4445166321742626\n",
      "44000. Accuracy: 0.6829268292682927 Loss: 0.618731850192808\n",
      "44000. Accuracy: 0.8292682926829268 Loss: 0.4657022801606084\n",
      "44000. Accuracy: 0.7317073170731707 Loss: 0.5069527994841575\n",
      "44000. Accuracy: 0.7073170731707317 Loss: 0.57560873029444\n",
      "44000. Accuracy: 0.7560975609756098 Loss: 0.5448492521984755\n",
      "44500. Accuracy: 0.7804878048780488 Loss: 0.4443227639664287\n",
      "44500. Accuracy: 0.6829268292682927 Loss: 0.6185082637598638\n",
      "44500. Accuracy: 0.8292682926829268 Loss: 0.4651307510125394\n",
      "44500. Accuracy: 0.7317073170731707 Loss: 0.5064926165235945\n",
      "44500. Accuracy: 0.7073170731707317 Loss: 0.5752390088342066\n",
      "44500. Accuracy: 0.7560975609756098 Loss: 0.5447009403494447\n",
      "45000. Accuracy: 0.7804878048780488 Loss: 0.4442345638536278\n",
      "45000. Accuracy: 0.6829268292682927 Loss: 0.6182595016780884\n",
      "45000. Accuracy: 0.8292682926829268 Loss: 0.4646481043028332\n",
      "45000. Accuracy: 0.7317073170731707 Loss: 0.5060302468093286\n",
      "45000. Accuracy: 0.7073170731707317 Loss: 0.5747820879098922\n",
      "45000. Accuracy: 0.7560975609756098 Loss: 0.5445101144077965\n",
      "45500. Accuracy: 0.7804878048780488 Loss: 0.4441431491778163\n",
      "45500. Accuracy: 0.6829268292682927 Loss: 0.6180234364364555\n",
      "45500. Accuracy: 0.8292682926829268 Loss: 0.46415274737783047\n",
      "45500. Accuracy: 0.7317073170731707 Loss: 0.5055760837064108\n",
      "45500. Accuracy: 0.7073170731707317 Loss: 0.5743342979864227\n",
      "45500. Accuracy: 0.7560975609756098 Loss: 0.5443140506961021\n",
      "46000. Accuracy: 0.7804878048780488 Loss: 0.4440470500740028\n",
      "46000. Accuracy: 0.6829268292682927 Loss: 0.6177812072835321\n",
      "46000. Accuracy: 0.8292682926829268 Loss: 0.463670042567303\n",
      "46000. Accuracy: 0.7317073170731707 Loss: 0.505116714704807\n",
      "46000. Accuracy: 0.7073170731707317 Loss: 0.5738747464992174\n",
      "46000. Accuracy: 0.7560975609756098 Loss: 0.5440983539636515\n",
      "46500. Accuracy: 0.7804878048780488 Loss: 0.44392707643977863\n",
      "46500. Accuracy: 0.6829268292682927 Loss: 0.6175632496434998\n",
      "46500. Accuracy: 0.8292682926829268 Loss: 0.4631666174570043\n",
      "46500. Accuracy: 0.7317073170731707 Loss: 0.5046481274642266\n",
      "46500. Accuracy: 0.7073170731707317 Loss: 0.5734203286978938\n",
      "46500. Accuracy: 0.7560975609756098 Loss: 0.5438778963634917\n",
      "47000. Accuracy: 0.7804878048780488 Loss: 0.4437427813369709\n",
      "47000. Accuracy: 0.6829268292682927 Loss: 0.6174364983784029\n",
      "47000. Accuracy: 0.8292682926829268 Loss: 0.46261623113050565\n",
      "47000. Accuracy: 0.7317073170731707 Loss: 0.5042225549673957\n",
      "47000. Accuracy: 0.7073170731707317 Loss: 0.5729757745558155\n",
      "47000. Accuracy: 0.7560975609756098 Loss: 0.5436373802376276\n",
      "47500. Accuracy: 0.7804878048780488 Loss: 0.4436148007509117\n",
      "47500. Accuracy: 0.6829268292682927 Loss: 0.6172731287422109\n",
      "47500. Accuracy: 0.8292682926829268 Loss: 0.4620845223026296\n",
      "47500. Accuracy: 0.7317073170731707 Loss: 0.5037497629562205\n",
      "47500. Accuracy: 0.7073170731707317 Loss: 0.5725435714643626\n",
      "47500. Accuracy: 0.7560975609756098 Loss: 0.5434186735821387\n",
      "48000. Accuracy: 0.7804878048780488 Loss: 0.4434711089201152\n",
      "48000. Accuracy: 0.6829268292682927 Loss: 0.6170999155047988\n",
      "48000. Accuracy: 0.8292682926829268 Loss: 0.4615920973321422\n",
      "48000. Accuracy: 0.7317073170731707 Loss: 0.5032760170747606\n",
      "48000. Accuracy: 0.7073170731707317 Loss: 0.5721110822288638\n",
      "48000. Accuracy: 0.7560975609756098 Loss: 0.543197723987345\n",
      "48500. Accuracy: 0.7804878048780488 Loss: 0.4433195137328851\n",
      "48500. Accuracy: 0.6829268292682927 Loss: 0.6169558021530315\n",
      "48500. Accuracy: 0.8292682926829268 Loss: 0.46109633542516726\n",
      "48500. Accuracy: 0.7317073170731707 Loss: 0.502805730154522\n",
      "48500. Accuracy: 0.7073170731707317 Loss: 0.5716857225136862\n",
      "48500. Accuracy: 0.7560975609756098 Loss: 0.5429793803072753\n",
      "49000. Accuracy: 0.7804878048780488 Loss: 0.44315954335645863\n",
      "49000. Accuracy: 0.6829268292682927 Loss: 0.6168031435149709\n",
      "49000. Accuracy: 0.8292682926829268 Loss: 0.4606129884158046\n",
      "49000. Accuracy: 0.7317073170731707 Loss: 0.5023489149633334\n",
      "49000. Accuracy: 0.7073170731707317 Loss: 0.5712648980822927\n",
      "49000. Accuracy: 0.7560975609756098 Loss: 0.5427559254743175\n",
      "49500. Accuracy: 0.7804878048780488 Loss: 0.4430089844895949\n",
      "49500. Accuracy: 0.6829268292682927 Loss: 0.6166508780848431\n",
      "49500. Accuracy: 0.8292682926829268 Loss: 0.46011771069232466\n",
      "49500. Accuracy: 0.7317073170731707 Loss: 0.501906327267657\n",
      "49500. Accuracy: 0.7073170731707317 Loss: 0.5708453120011956\n",
      "49500. Accuracy: 0.7560975609756098 Loss: 0.5425399752503264\n"
     ]
    }
   ],
   "source": [
    "train = Train(network2e, learning_rate, batch_size, epochs, loss_function)\n",
    "cost, accuracies = train.train(inputs_train, outputs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "55550f51-ff8f-4fd8-ad8d-63da09f74ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([a for a in range(len(cost))],cost)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3a701b0c-2e38-416b-94c7-4e0f02c54c51",
   "metadata": {},
   "source": [
    "### f) use TanH on hidden layers (get back to default lerning rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c54881ac-b599-4e3d-ad6c-31ddd0534e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_output = Sigmoid()\n",
    "activation = TanH()\n",
    "\n",
    "learning_rate = 0.00001\n",
    "network2f = NeuralNetwork(input_dim,\n",
    "                        hidden_dim,\n",
    "                        output_dim,\n",
    "                        num_of_hidden_layers,\n",
    "                        activation,\n",
    "                        activation_output,\n",
    "                        initialization,\n",
    "                        output_initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0ff8e22a-db31-4a89-b05b-d65783fbb7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Accuracy: 0.5853658536585366 Loss: 6.284727311338543\n",
      "0. Accuracy: 0.5609756097560976 Loss: 6.62952087882468\n",
      "0. Accuracy: 0.7073170731707317 Loss: 4.4334148937431275\n",
      "0. Accuracy: 0.6829268292682927 Loss: 4.771502488570937\n",
      "0. Accuracy: 0.6097560975609756 Loss: 5.853936987807127\n",
      "0. Accuracy: 0.6829268292682927 Loss: 4.7387752848704165\n",
      "500. Accuracy: 0.4146341463414634 Loss: 9.434982861844691\n",
      "500. Accuracy: 0.43902439024390244 Loss: 9.041858580101163\n",
      "500. Accuracy: 0.2926829268292683 Loss: 11.400604270562333\n",
      "500. Accuracy: 0.3170731707317073 Loss: 11.007479988818805\n",
      "500. Accuracy: 0.3902439024390244 Loss: 9.82810714358822\n",
      "500. Accuracy: 0.3170731707317073 Loss: 11.007479988818806\n",
      "1000. Accuracy: 0.4146341463414634 Loss: 9.434982861844691\n",
      "1000. Accuracy: 0.43902439024390244 Loss: 9.041858580101163\n",
      "1000. Accuracy: 0.2926829268292683 Loss: 11.400604270562333\n",
      "1000. Accuracy: 0.3170731707317073 Loss: 11.007479988818805\n",
      "1000. Accuracy: 0.3902439024390244 Loss: 9.82810714358822\n",
      "1000. Accuracy: 0.3170731707317073 Loss: 11.007479988818806\n",
      "1500. Accuracy: 0.4146341463414634 Loss: 9.434982861844691\n",
      "1500. Accuracy: 0.43902439024390244 Loss: 9.041858580101163\n",
      "1500. Accuracy: 0.2926829268292683 Loss: 11.400604270562333\n",
      "1500. Accuracy: 0.3170731707317073 Loss: 11.007479988818805\n",
      "1500. Accuracy: 0.3902439024390244 Loss: 9.82810714358822\n",
      "1500. Accuracy: 0.3170731707317073 Loss: 11.007479988818806\n",
      "2000. Accuracy: 0.4146341463414634 Loss: 9.434982861844691\n",
      "2000. Accuracy: 0.43902439024390244 Loss: 9.041858580101163\n",
      "2000. Accuracy: 0.2926829268292683 Loss: 11.400604270562333\n",
      "2000. Accuracy: 0.3170731707317073 Loss: 11.007479988818805\n",
      "2000. Accuracy: 0.3902439024390244 Loss: 9.82810714358822\n",
      "2000. Accuracy: 0.3170731707317073 Loss: 11.007479988818806\n",
      "2500. Accuracy: 0.4146341463414634 Loss: 9.434982861844691\n",
      "2500. Accuracy: 0.43902439024390244 Loss: 9.041858580101163\n",
      "2500. Accuracy: 0.2926829268292683 Loss: 11.400604270562333\n",
      "2500. Accuracy: 0.3170731707317073 Loss: 11.007479988818805\n",
      "2500. Accuracy: 0.3902439024390244 Loss: 9.82810714358822\n",
      "2500. Accuracy: 0.3170731707317073 Loss: 11.007479988818806\n",
      "3000. Accuracy: 0.4146341463414634 Loss: 9.434982861844691\n",
      "3000. Accuracy: 0.43902439024390244 Loss: 9.041858580101163\n",
      "3000. Accuracy: 0.2926829268292683 Loss: 11.400604270562333\n",
      "3000. Accuracy: 0.3170731707317073 Loss: 11.007479988818805\n",
      "3000. Accuracy: 0.3902439024390244 Loss: 9.82810714358822\n",
      "3000. Accuracy: 0.3170731707317073 Loss: 11.007479988818806\n",
      "3500. Accuracy: 0.4146341463414634 Loss: 9.434982861844691\n",
      "3500. Accuracy: 0.43902439024390244 Loss: 9.041858580101163\n",
      "3500. Accuracy: 0.2926829268292683 Loss: 11.400604270562333\n",
      "3500. Accuracy: 0.3170731707317073 Loss: 11.007479988818805\n",
      "3500. Accuracy: 0.3902439024390244 Loss: 9.82810714358822\n",
      "3500. Accuracy: 0.3170731707317073 Loss: 11.007479988818806\n",
      "4000. Accuracy: 0.4146341463414634 Loss: 9.434982861844691\n",
      "4000. Accuracy: 0.43902439024390244 Loss: 9.041858580101163\n",
      "4000. Accuracy: 0.2926829268292683 Loss: 11.400604270562333\n",
      "4000. Accuracy: 0.3170731707317073 Loss: 11.007479988818805\n",
      "4000. Accuracy: 0.3902439024390244 Loss: 9.82810714358822\n",
      "4000. Accuracy: 0.3170731707317073 Loss: 11.007479988818806\n",
      "4500. Accuracy: 0.4146341463414634 Loss: 9.434982861844691\n",
      "4500. Accuracy: 0.43902439024390244 Loss: 9.041858580101163\n",
      "4500. Accuracy: 0.2926829268292683 Loss: 11.400604270562333\n",
      "4500. Accuracy: 0.3170731707317073 Loss: 11.007479988818805\n",
      "4500. Accuracy: 0.3902439024390244 Loss: 9.82810714358822\n",
      "4500. Accuracy: 0.3170731707317073 Loss: 11.007479988818806\n",
      "5000. Accuracy: 0.4146341463414634 Loss: 9.434982861844691\n",
      "5000. Accuracy: 0.43902439024390244 Loss: 9.041858580101163\n",
      "5000. Accuracy: 0.2926829268292683 Loss: 11.400604270562333\n",
      "5000. Accuracy: 0.3170731707317073 Loss: 11.007479988818805\n",
      "5000. Accuracy: 0.3902439024390244 Loss: 9.82810714358822\n",
      "5000. Accuracy: 0.3170731707317073 Loss: 11.007479988818806\n",
      "5500. Accuracy: 0.0 Loss: nan\n",
      "5500. Accuracy: 0.0 Loss: nan\n",
      "5500. Accuracy: 0.0 Loss: nan\n",
      "5500. Accuracy: 0.0 Loss: nan\n",
      "5500. Accuracy: 0.0 Loss: nan\n",
      "5500. Accuracy: 0.0 Loss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[134], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m train \u001b[38;5;241m=\u001b[39m Train(network2f, learning_rate, batch_size, epochs, loss_function)\n\u001b[0;32m----> 2\u001b[0m cost, accuracies \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/network/train.py:33\u001b[0m, in \u001b[0;36mTrain.train\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m     30\u001b[0m accuracies\u001b[38;5;241m.\u001b[39mappend(accuracy)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_function\u001b[38;5;241m.\u001b[39mbackward(predictions, output_batch)\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimise()\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/PycharmProjects/network/model.py:89\u001b[0m, in \u001b[0;36mNeuralNetwork.backward\u001b[0;34m(self, d_loss)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer, activation \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers), \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivations)):\n\u001b[1;32m     88\u001b[0m     activation\u001b[38;5;241m.\u001b[39mbackward(grad)\n\u001b[0;32m---> 89\u001b[0m     \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     grad \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39md_input\n",
      "File \u001b[0;32m~/PycharmProjects/network/model.py:37\u001b[0m, in \u001b[0;36mLayer.backward\u001b[0;34m(self, d_error)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, d_error):\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_weights \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_bias \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(d_error, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_input \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(d_error, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights\u001b[38;5;241m.\u001b[39mT)  \u001b[38;5;66;03m# weights.t but the dim does nt go\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train = Train(network2f, learning_rate, batch_size, epochs, loss_function)\n",
    "cost, accuracies = train.train(inputs_train, outputs_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149e156d-d213-43bc-9f60-8ce4b58306e5",
   "metadata": {},
   "source": [
    "### g)change hidden initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7b14583d-7075-4b30-9a23-83a98e20595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialization = Xavier\n",
    "network2g = NeuralNetwork(input_dim,\n",
    "                        hidden_dim,\n",
    "                        output_dim,\n",
    "                        num_of_hidden_layers,\n",
    "                        activation,\n",
    "                        activation_output,\n",
    "                        initialization,\n",
    "                        output_initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "bfc04119-a02c-47fc-80ec-d3972dac0772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Accuracy: 0.6097560975609756 Loss: 2.194005527556494\n",
      "0. Accuracy: 0.5121951219512195 Loss: 2.285201975982546\n",
      "0. Accuracy: 0.6341463414634146 Loss: 2.1590730464917156\n",
      "0. Accuracy: 0.5365853658536586 Loss: 2.2449992216385275\n",
      "0. Accuracy: 0.5853658536585366 Loss: 1.8953376677402087\n",
      "0. Accuracy: 0.7560975609756098 Loss: 1.402130939697183\n",
      "500. Accuracy: 0.5609756097560976 Loss: 1.3861843244283492\n",
      "500. Accuracy: 0.6097560975609756 Loss: 1.7123379021628444\n",
      "500. Accuracy: 0.5853658536585366 Loss: 1.6524306359757919\n",
      "500. Accuracy: 0.4634146341463415 Loss: 1.716941706857457\n",
      "500. Accuracy: 0.5853658536585366 Loss: 1.51620131201927\n",
      "500. Accuracy: 0.6585365853658537 Loss: 1.148970611890459\n",
      "1000. Accuracy: 0.5609756097560976 Loss: 1.6307792080175214\n",
      "1000. Accuracy: 0.4878048780487805 Loss: 1.9198060593446333\n",
      "1000. Accuracy: 0.5609756097560976 Loss: 1.4888974401787454\n",
      "1000. Accuracy: 0.5609756097560976 Loss: 1.2101713779377972\n",
      "1000. Accuracy: 0.6341463414634146 Loss: 1.49506527474385\n",
      "1000. Accuracy: 0.4634146341463415 Loss: 1.3926295355885967\n",
      "1500. Accuracy: 0.4878048780487805 Loss: 1.3934470148832496\n",
      "1500. Accuracy: 0.5365853658536586 Loss: 1.0371365403830046\n",
      "1500. Accuracy: 0.5121951219512195 Loss: 1.213803539623225\n",
      "1500. Accuracy: 0.5853658536585366 Loss: 0.9032825337969417\n",
      "1500. Accuracy: 0.4634146341463415 Loss: 1.1680379673513577\n",
      "1500. Accuracy: 0.4878048780487805 Loss: 1.0818896401906026\n",
      "2000. Accuracy: 0.4878048780487805 Loss: 1.204350070318962\n",
      "2000. Accuracy: 0.5121951219512195 Loss: 0.8985009248643415\n",
      "2000. Accuracy: 0.6829268292682927 Loss: 0.7993363028310416\n",
      "2000. Accuracy: 0.5853658536585366 Loss: 1.149481674004486\n",
      "2000. Accuracy: 0.5609756097560976 Loss: 0.912994356217831\n",
      "2000. Accuracy: 0.5609756097560976 Loss: 0.8881500036014662\n",
      "2500. Accuracy: 0.4878048780487805 Loss: 1.3221320721468528\n",
      "2500. Accuracy: 0.5121951219512195 Loss: 1.0254844029907204\n",
      "2500. Accuracy: 0.7073170731707317 Loss: 0.8674272796546855\n",
      "2500. Accuracy: 0.6097560975609756 Loss: 0.9819365792504062\n",
      "2500. Accuracy: 0.5609756097560976 Loss: 0.8949104741732228\n",
      "2500. Accuracy: 0.5853658536585366 Loss: 0.9398479544659464\n",
      "3000. Accuracy: 0.4878048780487805 Loss: 0.980183987498131\n",
      "3000. Accuracy: 0.5365853658536586 Loss: 0.8325345087222757\n",
      "3000. Accuracy: 0.6829268292682927 Loss: 0.6757391792749672\n",
      "3000. Accuracy: 0.6341463414634146 Loss: 0.7435551715013847\n",
      "3000. Accuracy: 0.5609756097560976 Loss: 0.7773828143834537\n",
      "3000. Accuracy: 0.6097560975609756 Loss: 0.8043395818981597\n",
      "3500. Accuracy: 0.4878048780487805 Loss: 0.8332757328270246\n",
      "3500. Accuracy: 0.5365853658536586 Loss: 0.7529915075536516\n",
      "3500. Accuracy: 0.6829268292682927 Loss: 0.6416206009038906\n",
      "3500. Accuracy: 0.6341463414634146 Loss: 0.6816923334775761\n",
      "3500. Accuracy: 0.5609756097560976 Loss: 0.7346449554532509\n",
      "3500. Accuracy: 0.6097560975609756 Loss: 0.7107004359891405\n",
      "4000. Accuracy: 0.5609756097560976 Loss: 0.7164724390717367\n",
      "4000. Accuracy: 0.5853658536585366 Loss: 0.6828440564671596\n",
      "4000. Accuracy: 0.7073170731707317 Loss: 0.6125820264507679\n",
      "4000. Accuracy: 0.6585365853658537 Loss: 0.649177284534616\n",
      "4000. Accuracy: 0.5853658536585366 Loss: 0.6957477338818158\n",
      "4000. Accuracy: 0.6341463414634146 Loss: 0.6746434522542248\n",
      "4500. Accuracy: 0.0 Loss: nan\n",
      "4500. Accuracy: 0.0 Loss: nan\n",
      "4500. Accuracy: 0.0 Loss: nan\n",
      "4500. Accuracy: 0.0 Loss: nan\n",
      "4500. Accuracy: 0.0 Loss: nan\n",
      "4500. Accuracy: 0.0 Loss: nan\n",
      "5000. Accuracy: 0.0 Loss: nan\n",
      "5000. Accuracy: 0.0 Loss: nan\n",
      "5000. Accuracy: 0.0 Loss: nan\n",
      "5000. Accuracy: 0.0 Loss: nan\n",
      "5000. Accuracy: 0.0 Loss: nan\n",
      "5000. Accuracy: 0.0 Loss: nan\n",
      "5500. Accuracy: 0.0 Loss: nan\n",
      "5500. Accuracy: 0.0 Loss: nan\n",
      "5500. Accuracy: 0.0 Loss: nan\n",
      "5500. Accuracy: 0.0 Loss: nan\n",
      "5500. Accuracy: 0.0 Loss: nan\n",
      "5500. Accuracy: 0.0 Loss: nan\n",
      "6000. Accuracy: 0.0 Loss: nan\n",
      "6000. Accuracy: 0.0 Loss: nan\n",
      "6000. Accuracy: 0.0 Loss: nan\n",
      "6000. Accuracy: 0.0 Loss: nan\n",
      "6000. Accuracy: 0.0 Loss: nan\n",
      "6000. Accuracy: 0.0 Loss: nan\n",
      "6500. Accuracy: 0.0 Loss: nan\n",
      "6500. Accuracy: 0.0 Loss: nan\n",
      "6500. Accuracy: 0.0 Loss: nan\n",
      "6500. Accuracy: 0.0 Loss: nan\n",
      "6500. Accuracy: 0.0 Loss: nan\n",
      "6500. Accuracy: 0.0 Loss: nan\n",
      "7000. Accuracy: 0.0 Loss: nan\n",
      "7000. Accuracy: 0.0 Loss: nan\n",
      "7000. Accuracy: 0.0 Loss: nan\n",
      "7000. Accuracy: 0.0 Loss: nan\n",
      "7000. Accuracy: 0.0 Loss: nan\n",
      "7000. Accuracy: 0.0 Loss: nan\n",
      "7500. Accuracy: 0.0 Loss: nan\n",
      "7500. Accuracy: 0.0 Loss: nan\n",
      "7500. Accuracy: 0.0 Loss: nan\n",
      "7500. Accuracy: 0.0 Loss: nan\n",
      "7500. Accuracy: 0.0 Loss: nan\n",
      "7500. Accuracy: 0.0 Loss: nan\n",
      "8000. Accuracy: 0.0 Loss: nan\n",
      "8000. Accuracy: 0.0 Loss: nan\n",
      "8000. Accuracy: 0.0 Loss: nan\n",
      "8000. Accuracy: 0.0 Loss: nan\n",
      "8000. Accuracy: 0.0 Loss: nan\n",
      "8000. Accuracy: 0.0 Loss: nan\n",
      "8500. Accuracy: 0.0 Loss: nan\n",
      "8500. Accuracy: 0.0 Loss: nan\n",
      "8500. Accuracy: 0.0 Loss: nan\n",
      "8500. Accuracy: 0.0 Loss: nan\n",
      "8500. Accuracy: 0.0 Loss: nan\n",
      "8500. Accuracy: 0.0 Loss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[136], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m train \u001b[38;5;241m=\u001b[39m Train(network2g, learning_rate, batch_size, epochs, loss_function)\n\u001b[0;32m----> 2\u001b[0m cost, accuracies \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/network/train.py:33\u001b[0m, in \u001b[0;36mTrain.train\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m     30\u001b[0m accuracies\u001b[38;5;241m.\u001b[39mappend(accuracy)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_function\u001b[38;5;241m.\u001b[39mbackward(predictions, output_batch)\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimise()\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/PycharmProjects/network/model.py:89\u001b[0m, in \u001b[0;36mNeuralNetwork.backward\u001b[0;34m(self, d_loss)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer, activation \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers), \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivations)):\n\u001b[1;32m     88\u001b[0m     activation\u001b[38;5;241m.\u001b[39mbackward(grad)\n\u001b[0;32m---> 89\u001b[0m     \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     grad \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39md_input\n",
      "File \u001b[0;32m~/PycharmProjects/network/model.py:39\u001b[0m, in \u001b[0;36mLayer.backward\u001b[0;34m(self, d_error)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput\u001b[38;5;241m.\u001b[39mT, d_error)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_bias \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(d_error, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_input \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# weights.t but the dim does nt go\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_input\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train = Train(network2g, learning_rate, batch_size, epochs, loss_function)\n",
    "cost, accuracies = train.train(inputs_train, outputs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1a5e5a27-fa8f-40c2-8d68-774fd77531a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([a for a in range(len(cost))],cost)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181983b0-a05b-4baa-9911-af3f665e2c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
